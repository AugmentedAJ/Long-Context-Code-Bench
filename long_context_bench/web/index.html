<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Long-Context-Bench - Leaderboard</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>Long-Context-Bench</h1>
        </header>

        <main>
            <section class="intro">
                <h2>About Long-Context-Code-Bench</h2>
                <p>
                    Long-Context-Code-Bench evaluates AI coding agents on <strong>enterprise-scale repositories with 40,000+ files</strong>.
                    Unlike existing benchmarks that focus on small codebases, LCB measures what matters most for enterprise adoption:
                    the ability to understand, modify, and integrate changes across massive real-world repositories.
                </p>
                <p>
                    This leaderboard shows results from <strong>head-to-head LLM-judge evaluation</strong>, where a single LLM
                    compares every pair of agents' solutions to the same real GitHub PRs. Each agent is tested on recreating actual PR
                    changes given only the PR description‚Äîno access to the solution or git history. The LLM then compares pairs of
                    solutions against the human ground truth diff and decides which is better based on correctness, completeness,
                    code quality, and integration.
                </p>
                <p>
                    <strong>üîç Most Openly Verifiable Benchmark:</strong> For each task, you can view each agent's judgment rationale,
                    side-by-side diff comparisons, and complete agent execution logs‚Äîmaking this the most transparent and verifiable
                    coding agent benchmark available. The entire benchmark is <strong>reproducible and fully open source</strong> at
                    <a href="https://github.com/AugmentedAJ/Long-Context-Code-Bench" target="_blank">github.com/AugmentedAJ/Long-Context-Code-Bench</a>.
                </p>
                <div class="version-notice">
                    <strong>üìä Version v0</strong> ‚Äî This is our initial release featuring 40 PRs from the Elasticsearch repository
                    (~40,000 files). Future versions will expand to include diverse codebases across multiple languages (Java, TypeScript,
                    Go, Rust) and even larger repository sizes to comprehensively evaluate context engines and retrieval systems at scale.
                </div>
            </section>

            <section class="leaderboard">
                <h2>Agent Leaderboard</h2>
                <p class="section-description">
                    Ranked by win rate from head-to-head LLM-judge evaluation. A single LLM compares every pair of agents' solutions,
                    and pairwise decisions determine win/loss/tie records.
                </p>
                <div class="table-container">
                    <table id="h2h-leaderboard-table">
                        <thead>
                            <tr>
                                <th>Rank</th>
                                <th>Agent</th>
                                <th>Win Rate</th>
                                <th>Wins</th>
                                <th>Losses</th>
                                <th>Ties</th>
                            </tr>
                        </thead>
                        <tbody id="h2h-leaderboard-body">
                            <tr>
                                <td colspan="6" class="loading">Loading leaderboard...</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </section>

            <section class="cross-agent-details">
                <h2>Head-to-Head Details by PR</h2>
                <p class="section-description">View pairwise agent judgments and results for each PR</p>

                <!-- Analysis List -->
                <div class="analysis-list-container">
                    <div class="analysis-list" id="analysis-list">
                        <p class="loading">Loading cross-agent analyses...</p>
                    </div>
                </div>

                <!-- Analysis Detail View -->
                <div class="analysis-detail" id="analysis-detail" style="display: none;">
                    <button id="back-button" class="btn-secondary" style="margin-bottom: 1rem;">‚Üê Back to List</button>

                    <h3 id="detail-title"></h3>

                    <!-- Task Description -->
                    <div class="card">
                        <h4>Task Description</h4>
                        <pre id="task-instructions" class="code-block"></pre>
                    </div>

                    <!-- Comparative Analysis (if available) -->
                    <div class="card" id="comparative-section" style="display: none;">
                        <h4>üèÜ Comparative Analysis</h4>
                        <div class="comparative-content">
                            <div class="metric-card">
                                <div class="stat-label">Best Agent</div>
                                <div class="stat-value" id="best-agent"></div>
                            </div>
                            <div class="analysis-text">
                                <h5>Summary</h5>
                                <p id="comparative-summary"></p>
                                <h5>Best Agent Reasoning</h5>
                                <p id="best-agent-reasoning"></p>
                                <h5>Approach Differences</h5>
                                <p id="approach-differences"></p>
                            </div>
                        </div>
                    </div>

                    <!-- Agent Results Comparison -->
                    <div class="card">
                        <h4>Agent Results</h4>
                        <div class="table-container">
                            <table id="agent-results-table">
                                <thead>
                                    <tr>
                                        <th>Rank</th>
                                        <th>Agent</th>
                                        <th>W/L/T</th>
                                        <th>Aggregate</th>
                                        <th>Correctness</th>
                                        <th>Completeness</th>
                                        <th>Code Reuse</th>
                                        <th>Best Practices</th>
                                        <th>Unsolicited Docs</th>
                                        <th>Time (s)</th>
                                    </tr>
                                </thead>
                                <tbody id="agent-results-body">
                                </tbody>
                            </table>
                            <!-- Agent Details (Diff/Logs) -->
                            <div id="agent-details-sections"></div>
                        </div>
                    </div>

                    <!-- Individual Agent Details -->
                    <div id="agent-details-container"></div>
                </div>
            </section>
        </main>

        <footer>
            <p>Last updated: <span id="last-updated">-</span></p>
        </footer>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
    <script src="data-loader.js?v=5"></script>
    <script src="charts.js?v=5"></script>
    <script src="cross-agent.js?v=5"></script>
    <script src="app.js?v=5"></script>
    <script>
        // Initialize leaderboard page
        document.addEventListener('DOMContentLoaded', async () => {
            await loadLeaderboard();

            // Back button handler for detail view
            const backButton = document.getElementById('back-button');
            if (backButton) {
                backButton.addEventListener('click', () => {
                    // Show the PR list again
                    document.getElementById('analysis-list').style.display = 'block';
                    document.getElementById('analysis-detail').style.display = 'none';
                });
            }
        });
    </script>
</body>
</html>

