<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Long-Context-Bench - Leaderboard</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>Long-Context-Bench</h1>
        </header>

        <main>
            <section class="intro">
                <h2>About Long-Context-Code-Bench</h2>
                <p>
                    Long-Context-Code-Bench evaluates AI coding agents on <strong>enterprise-scale repositories with 40,000+ files</strong>.
                    Unlike existing benchmarks that focus on small codebases, LCB measures what matters most for enterprise adoption:
                    the ability to understand, modify, and integrate changes across massive real-world repositories.
                </p>
                <p>
                    This leaderboard shows results from <strong>cross-agent comparative analysis</strong>, where an LLM judge evaluates
                    multiple agents solving the same real GitHub PRs and ranks them based on correctness, completeness, code reuse,
                    and best practices. Each agent is tested on recreating actual PR changes given only the PR description‚Äîno access
                    to the solution or git history.
                </p>
                <p>
                    <strong>üîç Most Openly Verifiable Benchmark:</strong> For each task, you can view the LLM judge's detailed commentary,
                    side-by-side diff comparisons, and complete agent execution logs‚Äîmaking this the most transparent and verifiable
                    coding agent benchmark available. The entire benchmark is <strong>reproducible and fully open source</strong> at
                    <a href="https://github.com/AugmentedAJ/Long-Context-Code-Bench" target="_blank">github.com/AugmentedAJ/Long-Context-Code-Bench</a>.
                </p>
                <div class="version-notice">
                    <strong>üìä Version v0</strong> ‚Äî This is our initial release featuring 40 PRs from the Elasticsearch repository
                    (~40,000 files). Future versions will expand to include diverse codebases across multiple languages (Java, TypeScript,
                    Go, Rust) and even larger repository sizes to comprehensively evaluate context engines and retrieval systems at scale.
                </div>
            </section>

            <section class="leaderboard">
                <h2>Agent Leaderboard</h2>
                <p class="section-description">Ranked by aggregate LLM judge score from cross-agent comparative analysis</p>
                <div class="table-container">
                    <table id="leaderboard-table">
                        <thead>
                            <tr>
                                <th class="sortable" data-sort="rank">Rank</th>
                                <th class="sortable" data-sort="runner">Runner</th>
                                <th class="sortable" data-sort="model">Model</th>
                                <th class="sortable" data-sort="win_rate">Win Rate</th>
                                <th class="sortable" data-sort="wins">Wins</th>
                                <th class="sortable" data-sort="mean_aggregate">Aggregate Score</th>
                                <th class="sortable" data-sort="mean_correctness">Correctness</th>
                                <th class="sortable" data-sort="mean_completeness">Completeness</th>
                                <th class="sortable" data-sort="mean_code_reuse">Code Reuse</th>
                            </tr>
                        </thead>
                        <tbody id="leaderboard-body">
                            <tr>
                                <td colspan="9" class="loading">Loading data...</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </section>

            <section class="cross-agent-details">
                <h2>Cross-Agent Analysis Details</h2>
                <p class="section-description">Detailed comparative analysis for each PR</p>

                <!-- Analysis List -->
                <div class="analysis-list-container">
                    <div class="analysis-list" id="analysis-list">
                        <p class="loading">Loading cross-agent analyses...</p>
                    </div>
                </div>

                <!-- Analysis Detail View -->
                <div class="analysis-detail" id="analysis-detail" style="display: none;">
                    <button id="back-button" class="btn-secondary" style="margin-bottom: 1rem;">‚Üê Back to List</button>

                    <h3 id="detail-title"></h3>

                    <!-- Task Description -->
                    <div class="card">
                        <h4>Task Description</h4>
                        <pre id="task-instructions" class="code-block"></pre>
                    </div>

                    <!-- Comparative Analysis (if available) -->
                    <div class="card" id="comparative-section" style="display: none;">
                        <h4>üèÜ Comparative Analysis</h4>
                        <div class="comparative-content">
                            <div class="metric-card">
                                <div class="stat-label">Best Agent</div>
                                <div class="stat-value" id="best-agent"></div>
                            </div>
                            <div class="analysis-text">
                                <h5>Summary</h5>
                                <p id="comparative-summary"></p>
                                <h5>Best Agent Reasoning</h5>
                                <p id="best-agent-reasoning"></p>
                                <h5>Approach Differences</h5>
                                <p id="approach-differences"></p>
                            </div>
                        </div>
                    </div>

                    <!-- Agent Results Comparison -->
                    <div class="card">
                        <h4>Agent Results</h4>
                        <div class="chart-container">
                            <canvas id="agent-scores-chart"></canvas>
                        </div>
                        <div class="table-container">
                            <table id="agent-results-table">
                                <thead>
                                    <tr>
                                        <th>Rank</th>
                                        <th>Agent</th>
                                        <th>Status</th>
                                        <th>LLM Rating</th>
                                        <th>Summary</th>
                                        <th>Aggregate</th>
                                        <th>Correctness</th>
                                        <th>Completeness</th>
                                        <th>Code Reuse</th>
                                        <th>Best Practices</th>
                                        <th>Unsolicited Docs</th>
                                        <th>Time (s)</th>
                                    </tr>
                                </thead>
                                <tbody id="agent-results-body">
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <!-- Individual Agent Details -->
                    <div id="agent-details-container"></div>
                </div>
            </section>
        </main>

        <footer>
            <p>Last updated: <span id="last-updated">-</span></p>
        </footer>
    </div>

    <script src="lib/chart.min.js"></script>
    <script src="data-loader.js"></script>
    <script src="charts.js"></script>
    <script src="cross-agent.js"></script>
    <script src="app.js"></script>
    <script>
        // Initialize leaderboard page
        document.addEventListener('DOMContentLoaded', async () => {
            await loadLeaderboard();

            // Back button handler for detail view
            const backButton = document.getElementById('back-button');
            if (backButton) {
                backButton.addEventListener('click', () => {
                    if (typeof showAnalysisList === 'function') {
                        showAnalysisList();
                    }
                });
            }
        });
    </script>
</body>
</html>

