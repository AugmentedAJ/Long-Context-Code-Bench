{
  "repo_url": "https://github.com/elastic/elasticsearch.git",
  "pr_number": 134964,
  "base_commit": "2ab71babbc961f70b434f7bd5f8cb935f283fc0e",
  "head_commit": "bcd9b24aa87f17df49a41e784968bbada2ae1713",
  "judge_mode": "llm",
  "judge_model": "claude-sonnet-4-5",
  "scores": {
    "correctness": -1.0,
    "completeness": -1.0,
    "code_reuse": 0.0,
    "best_practices": 0.0,
    "unsolicited_docs": 1.0
  },
  "aggregate": -0.2,
  "rationale": "The agent modified the wrong file entirely. The task and ground truth both fix a typo in DefaultUnsortableTopNEncoder.java (line 146), changing Long.BYTES to Double.BYTES in the encodeDouble method's setLength call. The agent instead modified SortableTopNEncoder.java, which appears to be a different class with similar code. While the agent's change is technically correct for the file it modified (fixing both grow and setLength calls to use Double.BYTES), it completely missed the actual target file specified in the task. The ground truth also includes substantial changes to PatternTextFieldType.java and PatternTextFieldMapperTests.java that the agent did not address, though these appear unrelated to the stated task about the typo. Since the agent failed to fix the actual typo in the correct file, this is a critical failure in both correctness and completeness.",
  "edit_run_id": "7ad89f22",
  "judge_run_id": "3e164e1c",
  "ground_truth_patch": "diff --git a/x-pack/plugin/esql/compute/src/main/java/org/elasticsearch/compute/operator/topn/DefaultUnsortableTopNEncoder.java b/x-pack/plugin/esql/compute/src/main/java/org/elasticsearch/compute/operator/topn/DefaultUnsortableTopNEncoder.java\nindex df1025f89c8..603af7f4654 100644\n--- a/x-pack/plugin/esql/compute/src/main/java/org/elasticsearch/compute/operator/topn/DefaultUnsortableTopNEncoder.java\n+++ b/x-pack/plugin/esql/compute/src/main/java/org/elasticsearch/compute/operator/topn/DefaultUnsortableTopNEncoder.java\n@@ -143,7 +143,7 @@ public final class DefaultUnsortableTopNEncoder implements TopNEncoder {\n     public void encodeDouble(double value, BreakingBytesRefBuilder bytesRefBuilder) {\n         bytesRefBuilder.grow(bytesRefBuilder.length() + Double.BYTES);\n         DOUBLE.set(bytesRefBuilder.bytes(), bytesRefBuilder.length(), value);\n-        bytesRefBuilder.setLength(bytesRefBuilder.length() + Long.BYTES);\n+        bytesRefBuilder.setLength(bytesRefBuilder.length() + Double.BYTES);\n     }\n \n     @Override\ndiff --git a/x-pack/plugin/logsdb/src/main/java/org/elasticsearch/xpack/logsdb/patterntext/PatternTextFieldType.java b/x-pack/plugin/logsdb/src/main/java/org/elasticsearch/xpack/logsdb/patterntext/PatternTextFieldType.java\nindex 62e4c205571..555cacb36be 100644\n--- a/x-pack/plugin/logsdb/src/main/java/org/elasticsearch/xpack/logsdb/patterntext/PatternTextFieldType.java\n+++ b/x-pack/plugin/logsdb/src/main/java/org/elasticsearch/xpack/logsdb/patterntext/PatternTextFieldType.java\n@@ -28,9 +28,11 @@ import org.elasticsearch.common.CheckedIntFunction;\n import org.elasticsearch.common.unit.Fuzziness;\n import org.elasticsearch.index.fielddata.FieldDataContext;\n import org.elasticsearch.index.fielddata.IndexFieldData;\n+import org.elasticsearch.index.fielddata.SourceValueFetcherSortedBinaryIndexFieldData;\n import org.elasticsearch.index.fieldvisitor.StoredFieldLoader;\n import org.elasticsearch.index.mapper.BlockLoader;\n import org.elasticsearch.index.mapper.BlockStoredFieldsReader;\n+import org.elasticsearch.index.mapper.SourceValueFetcher;\n import org.elasticsearch.index.mapper.StringFieldType;\n import org.elasticsearch.index.mapper.TextFieldMapper;\n import org.elasticsearch.index.mapper.TextSearchInfo;\n@@ -38,8 +40,9 @@ import org.elasticsearch.index.mapper.ValueFetcher;\n import org.elasticsearch.index.mapper.extras.SourceConfirmedTextQuery;\n import org.elasticsearch.index.mapper.extras.SourceIntervalsSource;\n import org.elasticsearch.index.query.SearchExecutionContext;\n-import org.elasticsearch.search.fetch.StoredFieldsSpec;\n-import org.elasticsearch.search.lookup.Source;\n+import org.elasticsearch.script.field.KeywordDocValuesField;\n+import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;\n+import org.elasticsearch.search.lookup.SourceProvider;\n \n import java.io.IOException;\n import java.io.UncheckedIOException;\n@@ -112,32 +115,7 @@ public class PatternTextFieldType extends StringFieldType {\n \n     @Override\n     public ValueFetcher valueFetcher(SearchExecutionContext context, String format) {\n-        return new ValueFetcher() {\n-            PatternTextCompositeValues docValues;\n-\n-            @Override\n-            public void setNextReader(LeafReaderContext context) {\n-                try {\n-                    this.docValues = PatternTextCompositeValues.from(context.reader(), PatternTextFieldType.this);\n-                } catch (IOException e) {\n-                    throw new UncheckedIOException(e);\n-                }\n-            }\n-\n-            @Override\n-            public List<Object> fetchValues(Source source, int doc, List<Object> ignoredValues) throws IOException {\n-                if (false == docValues.advanceExact(doc)) {\n-                    return List.of();\n-                }\n-                return List.of(docValues.binaryValue().utf8ToString());\n-            }\n-\n-            @Override\n-            public StoredFieldsSpec storedFieldsSpec() {\n-                // PatternedTextCompositeValues may require a stored field, but it handles loading this field internally.\n-                return StoredFieldsSpec.NO_REQUIREMENTS;\n-            }\n-        };\n+        return SourceValueFetcher.toString(name(), context, format);\n     }\n \n     private IOFunction<LeafReaderContext, CheckedIntFunction<List<Object>, IOException>> getValueFetcherProvider(\n@@ -149,10 +127,11 @@ public class PatternTextFieldType extends StringFieldType {\n \n         return context -> {\n             ValueFetcher valueFetcher = valueFetcher(searchExecutionContext, null);\n+            SourceProvider sourceProvider = searchExecutionContext.lookup();\n             valueFetcher.setNextReader(context);\n             return docID -> {\n                 try {\n-                    return valueFetcher.fetchValues(null, docID, new ArrayList<>());\n+                    return valueFetcher.fetchValues(sourceProvider.getSource(context, docID), docID, new ArrayList<>());\n                 } catch (IOException e) {\n                     throw new UncheckedIOException(e);\n                 }\n@@ -314,7 +293,17 @@ public class PatternTextFieldType extends StringFieldType {\n         if (fieldDataContext.fielddataOperation() != FielddataOperation.SCRIPT) {\n             throw new IllegalArgumentException(CONTENT_TYPE + \" fields do not support sorting and aggregations\");\n         }\n-        return new PatternTextIndexFieldData.Builder(this);\n+        if (textFieldType.isSyntheticSource()) {\n+            return new PatternTextIndexFieldData.Builder(this);\n+        }\n+        return new SourceValueFetcherSortedBinaryIndexFieldData.Builder(\n+            name(),\n+            CoreValuesSourceType.KEYWORD,\n+            SourceValueFetcher.toString(fieldDataContext.sourcePathsLookup().apply(name())),\n+            fieldDataContext.lookupSupplier().get(),\n+            KeywordDocValuesField::new\n+        );\n+\n     }\n \n     String templateFieldName() {\ndiff --git a/x-pack/plugin/logsdb/src/test/java/org/elasticsearch/xpack/logsdb/patterntext/PatternTextFieldMapperTests.java b/x-pack/plugin/logsdb/src/test/java/org/elasticsearch/xpack/logsdb/patterntext/PatternTextFieldMapperTests.java\nindex 99e57bf3b06..52c3b7ceb75 100644\n--- a/x-pack/plugin/logsdb/src/test/java/org/elasticsearch/xpack/logsdb/patterntext/PatternTextFieldMapperTests.java\n+++ b/x-pack/plugin/logsdb/src/test/java/org/elasticsearch/xpack/logsdb/patterntext/PatternTextFieldMapperTests.java\n@@ -26,9 +26,6 @@ import org.elasticsearch.common.bytes.BytesReference;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.xcontent.XContentHelper;\n import org.elasticsearch.core.Tuple;\n-import org.elasticsearch.index.fielddata.FieldDataContext;\n-import org.elasticsearch.index.fielddata.IndexFieldDataCache;\n-import org.elasticsearch.index.mapper.DocValueFetcher;\n import org.elasticsearch.index.mapper.DocumentMapper;\n import org.elasticsearch.index.mapper.KeywordFieldMapper;\n import org.elasticsearch.index.mapper.LuceneDocument;\n@@ -37,14 +34,9 @@ import org.elasticsearch.index.mapper.MapperParsingException;\n import org.elasticsearch.index.mapper.MapperService;\n import org.elasticsearch.index.mapper.MapperTestCase;\n import org.elasticsearch.index.mapper.ParsedDocument;\n-import org.elasticsearch.index.mapper.SourceToParse;\n-import org.elasticsearch.index.mapper.ValueFetcher;\n import org.elasticsearch.index.query.MatchPhraseQueryBuilder;\n import org.elasticsearch.index.query.SearchExecutionContext;\n-import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;\n import org.elasticsearch.plugins.Plugin;\n-import org.elasticsearch.search.lookup.Source;\n-import org.elasticsearch.search.lookup.SourceProvider;\n import org.elasticsearch.xcontent.ToXContent;\n import org.elasticsearch.xcontent.XContentBuilder;\n import org.elasticsearch.xcontent.XContentFactory;\n@@ -55,21 +47,14 @@ import org.junit.AssumptionViolatedException;\n import org.junit.Before;\n \n import java.io.IOException;\n-import java.util.ArrayList;\n import java.util.Collection;\n import java.util.Collections;\n import java.util.List;\n import java.util.Map;\n-import java.util.Set;\n-import java.util.stream.Collectors;\n \n-import static java.util.stream.Collectors.toList;\n-import static org.hamcrest.Matchers.containsInAnyOrder;\n import static org.hamcrest.Matchers.containsString;\n import static org.hamcrest.Matchers.equalTo;\n import static org.hamcrest.Matchers.instanceOf;\n-import static org.mockito.Mockito.mock;\n-import static org.mockito.Mockito.when;\n \n public class PatternTextFieldMapperTests extends MapperTestCase {\n \n@@ -313,69 +298,13 @@ public class PatternTextFieldMapperTests extends MapperTestCase {\n \n     @Override\n     protected Object generateRandomInputValue(MappedFieldType ft) {\n-        return PatternTextIntegrationTests.randomMessageMaybeLarge();\n+        assumeFalse(\"We don't have a way to assert things here\", true);\n+        return null;\n     }\n \n     @Override\n-    protected void assertFetchMany(MapperService mapperService, String field, Object value, String format, int count) throws IOException {\n-        assumeFalse(\"pattern_text currently don't support multiple values in the same field\", false);\n-    }\n-\n-    /**\n-     * pattern_text does not allow sorting or aggregation and thus only allow field data operations\n-     * of type SCRIPT to access field data. We still want to use `testFetch` to compare value fetchers against doc\n-     * values. This method copies MapperTestCase.assertFetch, but uses field data operation type SCRIPT.\n-     */\n-    @Override\n-    protected void assertFetch(MapperService mapperService, String field, Object value, String format) throws IOException {\n-        MappedFieldType ft = mapperService.fieldType(field);\n-        SourceToParse source = source(b -> b.field(ft.name(), value));\n-        var fielddataContext = new FieldDataContext(\"\", null, () -> null, Set::of, MappedFieldType.FielddataOperation.SCRIPT);\n-        var fdt = fielddataContext.fielddataOperation();\n-        ValueFetcher docValueFetcher = new DocValueFetcher(\n-            ft.docValueFormat(format, null),\n-            ft.fielddataBuilder(fielddataContext).build(new IndexFieldDataCache.None(), new NoneCircuitBreakerService())\n-        );\n-        SearchExecutionContext searchExecutionContext = mock(SearchExecutionContext.class);\n-        when(searchExecutionContext.isSourceEnabled()).thenReturn(true);\n-        when(searchExecutionContext.sourcePath(field)).thenReturn(Set.of(field));\n-        when(searchExecutionContext.getForField(ft, fdt)).thenAnswer(inv -> fieldDataLookup(mapperService).apply(ft, () -> {\n-            throw new UnsupportedOperationException();\n-        }, fdt));\n-        ValueFetcher nativeFetcher = ft.valueFetcher(searchExecutionContext, format);\n-        ParsedDocument doc = mapperService.documentMapper().parse(source);\n-        withLuceneIndex(mapperService, iw -> iw.addDocuments(doc.docs()), ir -> {\n-            Source s = SourceProvider.fromLookup(mapperService.mappingLookup(), null, mapperService.getMapperMetrics().sourceFieldMetrics())\n-                .getSource(ir.leaves().get(0), 0);\n-            docValueFetcher.setNextReader(ir.leaves().get(0));\n-            nativeFetcher.setNextReader(ir.leaves().get(0));\n-            List<Object> fromDocValues = docValueFetcher.fetchValues(s, 0, new ArrayList<>());\n-            List<Object> fromNative = nativeFetcher.fetchValues(s, 0, new ArrayList<>());\n-            /*\n-             * The native fetcher uses byte, short, etc but doc values always\n-             * uses long or double. This difference is fine because on the outside\n-             * users can't see it.\n-             */\n-            fromNative = fromNative.stream().map(o -> {\n-                if (o instanceof Integer || o instanceof Short || o instanceof Byte) {\n-                    return ((Number) o).longValue();\n-                }\n-                if (o instanceof Float) {\n-                    return ((Float) o).doubleValue();\n-                }\n-                return o;\n-            }).collect(toList());\n-\n-            if (dedupAfterFetch()) {\n-                fromNative = fromNative.stream().distinct().collect(Collectors.toList());\n-            }\n-            /*\n-             * Doc values sort according to something appropriate to the field\n-             * and the native fetchers usually don't sort. We're ok with this\n-             * difference. But we have to convince the test we're ok with it.\n-             */\n-            assertThat(\"fetching \" + value, fromNative, containsInAnyOrder(fromDocValues.toArray()));\n-        });\n+    protected void randomFetchTestFieldConfig(XContentBuilder b) throws IOException {\n+        assumeFalse(\"We don't have a way to assert things here\", true);\n     }\n \n     @Override\ndiff --git a/x-pack/plugin/logsdb/src/test/java/org/elasticsearch/xpack/logsdb/patterntext/PatternTextIntegrationTests.java b/x-pack/plugin/logsdb/src/test/java/org/elasticsearch/xpack/logsdb/patterntext/PatternTextIntegrationTests.java\nindex 68ceed8e934..051dab7a81b 100644\n--- a/x-pack/plugin/logsdb/src/test/java/org/elasticsearch/xpack/logsdb/patterntext/PatternTextIntegrationTests.java\n+++ b/x-pack/plugin/logsdb/src/test/java/org/elasticsearch/xpack/logsdb/patterntext/PatternTextIntegrationTests.java\n@@ -185,24 +185,6 @@ public class PatternTextIntegrationTests extends ESSingleNodeTestCase {\n         }\n     }\n \n-    public void testPhraseQuery() throws IOException {\n-        var createRequest = new CreateIndexRequest(INDEX).mapping(mapping);\n-        createRequest.settings(LOGSDB_SETTING);\n-        assertAcked(admin().indices().create(createRequest));\n-\n-        String smallMessage = \"cat dog 123 house mouse\";\n-        final String message = randomBoolean() ? smallMessage : smallMessage.repeat(32_000 / smallMessage.length());\n-\n-        List<String> logMessages = List.of(message);\n-        indexDocs(logMessages);\n-        assertMappings();\n-\n-        var query = QueryBuilders.matchPhraseQuery(\"field_pattern_text\", \"dog 123 house\");\n-        var searchRequest = client().prepareSearch(INDEX).setQuery(query);\n-\n-        assertNoFailuresAndResponse(searchRequest, searchResponse -> { assertEquals(1, searchResponse.getHits().getTotalHits().value()); });\n-    }\n-\n     public void testQueryResultsSameAsMatchOnlyText() throws IOException {\n         var createRequest = new CreateIndexRequest(INDEX).mapping(mapping);\n \n@@ -356,14 +338,6 @@ public class PatternTextIntegrationTests extends ESSingleNodeTestCase {\n         return sb.toString();\n     }\n \n-    public static String randomMessageMaybeLarge() {\n-        if (randomDouble() < 0.2) {\n-            return randomMessage(32 * 1024);\n-        } else {\n-            return randomMessage();\n-        }\n-    }\n-\n     public static String randomMessage() {\n         if (rarely()) {\n             return randomRealisticUnicodeOfCodepointLength(randomIntBetween(1, 100));"
}