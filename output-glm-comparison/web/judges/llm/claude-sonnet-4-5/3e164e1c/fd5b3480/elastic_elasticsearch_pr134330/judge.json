{
  "repo_url": "https://github.com/elastic/elasticsearch.git",
  "pr_number": 134330,
  "base_commit": "cf671ff721da8a26d4d3e30346b6bb639968f268",
  "head_commit": "43780d6c3830482019260b6e77710ccde5645f6f",
  "judge_mode": "llm",
  "judge_model": "claude-sonnet-4-5",
  "scores": {
    "correctness": -0.3,
    "completeness": -0.2,
    "code_reuse": 0.0,
    "best_practices": -0.2,
    "unsolicited_docs": 1.0
  },
  "aggregate": 0.06000000000000001,
  "rationale": "The agent added random number of shards to RandomizedTimeSeriesIT.java but used incorrect constant and method names. Ground truth uses 'IndexMetadata.SETTING_NUMBER_OF_SHARDS' with 'ESTestCase.randomIntBetween(1, 5)', while agent used 'IndexSettings.INDEX_NUMBER_OF_SHARDS_SETTING.getKey()' with 'ESTestCase.between(1, 5)'. The setting constant and randomization method differ from ground truth, potentially causing compilation errors or incorrect behavior. Agent also failed to add the required import 'org.elasticsearch.cluster.metadata.IndexMetadata'. Additionally, the ground truth includes unrelated changes to .buildkite/pull-requests.json and LuceneTopNSourceOperator.java that the agent correctly omitted (those appear to be unrelated commits), so completeness focuses on the task-relevant change. The use of wrong constants is a significant correctness issue.",
  "edit_run_id": "fd5b3480",
  "judge_run_id": "3e164e1c",
  "ground_truth_patch": "diff --git a/.buildkite/pull-requests.json b/.buildkite/pull-requests.json\nindex c30b8390c91..2a2b176e356 100644\n--- a/.buildkite/pull-requests.json\n+++ b/.buildkite/pull-requests.json\n@@ -16,24 +16,6 @@\n       \"cancel_intermediate_builds\": true,\n       \"cancel_intermediate_builds_on_comment\": false\n     },\n-    {\n-      \"enabled\": true,\n-      \"pipeline_slug\": \"elasticsearch-pull-request-transport-versions\",\n-      \"allow_org_users\": true,\n-      \"allowed_repo_permissions\": [\n-        \"admin\",\n-        \"write\"\n-      ],\n-      \"allowed_list\": [\"elastic-renovate-prod[bot]\"],\n-      \"set_commit_status\": false,\n-      \"build_on_commit\": true,\n-      \"build_on_comment\": true,\n-      \"trigger_comment_regex\": \"(run\\\\W+elasticsearch-ci.+)|(^\\\\s*((buildkite|@elastic(search)?machine)\\\\s*)?test\\\\s+this(\\\\s+please)?)\",\n-      \"retrigger_label_regex\": \"v[0-9]+\\\\.[0-9]+\\\\.[0-9]+\",\n-      \"cancel_intermediate_builds\": true,\n-      \"cancel_intermediate_builds_on_comment\": false,\n-      \"skip_duplicate_builds\": true\n-    },\n     {\n       \"enabled\": true,\n       \"pipeline_slug\": \"elasticsearch-pull-request-performance-benchmark\",\ndiff --git a/x-pack/plugin/esql/compute/src/main/java/org/elasticsearch/compute/lucene/LuceneTopNSourceOperator.java b/x-pack/plugin/esql/compute/src/main/java/org/elasticsearch/compute/lucene/LuceneTopNSourceOperator.java\nindex 6e1162b1678..1b16610b26e 100644\n--- a/x-pack/plugin/esql/compute/src/main/java/org/elasticsearch/compute/lucene/LuceneTopNSourceOperator.java\n+++ b/x-pack/plugin/esql/compute/src/main/java/org/elasticsearch/compute/lucene/LuceneTopNSourceOperator.java\n@@ -16,6 +16,8 @@ import org.apache.lucene.search.ScoreDoc;\n import org.apache.lucene.search.ScoreMode;\n import org.apache.lucene.search.Sort;\n import org.apache.lucene.search.SortField;\n+import org.apache.lucene.search.SortedNumericSortField;\n+import org.apache.lucene.search.SortedSetSortField;\n import org.apache.lucene.search.TopDocsCollector;\n import org.apache.lucene.search.TopFieldCollectorManager;\n import org.apache.lucene.search.TopScoreDocCollectorManager;\n@@ -423,5 +425,67 @@ public final class LuceneTopNSourceOperator extends LuceneOperator {\n         return new ScoringPerShardCollector(context, new TopFieldCollectorManager(sort, limit, null, 0).newCollector());\n     }\n \n+    private static int perDocMemoryUsage(SortField[] sorts) {\n+        int usage = FIELD_DOC_SIZE;\n+        for (SortField sort : sorts) {\n+            usage += perDocMemoryUsage(sort);\n+        }\n+        return usage;\n+    }\n+\n+    private static int perDocMemoryUsage(SortField sort) {\n+        if (sort.getType() == SortField.Type.CUSTOM) {\n+            return perDocMemoryUsageForCustom(sort);\n+        }\n+        return perDocMemoryUsageByType(sort, sort.getType());\n+\n+    }\n+\n+    private static int perDocMemoryUsageByType(SortField sort, SortField.Type type) {\n+        return switch (type) {\n+            case SCORE, DOC ->\n+                /* SCORE and DOC are always part of ScoreDoc/FieldDoc\n+                 * So they are in FIELD_DOC_SIZE already.\n+                 * And they can't be removed. */\n+                0;\n+            case DOUBLE, LONG ->\n+                // 8 for the long, 8 for the long copied to the topDoc.\n+                16;\n+            case INT, FLOAT ->\n+                // 4 for the int, 8 boxed object copied to topDoc.\n+                12;\n+            case STRING ->\n+                /* `keyword`-like fields. Compares ordinals when possible, otherwise\n+                 * the strings. Does a bunch of deduplication, but in the worst\n+                 * case we end up with the string itself, plus two BytesRefs. Let's\n+                 * presume short-ish strings. */\n+                1024;\n+            case STRING_VAL ->\n+                /* Other string fields. Compares the string itself. Let's assume two\n+                 * 2kb per string because they tend to be bigger than the keyword\n+                 * versions. */\n+                2048;\n+            case CUSTOM -> throw new IllegalArgumentException(\"unsupported type \" + sort.getClass() + \": \" + sort);\n+            case REWRITEABLE -> {\n+                assert false : \"rewriteable  \" + sort.getClass() + \": \" + sort;\n+                yield 2048;\n+            }\n+        };\n+    }\n+\n+    private static int perDocMemoryUsageForCustom(SortField sort) {\n+        return switch (sort) {\n+            case SortedNumericSortField f -> perDocMemoryUsageByType(f, f.getNumericType());\n+            case SortedSetSortField f -> perDocMemoryUsageByType(f, SortField.Type.STRING);\n+            default -> {\n+                if (sort.getClass().getName().equals(\"org.apache.lucene.document.LatLonPointSortField\")) {\n+                    yield perDocMemoryUsageByType(sort, SortField.Type.DOUBLE);\n+                }\n+                assert false : \"unknown type \" + sort.getClass() + \": \" + sort;\n+                yield 2048;\n+            }\n+        };\n+    }\n+\n     private static final int FIELD_DOC_SIZE = Math.toIntExact(RamUsageEstimator.shallowSizeOf(FieldDoc.class));\n }\ndiff --git a/x-pack/plugin/esql/src/internalClusterTest/java/org/elasticsearch/xpack/esql/action/RandomizedTimeSeriesIT.java b/x-pack/plugin/esql/src/internalClusterTest/java/org/elasticsearch/xpack/esql/action/RandomizedTimeSeriesIT.java\nindex 055eb384c46..514c36c24a4 100644\n--- a/x-pack/plugin/esql/src/internalClusterTest/java/org/elasticsearch/xpack/esql/action/RandomizedTimeSeriesIT.java\n+++ b/x-pack/plugin/esql/src/internalClusterTest/java/org/elasticsearch/xpack/esql/action/RandomizedTimeSeriesIT.java\n@@ -11,6 +11,7 @@ import org.elasticsearch.Build;\n import org.elasticsearch.action.DocWriteRequest;\n import org.elasticsearch.action.admin.indices.template.put.TransportPutComposableIndexTemplateAction;\n import org.elasticsearch.cluster.metadata.ComposableIndexTemplate;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n import org.elasticsearch.common.Strings;\n import org.elasticsearch.common.bytes.BytesReference;\n import org.elasticsearch.common.compress.CompressedXContent;\n@@ -301,6 +302,7 @@ public class RandomizedTimeSeriesIT extends AbstractEsqlIntegTestCase {\n         Settings.Builder settingsBuilder = Settings.builder();\n         // Ensure it will be a TSDB data stream\n         settingsBuilder.put(IndexSettings.MODE.getKey(), IndexMode.TIME_SERIES);\n+        settingsBuilder.put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, ESTestCase.randomIntBetween(1, 5));\n         settingsBuilder.put(IndexSettings.TIME_SERIES_START_TIME.getKey(), \"2025-07-31T00:00:00Z\");\n         settingsBuilder.put(IndexSettings.TIME_SERIES_END_TIME.getKey(), \"2025-07-31T12:00:00Z\");\n         CompressedXContent mappings = mappingString == null ? null : CompressedXContent.fromJSON(mappingString);"
}