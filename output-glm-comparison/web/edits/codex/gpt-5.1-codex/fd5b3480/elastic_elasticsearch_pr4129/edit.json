{
  "repo_url": "https://github.com/elastic/elasticsearch.git",
  "pr_number": 4129,
  "base_commit": "f7d5d1e5c9a04117f780a62cac970dbe24ddebf7",
  "runner": "codex",
  "model": "gpt-5.1-codex",
  "timeout_s": 10800,
  "status": "success",
  "elapsed_ms": 147677,
  "patch_unified": "diff --git a/src/main/java/org/elasticsearch/search/suggest/completion/CompletionTokenStream.java b/src/main/java/org/elasticsearch/search/suggest/completion/CompletionTokenStream.java\nindex 260bd57..8f87302 100644\n--- a/src/main/java/org/elasticsearch/search/suggest/completion/CompletionTokenStream.java\n+++ b/src/main/java/org/elasticsearch/search/suggest/completion/CompletionTokenStream.java\n@@ -19,12 +19,15 @@\n package org.elasticsearch.search.suggest.completion;\n \n import org.apache.lucene.analysis.TokenStream;\n+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;\n import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;\n import org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute;\n import org.apache.lucene.util.AttributeImpl;\n import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.CharsRef;\n import org.apache.lucene.util.IntsRef;\n+import org.apache.lucene.util.UnicodeUtil;\n import org.apache.lucene.util.fst.Util;\n \n import java.io.IOException;\n@@ -39,6 +42,7 @@ public final class CompletionTokenStream extends TokenStream {\n     private final PayloadAttribute payloadAttr = addAttribute(PayloadAttribute.class);;\n     private final PositionIncrementAttribute posAttr = addAttribute(PositionIncrementAttribute.class);\n     private final ByteTermAttribute bytesAtt = addAttribute(ByteTermAttribute.class);\n+    private final CharTermAttribute charTermAttribute = addAttribute(CharTermAttribute.class);\n \n     private final TokenStream input;\n     private BytesRef payload;\n@@ -47,6 +51,7 @@ public final class CompletionTokenStream extends TokenStream {\n     private int posInc = -1;\n     private static final int MAX_PATHS = 256;\n     private final BytesRef scratch = new BytesRef();\n+    private final CharsRef spareChars = new CharsRef();\n \n     public CompletionTokenStream(TokenStream input, BytesRef payload, ToFiniteStrings toFiniteStrings) throws IOException {\n         this.input = input;\n@@ -76,6 +81,8 @@ public final class CompletionTokenStream extends TokenStream {\n             posInc = 0;\n             Util.toBytesRef(finiteStrings.next(), scratch); // now we have UTF-8\n             bytesAtt.setBytesRef(scratch);\n+            UnicodeUtil.UTF8toUTF16(scratch, spareChars);\n+            charTermAttribute.copyBuffer(spareChars.chars, spareChars.offset, spareChars.length);\n             if (payload != null) {\n                 payloadAttr.setPayload(this.payload);\n             }\n@@ -143,4 +150,4 @@ public final class CompletionTokenStream extends TokenStream {\n             other.bytes = bytes;\n         }\n     }\n-}\n\\ No newline at end of file\n+}\ndiff --git a/src/test/java/org/elasticsearch/search/suggest/CompletionTokenStreamTest.java b/src/test/java/org/elasticsearch/search/suggest/CompletionTokenStreamTest.java\nindex d5ebfa5..e03c733 100644\n--- a/src/test/java/org/elasticsearch/search/suggest/CompletionTokenStreamTest.java\n+++ b/src/test/java/org/elasticsearch/search/suggest/CompletionTokenStreamTest.java\n@@ -19,7 +19,6 @@\n package org.elasticsearch.search.suggest;\n \n import org.apache.lucene.analysis.MockTokenizer;\n-import org.apache.lucene.analysis.TokenFilter;\n import org.apache.lucene.analysis.TokenStream;\n import org.apache.lucene.analysis.core.SimpleAnalyzer;\n import org.apache.lucene.analysis.synonym.SynonymFilter;\n@@ -28,7 +27,6 @@ import org.apache.lucene.analysis.synonym.SynonymMap.Builder;\n import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;\n import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;\n-import org.apache.lucene.analysis.tokenattributes.TypeAttribute;\n import org.apache.lucene.search.suggest.analyzing.XAnalyzingSuggester;\n import org.apache.lucene.util.BytesRef;\n import org.apache.lucene.util.CharsRef;\n@@ -50,13 +48,16 @@ public class CompletionTokenStreamTest extends ElasticsearchTokenStreamTestCase\n     public void testSuggestTokenFilter() throws Exception {\n         TokenStream tokenStream = new MockTokenizer(new StringReader(\"mykeyword\"), MockTokenizer.WHITESPACE, true);\n         BytesRef payload = new BytesRef(\"Surface keyword|friggin payload|10\");\n-        TokenStream suggestTokenStream = new ByteTermAttrToCharTermAttrFilter(new CompletionTokenStream(tokenStream, payload, new CompletionTokenStream.ToFiniteStrings() {\n+        TokenStream suggestTokenStream = new CompletionTokenStream(tokenStream, payload, new CompletionTokenStream.ToFiniteStrings() {\n             @Override\n             public Set<IntsRef> toFiniteStrings(TokenStream stream) throws IOException {\n                 return suggester.toFiniteStrings(suggester.getTokenStreamToAutomaton(), stream);\n             }\n-        }));\n-        assertTokenStreamContents(suggestTokenStream, new String[] {\"mykeyword\"}, null, null, new String[] {\"Surface keyword|friggin payload|10\"}, new int[] { 1 }, null, null);\n+        });\n+        assertCharTermAndPayloads(suggestTokenStream,\n+                new String[] {\"mykeyword\"},\n+                new BytesRef[] {payload},\n+                new int[] { 1 });\n     }\n \n     @Test\n@@ -68,13 +69,16 @@ public class CompletionTokenStreamTest extends ElasticsearchTokenStreamTestCase\n         SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n \n         BytesRef payload = new BytesRef(\"Surface keyword|friggin payload|10\");\n-        TokenStream suggestTokenStream = new ByteTermAttrToCharTermAttrFilter(new CompletionTokenStream(filter, payload, new CompletionTokenStream.ToFiniteStrings() {\n+        TokenStream suggestTokenStream = new CompletionTokenStream(filter, payload, new CompletionTokenStream.ToFiniteStrings() {\n             @Override\n             public Set<IntsRef> toFiniteStrings(TokenStream stream) throws IOException {\n                 return suggester.toFiniteStrings(suggester.getTokenStreamToAutomaton(), stream);\n             }\n-        }));\n-        assertTokenStreamContents(suggestTokenStream, new String[] {\"mysynonym\", \"mykeyword\"}, null, null, new String[] {\"Surface keyword|friggin payload|10\", \"Surface keyword|friggin payload|10\"}, new int[] { 2, 0 }, null, null);\n+        });\n+        assertCharTermAndPayloads(suggestTokenStream,\n+                new String[] {\"mysynonym\", \"mykeyword\"},\n+                new BytesRef[] {payload, payload},\n+                new int[] { 2, 0 });\n     }\n \n     @Test\n@@ -143,27 +147,23 @@ public class CompletionTokenStreamTest extends ElasticsearchTokenStreamTestCase\n         suggestTokenStream.close();\n \n     }\n-    \n-    public final static class ByteTermAttrToCharTermAttrFilter extends TokenFilter {\n-        private CharTermAttribute attr = addAttribute(CharTermAttribute.class);\n-        private ByteTermAttribute byteAttr = addAttribute(ByteTermAttribute.class);\n-        private PayloadAttribute payload = addAttribute(PayloadAttribute.class);\n-        private TypeAttribute type = addAttribute(TypeAttribute.class);\n-        protected ByteTermAttrToCharTermAttrFilter(TokenStream input) {\n-            super(input);\n-        }\n+    private void assertCharTermAndPayloads(TokenStream stream, String[] expectedTerms, BytesRef[] expectedPayloads, int[] expectedPosIncrements) throws IOException {\n+        assertEquals(expectedTerms.length, expectedPayloads.length);\n+        assertEquals(expectedTerms.length, expectedPosIncrements.length);\n \n-        @Override\n-        public boolean incrementToken() throws IOException {\n-            if (input.incrementToken()) {\n-                BytesRef bytesRef = byteAttr.getBytesRef();\n-                attr.append(bytesRef.utf8ToString());\n-                // we move them over so we can assert them more easily in the tests\n-                type.setType(payload.getPayload().utf8ToString()); \n-                return true;\n-            }\n-            return false;\n+        CharTermAttribute termAttr = stream.addAttribute(CharTermAttribute.class);\n+        PayloadAttribute payloadAttr = stream.addAttribute(PayloadAttribute.class);\n+        PositionIncrementAttribute posAttr = stream.addAttribute(PositionIncrementAttribute.class);\n+\n+        stream.reset();\n+        for (int i = 0; i < expectedTerms.length; i++) {\n+            assertTrue(stream.incrementToken());\n+            assertEquals(expectedTerms[i], termAttr.toString());\n+            assertEquals(expectedPayloads[i], payloadAttr.getPayload());\n+            assertEquals(expectedPosIncrements[i], posAttr.getPositionIncrement());\n         }\n-        \n+        assertFalse(stream.incrementToken());\n+        stream.end();\n+        stream.close();\n     }\n }",
  "logs_path": "codex/gpt-5.1-codex/b8978668/elastic_elasticsearch_pr4129/logs.jsonl",
  "errors": [],
  "edit_run_id": "fd5b3480",
  "test_label": "v1-agent-comparison"
}