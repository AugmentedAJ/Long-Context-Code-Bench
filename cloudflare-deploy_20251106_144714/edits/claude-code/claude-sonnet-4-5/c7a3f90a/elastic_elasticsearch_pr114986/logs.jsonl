{"timestamp": 1761868866.891238, "event": "agent_start", "runner": "claude-code", "model": "claude-sonnet-4-5", "command": ["claude", "-p", "You are working on a codebase. Your task is to make the necessary code changes to accomplish the following:\n\n[DOCS] Updates adaptive allocations reference docs\n\n## Overview\r\n\r\nAdaptive allocations can scale down to `0` allocations. This PR removes a sentence that stated that it is not possible.\n\nPlease make all necessary code changes to complete this task.", "--output-format", "stream-json", "--verbose", "--model", "claude-sonnet-4-5", "--allowedTools", "Edit Bash(git:*)"], "workspace": "/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace", "timeout_s": 1200}
{"timestamp": 1761868866.891263, "event": "auth_info", "auth_mode": "auto", "used_auth": "subscription", "anthropic_api_key_present": false}
{"timestamp": 1761868916.8229692, "event": "agent_run", "stdout": "{\"type\":\"system\",\"subtype\":\"init\",\"cwd\":\"/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace\",\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"tools\":[\"Task\",\"Bash\",\"Glob\",\"Grep\",\"ExitPlanMode\",\"Read\",\"Edit\",\"Write\",\"NotebookEdit\",\"WebFetch\",\"TodoWrite\",\"WebSearch\",\"BashOutput\",\"KillShell\",\"Skill\",\"SlashCommand\"],\"mcp_servers\":[],\"model\":\"claude-sonnet-4-5\",\"permissionMode\":\"default\",\"slash_commands\":[\"compact\",\"context\",\"cost\",\"init\",\"output-style:new\",\"pr-comments\",\"release-notes\",\"todos\",\"review\",\"security-review\"],\"apiKeySource\":\"none\",\"claude_code_version\":\"2.0.29\",\"output_style\":\"default\",\"agents\":[\"general-purpose\",\"statusline-setup\",\"output-style-setup\",\"Explore\",\"Plan\"],\"skills\":[],\"plugins\":[],\"uuid\":\"5a722412-c349-43f5-8c6e-760986ed3b43\"}\n{\"type\":\"assistant\",\"message\":{\"model\":\"claude-sonnet-4-5-20250929\",\"id\":\"msg_01FidY4xx9JWb1VurGVpTQjz\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[{\"type\":\"text\",\"text\":\"I'll help you update the documentation about adaptive allocations. Let me start by searching for the relevant documentation files.\"}],\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":2,\"cache_creation_input_tokens\":2668,\"cache_read_input_tokens\":12441,\"cache_creation\":{\"ephemeral_5m_input_tokens\":2668,\"ephemeral_1h_input_tokens\":0},\"output_tokens\":5,\"service_tier\":\"standard\"}},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"6a4e8ecb-6fa4-485c-bf9c-2ab276596666\"}\n{\"type\":\"assistant\",\"message\":{\"model\":\"claude-sonnet-4-5-20250929\",\"id\":\"msg_01FidY4xx9JWb1VurGVpTQjz\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[{\"type\":\"tool_use\",\"id\":\"toolu_016WAZGUEbBDAoU7kHDLpNzw\",\"name\":\"Grep\",\"input\":{\"pattern\":\"adaptive allocations\",\"output_mode\":\"files_with_matches\",\"-i\":true}}],\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":2,\"cache_creation_input_tokens\":2668,\"cache_read_input_tokens\":12441,\"cache_creation\":{\"ephemeral_5m_input_tokens\":2668,\"ephemeral_1h_input_tokens\":0},\"output_tokens\":5,\"service_tier\":\"standard\"}},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"7ae982f7-948e-478f-8e06-a950121bb9fb\"}\n{\"type\":\"assistant\",\"message\":{\"model\":\"claude-sonnet-4-5-20250929\",\"id\":\"msg_01FidY4xx9JWb1VurGVpTQjz\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[{\"type\":\"tool_use\",\"id\":\"toolu_01WKxspaL8QN8nBHCGvgrfWL\",\"name\":\"Grep\",\"input\":{\"pattern\":\"scale down to 0|scale down to zero|cannot scale to 0|cannot scale to zero\",\"output_mode\":\"files_with_matches\",\"-i\":true}}],\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":2,\"cache_creation_input_tokens\":2668,\"cache_read_input_tokens\":12441,\"cache_creation\":{\"ephemeral_5m_input_tokens\":2668,\"ephemeral_1h_input_tokens\":0},\"output_tokens\":5,\"service_tier\":\"standard\"}},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"ce5f9e08-dd3f-435e-8301-9fcff6a7d1db\"}\n{\"type\":\"assistant\",\"message\":{\"model\":\"claude-sonnet-4-5-20250929\",\"id\":\"msg_01FidY4xx9JWb1VurGVpTQjz\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[{\"type\":\"tool_use\",\"id\":\"toolu_01NRsTX6e4k2bVvA1F83bQ54\",\"name\":\"Glob\",\"input\":{\"pattern\":\"**/*adaptive*.md\"}}],\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":2,\"cache_creation_input_tokens\":2668,\"cache_read_input_tokens\":12441,\"cache_creation\":{\"ephemeral_5m_input_tokens\":2668,\"ephemeral_1h_input_tokens\":0},\"output_tokens\":5,\"service_tier\":\"standard\"}},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"1e00a628-5e6e-4498-9b66-23d9c55e7c52\"}\n{\"type\":\"assistant\",\"message\":{\"model\":\"claude-sonnet-4-5-20250929\",\"id\":\"msg_01FidY4xx9JWb1VurGVpTQjz\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[{\"type\":\"tool_use\",\"id\":\"toolu_01JBs3H2K7rfQNejEkoQXdui\",\"name\":\"Glob\",\"input\":{\"pattern\":\"**/docs/**/*.md\"}}],\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":2,\"cache_creation_input_tokens\":2668,\"cache_read_input_tokens\":12441,\"cache_creation\":{\"ephemeral_5m_input_tokens\":2668,\"ephemeral_1h_input_tokens\":0},\"output_tokens\":5,\"service_tier\":\"standard\"}},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"34d69ec4-70fa-46fc-8768-b75019a717e0\"}\n{\"type\":\"user\",\"message\":{\"role\":\"user\",\"content\":[{\"tool_use_id\":\"toolu_01WKxspaL8QN8nBHCGvgrfWL\",\"type\":\"tool_result\",\"content\":\"Found 2 files\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/inference/adaptiveallocations/AdaptiveAllocationsScalerTests.java\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/autoscaling/MlMemoryAutoscalingDecider.java\"}]},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"7e341e60-3bda-4c5e-aca2-080e640ae662\"}\n{\"type\":\"user\",\"message\":{\"role\":\"user\",\"content\":[{\"tool_use_id\":\"toolu_016WAZGUEbBDAoU7kHDLpNzw\",\"type\":\"tool_result\",\"content\":\"Found 14 files\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/inference/adaptiveallocations/AdaptiveAllocationsScalerServiceTests.java\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/assignment/TrainedModelAssignmentClusterService.java\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/adaptiveallocations/AdaptiveAllocationsScalerService.java\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/adaptiveallocations/AdaptiveAllocationsScaler.java\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/assignment/TrainedModelAssignment.java\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/action/UpdateTrainedModelDeploymentAction.java\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/action/StartTrainedModelDeploymentAction.java\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/search/search-your-data/semantic-text-hybrid-search\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/search/search-your-data/semantic-search-semantic-text.asciidoc\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/trained-models/apis/update-trained-model-deployment.asciidoc\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/ml-shared.asciidoc\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/inference/service-elser.asciidoc\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/changelog/110630.yaml\"}]},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"e3dd650a-488d-4736-ba9a-bda0f3e7d78f\"}\n{\"type\":\"user\",\"message\":{\"role\":\"user\",\"content\":[{\"tool_use_id\":\"toolu_01NRsTX6e4k2bVvA1F83bQ54\",\"type\":\"tool_result\",\"content\":\"No files found\"}]},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"1bcd74cd-7348-44ed-922a-753fdd30954a\"}\n{\"type\":\"user\",\"message\":{\"role\":\"user\",\"content\":[{\"tool_use_id\":\"toolu_01JBs3H2K7rfQNejEkoQXdui\",\"type\":\"tool_result\",\"content\":\"/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/internal/DistributedArchitectureGuide.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/internal/GeneralArchitectureGuide.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/internal/Versioning.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/README.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/abs.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/acos.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/add.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/asin.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/atan.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/atan2.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/avg.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/bucket.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/case.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/categorize.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/cbrt.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/ceil.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/cidr_match.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/coalesce.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/concat.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/cos.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/cosh.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/count.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/count_distinct.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/date_diff.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/date_extract.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/date_format.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/date_parse.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/date_trunc.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/div.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/e.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/ends_with.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/equals.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/exp.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/floor.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/from_base64.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/greater_than.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/greater_than_or_equal.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/greatest.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/hypot.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/in.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/ip_prefix.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/least.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/left.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/length.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/less_than.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/less_than_or_equal.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/like.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/locate.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/log.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/log10.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/ltrim.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/match.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/max.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/median.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/median_absolute_deviation.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/min.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/mod.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/mul.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/mv_append.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/mv_avg.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/mv_concat.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/mv_count.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/mv_dedupe.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/mv_first.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/mv_last.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/mv_max.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/mv_median.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/mv_median_absolute_deviation.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/mv_min.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/mv_percentile.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/mv_pseries_weighted_sum.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/mv_slice.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/mv_sort.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/mv_sum.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/mv_zip.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/neg.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/not_equals.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/now.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/percentile.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/pi.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/pow.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/qstr.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/repeat.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/replace.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/reverse.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/right.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/rlike.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/round.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/rtrim.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/signum.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/sin.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/sinh.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/space.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/split.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/sqrt.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/st_centroid_agg.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/st_contains.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/st_disjoint.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/st_distance.md\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/functions/kibana/docs/st_intersects.md\\n(Results are truncated. Consider using a more specific path or pattern.)\"}]},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"450929ff-ab28-4b35-8169-8a6c4b7533be\"}\n{\"type\":\"assistant\",\"message\":{\"model\":\"claude-sonnet-4-5-20250929\",\"id\":\"msg_012NE2hKfQ9HQaEsB8zUmX6i\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[{\"type\":\"text\",\"text\":\"Let me search more specifically for documentation files that mention adaptive allocations:\"}],\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":6,\"cache_creation_input_tokens\":8522,\"cache_read_input_tokens\":15109,\"cache_creation\":{\"ephemeral_5m_input_tokens\":8522,\"ephemeral_1h_input_tokens\":0},\"output_tokens\":3,\"service_tier\":\"standard\"}},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"0ab7a337-5f96-4c72-8623-a82aa02e20d9\"}\n{\"type\":\"assistant\",\"message\":{\"model\":\"claude-sonnet-4-5-20250929\",\"id\":\"msg_012NE2hKfQ9HQaEsB8zUmX6i\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[{\"type\":\"tool_use\",\"id\":\"toolu_01M7CAZaLqgXxw8MBktXn1tN\",\"name\":\"Read\",\"input\":{\"file_path\":\"/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/ml-shared.asciidoc\"}}],\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":6,\"cache_creation_input_tokens\":8522,\"cache_read_input_tokens\":15109,\"cache_creation\":{\"ephemeral_5m_input_tokens\":8522,\"ephemeral_1h_input_tokens\":0},\"output_tokens\":3,\"service_tier\":\"standard\"}},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"3d23452e-a330-4bd9-9dbc-6f9df2c4e109\"}\n{\"type\":\"assistant\",\"message\":{\"model\":\"claude-sonnet-4-5-20250929\",\"id\":\"msg_012NE2hKfQ9HQaEsB8zUmX6i\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[{\"type\":\"tool_use\",\"id\":\"toolu_01Aza3SHd4U19YoSV6iUA4X1\",\"name\":\"Grep\",\"input\":{\"pattern\":\"not possible|cannot.*0|can't.*0|unable to.*0\",\"output_mode\":\"content\",\"-i\":true,\"path\":\"/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs\",\"-n\":true,\"-C\":2}}],\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":6,\"cache_creation_input_tokens\":8522,\"cache_read_input_tokens\":15109,\"cache_creation\":{\"ephemeral_5m_input_tokens\":8522,\"ephemeral_1h_input_tokens\":0},\"output_tokens\":3,\"service_tier\":\"standard\"}},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"05f9f366-8c21-43cd-8f2b-4a8d86fd2fcf\"}\n{\"type\":\"user\",\"message\":{\"role\":\"user\",\"content\":[{\"tool_use_id\":\"toolu_01Aza3SHd4U19YoSV6iUA4X1\",\"type\":\"tool_result\",\"content\":\"/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/resiliency/index.asciidoc-126-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/resiliency/index.asciidoc-127-[discrete]\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/resiliency/index.asciidoc:128:=== Documents indexed during a network partition cannot be uniquely identified (STATUS: DONE, v7.0.0)\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/resiliency/index.asciidoc-129-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/resiliency/index.asciidoc-130-When a primary has been partitioned away from the cluster there is a short\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/resiliency/index.asciidoc-260-believes itself to be the active primary. This means that an index request that gets routed to the new primary does not get replicated to\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/resiliency/index.asciidoc-261-the old primary (as it has been deactivated from point of view of the new primary). If a subsequent read request gets routed to the old\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/resiliency/index.asciidoc:262:primary, it cannot see the indexed document. {GIT}15900[#15900]\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/resiliency/index.asciidoc-263-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/resiliency/index.asciidoc-264-In the reverse situation where a cluster state update that completes primary relocation is first applied on the relocation source and then\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/runtime.asciidoc-826-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/runtime.asciidoc-827-NOTE: Fields that are retrieved by runtime fields of type `lookup` can be used\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/runtime.asciidoc:828:to enrich the hits in a search response. It's not possible to query or aggregate\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/runtime.asciidoc-829-on these fields.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/runtime.asciidoc-830-\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/data-streams/downsampling-manual.asciidoc-33-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/data-streams/downsampling-manual.asciidoc-34-* Refer to the <<tsds-prereqs,TSDS prerequisites>>.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/data-streams/downsampling-manual.asciidoc:35:* It is not possible to downsample a <<data-streams,data stream>> directly, nor\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/data-streams/downsampling-manual.asciidoc-36-multiple indices at once. It's only possible to downsample one time series index\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/data-streams/downsampling-manual.asciidoc-37-(TSDS backing index).\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/sql/functions/type-conversion.asciidoc-20-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/sql/functions/type-conversion.asciidoc-21-*Description*: Casts the result of the given expression to the target <<sql-data-types, data type>>.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/sql/functions/type-conversion.asciidoc:22:If the cast is not possible (for example because of target type is too narrow or because\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/sql/functions/type-conversion.asciidoc-23-the value itself cannot be converted), the query fails.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/sql/functions/type-conversion.asciidoc-24-\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/painless/painless-lang-spec/painless-casting.asciidoc-108-+\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/painless/painless-lang-spec/painless-casting.asciidoc-109-<1> declare `int i`;\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/painless/painless-lang-spec/painless-casting.asciidoc:110:    *error* -> cannot implicit cast `double 1.0` to `int 1`;\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/painless/painless-lang-spec/painless-casting.asciidoc-111-    (note an explicit cast is valid)\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/painless/painless-lang-spec/painless-casting.asciidoc-112-<2> declare `int b`;\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/processors/geoip.asciidoc-28-license key, see <<put-geoip-database-api>>.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/processors/geoip.asciidoc-29-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/processors/geoip.asciidoc:30:If {es} can't connect to the endpoint for 30 days all updated databases will become\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/processors/geoip.asciidoc-31-invalid. {es} will stop enriching documents with geoip data and will add `tags: [\\\"_geoip_expired_database\\\"]`\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/processors/geoip.asciidoc-32-field instead.\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/settings/inference-settings.asciidoc-45-the internal connection pool. If this setting is set to a value equal to or greater than\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/settings/inference-settings.asciidoc-46-`xpack.inference.http.max_total_connections`, then a single third party service could lease all available\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/settings/inference-settings.asciidoc:47:connections and other third party services would be unable to lease connections. Defaults to `20`.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/settings/inference-settings.asciidoc-48-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/settings/inference-settings.asciidoc-49-`xpack.inference.http.connection_eviction_interval`::\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/sql/limitations.asciidoc-208-=== Aggregations in the <<sql-syntax-pivot, `PIVOT`>> clause\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/sql/limitations.asciidoc-209-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/sql/limitations.asciidoc:210:The aggregation expression in <<sql-syntax-pivot, `PIVOT`>> will currently accept only one aggregation. It is thus not possible to obtain multiple aggregations for any one pivoted column.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/sql/limitations.asciidoc-211-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/sql/limitations.asciidoc-212-[discrete]\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/processors/reroute.asciidoc-20-See <<reroute-options>> for more details.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/processors/reroute.asciidoc-21-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/processors/reroute.asciidoc:22:NOTE: It's not possible to change the `type` of the data stream with the `reroute` processor.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/processors/reroute.asciidoc-23-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/processors/reroute.asciidoc-24-After a `reroute` processor has been executed, all the other processors of the current pipeline are skipped, including the final pipeline.\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/processors/reroute.asciidoc-46-| Name          | Required  | Default                      | Description\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/processors/reroute.asciidoc-47-| `destination` | no        | -                            | A static value for the target. Can't be set when the `dataset` or `namespace` option is set.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/processors/reroute.asciidoc:48:| `dataset`     | no        | `{{data_stream.dataset}}`   a| Field references or a static value for the dataset part of the data stream name. In addition to the criteria for <<indices-create-api-path-params, index names>>, cannot contain `-` and must be no longer than 100 characters. Example values are `nginx.access` and `nginx.error`.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/processors/reroute.asciidoc-49-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/processors/reroute.asciidoc-50-Supports field references with a mustache-like syntax (denoted as `{{double}}` or `{{{triple}}}` curly braces). When resolving field references, the processor replaces invalid characters with `_`. Uses the `<dataset>` part of the index name as a fallback if all field references resolve to a `null`, missing, or non-string value.\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/search-inference-processing.asciidoc-71-First, you need to figure out which model works best for your data.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/search-inference-processing.asciidoc-72-Make sure to use a {ml-docs}/ml-nlp-model-ref.html[compatible third party NLP model^].\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/search-inference-processing.asciidoc:73:Since these are publicly available, it is not possible to fine-tune models before {ml-docs}/ml-nlp-deploy-models.html[deploying them^].\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/search-inference-processing.asciidoc-74-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ingest/search-inference-processing.asciidoc-75-Trained models must be available in the current {kibana-ref}/xpack-spaces.html[Kibana Space^] and running in order to use them.\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/sql/endpoints/odbc/installation.asciidoc-20-If you fail to meet any of the prerequisites the installer will show an error message and abort the installation.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/sql/endpoints/odbc/installation.asciidoc-21-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/sql/endpoints/odbc/installation.asciidoc:22:NOTE: It is not possible to inline upgrade using the MSI. In order to upgrade, you will first have to uninstall the old driver and then install the new driver.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/sql/endpoints/odbc/installation.asciidoc-23-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/sql/endpoints/odbc/installation.asciidoc-24-NOTE: When installing the MSI, the Windows Defender SmartScreen might warn\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/flattened.asciidoc-108-- `exists`\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/flattened.asciidoc-109-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/flattened.asciidoc:110:When querying, it is not possible to refer to field keys using wildcards, as in\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/flattened.asciidoc-111-`{ \\\"term\\\": {\\\"labels.time*\\\": 1541457010}}`. Note that all queries, including\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/flattened.asciidoc-112-`range`, treat the values as string keywords. Highlighting is not supported on\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/flattened.asciidoc-119-lexicographically.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/flattened.asciidoc-120-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/flattened.asciidoc:121:Flattened object fields currently cannot be stored. It is not possible to\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/flattened.asciidoc-122-specify the <<mapping-store, `store`>> parameter in the mapping.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/flattened.asciidoc-123-\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/health/health.asciidoc-342-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/health/health.asciidoc-343-`unknown_nodes`::\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/health/health.asciidoc:344:(int) The number of nodes for which it was not possible to determine their disk health.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/health/health.asciidoc-345-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/health/health.asciidoc-346-[[health-api-response-details-repository-integrity]]\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/docs/reindex.asciidoc-1126-specified in the `elasticsearch.yml` file, with the exception of the\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/docs/reindex.asciidoc-1127-secure settings, which you add in the Elasticsearch keystore.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/docs/reindex.asciidoc:1128:It is not possible to configure SSL in the body of the `_reindex` request.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/docs/reindex.asciidoc-1129-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/docs/reindex.asciidoc-1130-The following settings are supported:\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/dense-vector.asciidoc-47-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/dense-vector.asciidoc-48-NOTE: Unlike most other data types, dense vectors are always single-valued.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/dense-vector.asciidoc:49:It is not possible to store multiple values in one `dense_vector` field.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/dense-vector.asciidoc-50-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/dense-vector.asciidoc-51-[[index-vectors-knn-search]]\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/dense-vector.asciidoc-230-`dims`::\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/dense-vector.asciidoc-231-(Optional, integer)\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/dense-vector.asciidoc:232:Number of vector dimensions. Can't exceed `4096`. If `dims` is not specified,\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/dense-vector.asciidoc-233-it will be set to the length of the first vector added to the field.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/dense-vector.asciidoc-234-\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/searchable-snapshots/index.asciidoc-314-{search-snap} indices whose original index snapshot is unavailable.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/searchable-snapshots/index.asciidoc-315-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/searchable-snapshots/index.asciidoc:316:Because {search-snap} indices are not regular indices, it is not possible to use\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/searchable-snapshots/index.asciidoc-317-a <<snapshots-source-only-repository,source-only repository>> to take snapshots\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/searchable-snapshots/index.asciidoc-318-of {search-snap} indices.\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/snapshot-restore/index.asciidoc-120-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/snapshot-restore/index.asciidoc-121-You can't restore a snapshot to an earlier version of {es}. For example, you\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/snapshot-restore/index.asciidoc:122:can't restore a snapshot taken in 7.6.0 to a cluster running 7.5.0.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/snapshot-restore/index.asciidoc-123-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/snapshot-restore/index.asciidoc-124-ifeval::[\\\"{release-state}\\\"!=\\\"released\\\"]\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/alias.asciidoc-67-  * If nested objects are defined, a field alias must have the same nested scope as its target.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/types/alias.asciidoc-68-\\n/private/var/folders/1t/tn_3\\n\\n... [682 lines truncated] ...\"}]},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"c5ce327e-b35b-4b79-8b6a-8ea35f019af9\"}\n{\"type\":\"user\",\"message\":{\"role\":\"user\",\"content\":[{\"tool_use_id\":\"toolu_01M7CAZaLqgXxw8MBktXn1tN\",\"type\":\"tool_result\",\"content\":\"     1\u2192tag::adaptive-allocation[]\\n     2\u2192Adaptive allocations configuration object.\\n     3\u2192If enabled, the number of allocations of the model is set based on the current load the process gets.\\n     4\u2192When the load is high, a new model allocation is automatically created (respecting the value of `max_number_of_allocations` if it's set).\\n     5\u2192When the load is low, a model allocation is automatically removed (respecting the value of `min_number_of_allocations` if it's set).\\n     6\u2192The number of model allocations cannot be scaled down to less than `1` this way.\\n     7\u2192If `adaptive_allocations` is enabled, do not set the number of allocations manually.\\n     8\u2192end::adaptive-allocation[]\\n     9\u2192\\n    10\u2192tag::adaptive-allocation-enabled[]\\n    11\u2192If `true`, `adaptive_allocations` is enabled.\\n    12\u2192Defaults to `false`.\\n    13\u2192end::adaptive-allocation-enabled[]\\n    14\u2192\\n    15\u2192tag::adaptive-allocation-max-number[]\\n    16\u2192Specifies the maximum number of allocations to scale to.\\n    17\u2192If set, it must be greater than or equal to `min_number_of_allocations`.\\n    18\u2192end::adaptive-allocation-max-number[]\\n    19\u2192\\n    20\u2192tag::adaptive-allocation-min-number[]\\n    21\u2192Specifies the minimum number of allocations to scale to.\\n    22\u2192If set, it must be greater than or equal to `1`.\\n    23\u2192end::adaptive-allocation-min-number[]\\n    24\u2192\\n    25\u2192tag::aggregations[]\\n    26\u2192If set, the {dfeed} performs aggregation searches. Support for aggregations is\\n    27\u2192limited and should be used only with low cardinality data. For more information,\\n    28\u2192see\\n    29\u2192{ml-docs}/ml-configuring-aggregation.html[Aggregating data for faster performance].\\n    30\u2192end::aggregations[]\\n    31\u2192\\n    32\u2192tag::allow-lazy-open[]\\n    33\u2192Advanced configuration option. Specifies whether this job can open when there is\\n    34\u2192insufficient {ml} node capacity for it to be immediately assigned to a node. The\\n    35\u2192default value is `false`; if a {ml} node with capacity to run the job cannot\\n    36\u2192immediately be found, the <<ml-open-job,open {anomaly-jobs} API>> returns an\\n    37\u2192error. However, this is also subject to the cluster-wide\\n    38\u2192`xpack.ml.max_lazy_ml_nodes` setting; see <<advanced-ml-settings>>. If this\\n    39\u2192option is set to `true`, the <<ml-open-job,open {anomaly-jobs} API>> does not\\n    40\u2192return an error and the job waits in the `opening` state until sufficient {ml}\\n    41\u2192node capacity is available.\\n    42\u2192end::allow-lazy-open[]\\n    43\u2192\\n    44\u2192tag::allow-no-match-datafeeds[]\\n    45\u2192Specifies what to do when the request:\\n    46\u2192+\\n    47\u2192--\\n    48\u2192* Contains wildcard expressions and there are no {dfeeds} that match.\\n    49\u2192* Contains the `_all` string or no identifiers and there are no matches.\\n    50\u2192* Contains wildcard expressions and there are only partial matches.\\n    51\u2192\\n    52\u2192The default value is `true`, which returns an empty `datafeeds` array when\\n    53\u2192there are no matches and the subset of results when there are partial matches.\\n    54\u2192If this parameter is `false`, the request returns a `404` status code when there\\n    55\u2192are no matches or only partial matches.\\n    56\u2192--\\n    57\u2192end::allow-no-match-datafeeds[]\\n    58\u2192\\n    59\u2192tag::allow-no-match-deployments[]\\n    60\u2192Specifies what to do when the request:\\n    61\u2192+\\n    62\u2192--\\n    63\u2192* Contains wildcard expressions and there are no deployments that match.\\n    64\u2192* Contains the `_all` string or no identifiers and there are no matches.\\n    65\u2192* Contains wildcard expressions and there are only partial matches.\\n    66\u2192\\n    67\u2192The default value is `true`, which returns an empty array when there are no\\n    68\u2192matches and the subset of results when there are partial matches. If this\\n    69\u2192parameter is `false`, the request returns a `404` status code when there are no\\n    70\u2192matches or only partial matches.\\n    71\u2192--\\n    72\u2192end::allow-no-match-deployments[]\\n    73\u2192\\n    74\u2192tag::allow-no-match-dfa-jobs[]\\n    75\u2192 Specifies what to do when the request:\\n    76\u2192+\\n    77\u2192--\\n    78\u2192* Contains wildcard expressions and there are no {dfanalytics-jobs} that match.\\n    79\u2192* Contains the `_all` string or no identifiers and there are no matches.\\n    80\u2192* Contains wildcard expressions and there are only partial matches.\\n    81\u2192\\n    82\u2192The default value is `true`, which returns an empty `data_frame_analytics` array\\n    83\u2192when there are no matches and the subset of results when there are partial\\n    84\u2192matches. If this parameter is `false`, the request returns a `404` status code\\n    85\u2192when there are no matches or only partial matches.\\n    86\u2192--\\n    87\u2192end::allow-no-match-dfa-jobs[]\\n    88\u2192\\n    89\u2192tag::allow-no-match-jobs[]\\n    90\u2192Specifies what to do when the request:\\n    91\u2192+\\n    92\u2192--\\n    93\u2192* Contains wildcard expressions and there are no jobs that match.\\n    94\u2192* Contains the `_all` string or no identifiers and there are no matches.\\n    95\u2192* Contains wildcard expressions and there are only partial matches.\\n    96\u2192\\n    97\u2192The default value is `true`, which returns an empty `jobs` array\\n    98\u2192when there are no matches and the subset of results when there are partial\\n    99\u2192matches. If this parameter is `false`, the request returns a `404` status code\\n   100\u2192when there are no matches or only partial matches.\\n   101\u2192--\\n   102\u2192end::allow-no-match-jobs[]\\n   103\u2192\\n   104\u2192tag::allow-no-match-models[]\\n   105\u2192Specifies what to do when the request:\\n   106\u2192+\\n   107\u2192--\\n   108\u2192* Contains wildcard expressions and there are no models that match.\\n   109\u2192* Contains the `_all` string or no identifiers and there are no matches.\\n   110\u2192* Contains wildcard expressions and there are only partial matches.\\n   111\u2192\\n   112\u2192The default value is `true`, which returns an empty array when there are no\\n   113\u2192matches and the subset of results when there are partial matches. If this\\n   114\u2192parameter is `false`, the request returns a `404` status code when there are no\\n   115\u2192matches or only partial matches.\\n   116\u2192--\\n   117\u2192end::allow-no-match-models[]\\n   118\u2192\\n   119\u2192tag::analysis[]\\n   120\u2192Defines the type of {dfanalytics} you want to perform on your source index. For\\n   121\u2192example: `outlier_detection`. See <<ml-dfa-analysis-objects>>.\\n   122\u2192end::analysis[]\\n   123\u2192\\n   124\u2192tag::analysis-config[]\\n   125\u2192The analysis configuration, which specifies how to analyze the data. After you\\n   126\u2192create a job, you cannot change the analysis configuration; all the properties\\n   127\u2192are informational.\\n   128\u2192end::analysis-config[]\\n   129\u2192\\n   130\u2192tag::analysis-limits[]\\n   131\u2192Limits can be applied for the resources required to hold the mathematical models\\n   132\u2192in memory. These limits are approximate and can be set per job. They do not\\n   133\u2192control the memory used by other processes, for example the {es} Java processes.\\n   134\u2192end::analysis-limits[]\\n   135\u2192\\n   136\u2192tag::assignment-explanation-anomaly-jobs[]\\n   137\u2192For open {anomaly-jobs} only, contains messages relating to the selection\\n   138\u2192of a node to run the job.\\n   139\u2192end::assignment-explanation-anomaly-jobs[]\\n   140\u2192\\n   141\u2192tag::assignment-explanation-datafeeds[]\\n   142\u2192For started {dfeeds} only, contains messages relating to the selection of a\\n   143\u2192node.\\n   144\u2192end::assignment-explanation-datafeeds[]\\n   145\u2192\\n   146\u2192tag::assignment-explanation-dfanalytics[]\\n   147\u2192Contains messages relating to the selection of a node.\\n   148\u2192end::assignment-explanation-dfanalytics[]\\n   149\u2192\\n   150\u2192tag::assignment-memory-basis[]\\n   151\u2192Indicates where to find the memory requirement that is used to decide where the\\n   152\u2192job runs. The possible values are:\\n   153\u2192+\\n   154\u2192--\\n   155\u2192* `model_memory_limit`: The job's memory requirement is calculated on the basis\\n   156\u2192that its model memory will grow to the `model_memory_limit` specified in the\\n   157\u2192`analysis_limits` of its config.\\n   158\u2192* `current_model_bytes`: The job's memory requirement is calculated on the basis\\n   159\u2192that its current model memory size is a good reflection of what it will be in\\n   160\u2192the future.\\n   161\u2192* `peak_model_bytes`: The job's memory requirement is calculated on the basis\\n   162\u2192that its peak model memory size is a good reflection of what the model size will\\n   163\u2192be in the future.\\n   164\u2192--\\n   165\u2192end::assignment-memory-basis[]\\n   166\u2192\\n   167\u2192tag::background-persist-interval[]\\n   168\u2192Advanced configuration option. The time between each periodic persistence of the\\n   169\u2192model. The default value is a randomized value between 3 to 4 hours, which\\n   170\u2192avoids all jobs persisting at exactly the same time. The smallest allowed value\\n   171\u2192is 1 hour.\\n   172\u2192+\\n   173\u2192--\\n   174\u2192TIP: For very large models (several GB), persistence could take 10-20 minutes,\\n   175\u2192so do not set the `background_persist_interval` value too low.\\n   176\u2192\\n   177\u2192--\\n   178\u2192end::background-persist-interval[]\\n   179\u2192\\n   180\u2192tag::bucket-allocation-failures-count[]\\n   181\u2192The number of buckets for which new entities in incoming data were not processed\\n   182\u2192due to insufficient model memory. This situation is also signified by a\\n   183\u2192`hard_limit: memory_status` property value.\\n   184\u2192end::bucket-allocation-failures-count[]\\n   185\u2192\\n   186\u2192tag::bucket-count[]\\n   187\u2192The number of buckets processed.\\n   188\u2192end::bucket-count[]\\n   189\u2192\\n   190\u2192tag::bucket-count-anomaly-jobs[]\\n   191\u2192The number of bucket results produced by the job.\\n   192\u2192end::bucket-count-anomaly-jobs[]\\n   193\u2192\\n   194\u2192tag::bucket-span[]\\n   195\u2192The size of the interval that the analysis is aggregated into, typically between\\n   196\u2192`5m` and `1h`. This value should be either a whole number of days or equate to a\\n   197\u2192whole number of buckets in one day;\\n   198\u2192deprecated:[8.1, Values that do not meet these recommendations are deprecated and will be disallowed in a future version].\\n   199\u2192If the {anomaly-job} uses a {dfeed} with\\n   200\u2192{ml-docs}/ml-configuring-aggregation.html[aggregations], this value must also be\\n   201\u2192divisible by the interval of the date histogram aggregation. The default value\\n   202\u2192is `5m`. For more information, see\\n   203\u2192{ml-docs}/ml-ad-run-jobs.html#ml-ad-bucket-span[Bucket span].\\n   204\u2192end::bucket-span[]\\n   205\u2192\\n   206\u2192tag::bucket-span-results[]\\n   207\u2192The length of the bucket in seconds. This value matches the `bucket_span`\\n   208\u2192that is specified in the job.\\n   209\u2192end::bucket-span-results[]\\n   210\u2192\\n   211\u2192tag::bucket-time-exponential-average[]\\n   212\u2192Exponential moving average of all bucket processing times, in milliseconds.\\n   213\u2192end::bucket-time-exponential-average[]\\n   214\u2192\\n   215\u2192tag::bucket-time-exponential-average-hour[]\\n   216\u2192Exponentially-weighted moving average of bucket processing times\\n   217\u2192calculated in a 1 hour time window, in milliseconds.\\n   218\u2192end::bucket-time-exponential-average-hour[]\\n   219\u2192\\n   220\u2192tag::bucket-time-maximum[]\\n   221\u2192Maximum among all bucket processing times, in milliseconds.\\n   222\u2192end::bucket-time-maximum[]\\n   223\u2192\\n   224\u2192tag::bucket-time-minimum[]\\n   225\u2192Minimum among all bucket processing times, in milliseconds.\\n   226\u2192end::bucket-time-minimum[]\\n   227\u2192\\n   228\u2192tag::bucket-time-total[]\\n   229\u2192Sum of all bucket processing times, in milliseconds.\\n   230\u2192end::bucket-time-total[]\\n   231\u2192\\n   232\u2192tag::by-field-name[]\\n   233\u2192The field used to split the data. In particular, this property is used for\\n   234\u2192analyzing the splits with respect to their own history. It is used for finding\\n   235\u2192unusual values in the context of the split.\\n   236\u2192end::by-field-name[]\\n   237\u2192\\n   238\u2192tag::calendar-id[]\\n   239\u2192A string that uniquely identifies a calendar.\\n   240\u2192end::calendar-id[]\\n   241\u2192\\n   242\u2192tag::categorization-analyzer[]\\n   243\u2192If `categorization_field_name` is specified, you can also define the analyzer\\n   244\u2192that is used to interpret the categorization field. This property cannot be used\\n   245\u2192at the same time as `categorization_filters`. The categorization analyzer\\n   246\u2192specifies how the `categorization_field` is interpreted by the categorization\\n   247\u2192process. The syntax is very similar to that used to define the `analyzer` in the\\n   248\u2192<<indices-analyze,Analyze endpoint>>. For more information, see\\n   249\u2192{ml-docs}/ml-configuring-categories.html[Categorizing log messages].\\n   250\u2192+\\n   251\u2192The `categorization_analyzer` field can be specified either as a string or as an\\n   252\u2192object. If it is a string it must refer to a\\n   253\u2192<<analysis-analyzers,built-in analyzer>> or one added by another plugin. If it\\n   254\u2192is an object it has the following properties:\\n   255\u2192+\\n   256\u2192.Properties of `categorization_analyzer`\\n   257\u2192[%collapsible%open]\\n   258\u2192=====\\n   259\u2192`char_filter`::::\\n   260\u2192(array of strings or objects)\\n   261\u2192include::{es-ref-dir}/ml/ml-shared.asciidoc[tag=char-filter]\\n   262\u2192\\n   263\u2192`tokenizer`::::\\n   264\u2192(string or object)\\n   265\u2192include::{es-ref-dir}/ml/ml-shared.asciidoc[tag=tokenizer]\\n   266\u2192\\n   267\u2192`filter`::::\\n   268\u2192(array of strings or objects)\\n   269\u2192include::{es-ref-dir}/ml/ml-shared.asciidoc[tag=filter]\\n   270\u2192=====\\n   271\u2192end::categorization-analyzer[]\\n   272\u2192\\n   273\u2192tag::categorization-examples-limit[]\\n   274\u2192The maximum number of examples stored per category in memory and in the results\\n   275\u2192data store. The default value is 4. If you increase this value, more examples\\n   276\u2192are available, however it requires that you have more storage available. If you\\n   277\u2192set this value to `0`, no examples are stored.\\n   278\u2192+\\n   279\u2192NOTE: The `categorization_examples_limit` only applies to analysis that uses\\n   280\u2192categorization. For more information, see\\n   281\u2192{ml-docs}/ml-configuring-categories.html[Categorizing log messages].\\n   282\u2192end::categorization-examples-limit[]\\n   283\u2192\\n   284\u2192tag::categorization-field-name[]\\n   285\u2192If this property is specified, the values of the specified field will be\\n   286\u2192categorized. The resulting categories must be used in a detector by setting\\n   287\u2192`by_field_name`, `over_field_name`, or `partition_field_name` to the keyword\\n   288\u2192`mlcategory`. For more information, see\\n   289\u2192{ml-docs}/ml-configuring-categories.html[Categorizing log messages].\\n   290\u2192end::categorization-field-name[]\\n   291\u2192\\n   292\u2192tag::categorization-filters[]\\n   293\u2192If `categorization_field_name` is specified, you can also define optional\\n   294\u2192filters. This property expects an array of regular expressions. The expressions\\n   295\u2192are used to filter out matching sequences from the categorization field values.\\n   296\u2192You can use this functionality to fine tune the categorization by excluding\\n   297\u2192sequences from consideration when categories are defined. For example, you can\\n   298\u2192exclude SQL statements that appear in your log files. For more information, see\\n   299\u2192{ml-docs}/ml-configuring-categories.html[Categorizing log messages]. This\\n   300\u2192property cannot be used at the same time as `categorization_analyzer`. If you\\n   301\u2192only want to define simple regular expression filters that are applied prior to\\n   302\u2192tokenization, setting this property is the easiest method. If you also want to\\n   303\u2192customize the tokenizer or post-tokenization filtering, use the\\n   304\u2192`categorization_analyzer` property instead and include the filters as\\n   305\u2192`pattern_replace` character filters. The effect is exactly the same.\\n   306\u2192end::categorization-filters[]\\n   307\u2192\\n   308\u2192tag::categorization-status[]\\n   309\u2192The status of categorization for the job. Contains one of the following values:\\n   310\u2192+\\n   311\u2192--\\n   312\u2192* `ok`: Categorization is performing acceptably well (or not being used at all).\\n   313\u2192* `warn`: Categorization is detecting a distribution of categories that suggests\\n   314\u2192the input data is inappropriate for categorization. Problems could be that there\\n   315\u2192is only one category, more than 90% of categories are rare, the number of\\n   316\u2192categories is greater than 50% of the number of categorized documents, there are\\n   317\u2192no frequently matched categories, or more than 50% of categories are dead.\\n   318\u2192\\n   319\u2192--\\n   320\u2192end::categorization-status[]\\n   321\u2192\\n   322\u2192tag::categorized-doc-count[]\\n   323\u2192The number of documents that have had a field categorized.\\n   324\u2192end::categorized-doc-count[]\\n   325\u2192\\n   326\u2192tag::char-filter[]\\n   327\u2192One or more <<analysis-charfilters,character filters>>. In addition to the\\n   328\u2192built-in character filters, other plugins can provide more character filters.\\n   329\u2192This property is optional. If it is not specified, no character filters are\\n   330\u2192applied prior to categorization. If you are customizing some other aspect of the\\n   331\u2192analyzer and you need to achieve the equivalent of `categorization_filters`\\n   332\u2192(which are not permitted when some other aspect of the analyzer is customized),\\n   333\u2192add them here as\\n   334\u2192<<analysis-pattern-replace-charfilter,pattern replace character filters>>.\\n   335\u2192end::char-filter[]\\n   336\u2192\\n   337\u2192tag::chunking-config[]\\n   338\u2192{dfeeds-cap} might be required to search over long time periods, for several\\n   339\u2192months or years. This search is split into time chunks in order to ensure the\\n   340\u2192load on {es} is managed. Chunking configuration controls how the size of these\\n   341\u2192time chunks are calculated and is an advanced configuration option.\\n   342\u2192end::chunking-config[]\\n   343\u2192\\n   344\u2192tag::class-assignment-objective[]\\n   345\u2192Defines the objective to optimize when assigning class labels:\\n   346\u2192`maximize_accuracy` or `maximize_minimum_recall`. When maximizing accuracy,\\n   347\u2192class labels are chosen to maximize the number of correct predictions. When\\n   348\u2192maximizing minimum recall, labels are chosen to maximize the minimum recall for\\n   349\u2192any class. Defaults to `maximize_minimum_recall`.\\n   350\u2192end::class-assignment-objective[]\\n   351\u2192\\n   352\u2192tag::compute-feature-influence[]\\n   353\u2192Specifies whether the feature influence calculation is enabled. Defaults to\\n   354\u2192`true`.\\n   355\u2192end::compute-feature-influence[]\\n   356\u2192\\n   357\u2192tag::custom-preprocessor[]\\n   358\u2192(Optional, Boolean)\\n   359\u2192Boolean value indicating if the analytics job created the preprocessor\\n   360\u2192or if a user provided it. This adjusts the feature importance calculation.\\n   361\u2192When `true`, the feature importance calculation returns importance for the\\n   362\u2192processed feature. When `false`, the total importance of the original field\\n   363\u2192is returned. Default is `false`.\\n   364\u2192end::custom-preprocessor[]\\n   365\u2192\\n   366\u2192tag::custom-rules[]\\n   367\u2192An array of custom rule objects, which enable you to customize the way detectors\\n   368\u2192operate. For example, a rule may dictate to the detector conditions under which\\n   369\u2192results should be skipped. {kib} refers to custom rules as _job rules_. For more\\n   370\u2192examples, see\\n   371\u2192{ml-docs}/ml-configuring-detector-custom-rules.html[Customizing detectors with custom rules].\\n   372\u2192end::custom-rules[]\\n   373\u2192\\n   374\u2192tag::custom-rules-actions[]\\n   375\u2192The set of actions to be triggered when the rule applies. If\\n   376\u2192more than one action is specified the effects of all actions are combined. The\\n   377\u2192available actions include:\\n   378\u2192\\n   379\u2192* `skip_result`: The result will not be created. This is the default value.\\n   380\u2192Unless you also specify `skip_model_update`, the model will be updated as usual\\n   381\u2192with the corresponding series value.\\n   382\u2192* `skip_model_update`: The value for that series will not be used to update the\\n   383\u2192model. Unless you also specify `skip_result`, the results will be created as\\n   384\u2192usual. This action is suitable when certain values are expected to be\\n   385\u2192consistently anomalous and they affect the model in a way that negatively\\n   386\u2192impacts the rest of the results.\\n   387\u2192* `force_time_shift`: This action will shift the time inside the anomaly detector by a specified\\n   388\u2192amount. This is useful, e.g. to quickly adapt to the daylight saving time events that\\n   389\u2192are known beforehand. This action requires a `force_time_shift` parameter\\n   390\u2192in the `params` object.\\n   391\u2192end::custom-rules-actions[]\\n   392\u2192\\n   393\u2192tag::custom-rules-scope[]\\n   394\u2192An optional scope of series where the rule applies. A rule must either\\n   395\u2192have a non-empty scope or at least one condition. By default, the scope includes\\n   396\u2192all series. Scoping is allowed for any of the fields that are also specified in\\n   397\u2192`by_field_name`, `over_field_name`, or `partition_field_name`. To add a scope\\n   398\u2192for a field, add the field name as a key in the scope object and set its value\\n   399\u2192to an object with the following properties:\\n   400\u2192end::custom-rules-scope[]\\n   401\u2192\\n   402\u2192tag::custom-rules-scope-filter-id[]\\n   403\u2192The id of the filter to be used.\\n   404\u2192end::custom-rules-scope-filter-id[]\\n   405\u2192\\n   406\u2192tag::custom-rules-scope-filter-type[]\\n   407\u2192Either `include` (the rule applies for values in the filter) or `exclude` (the\\n   408\u2192rule applies for values not in the filter). Defaults to `include`.\\n   409\u2192end::custom-rules-scope-filter-type[]\\n   410\u2192\\n   411\u2192tag::custom-rules-conditions[]\\n   412\u2192An optional array of numeric conditions when the rule applies. A rule must\\n   413\u2192either have a non-empty scope or at least one condition. Multiple conditions are\\n   414\u2192combined together with a logical `AND`. A condition has the following\\n   415\u2192properties:\\n   416\u2192end::custom-rules-conditions[]\\n   417\u2192\\n   418\u2192tag::custom-rules-conditions-applies-to[]\\n   419\u2192Specifies the result property to which the condition applies. The available\\n   420\u2192options are `actual`, `typical`, `diff_from_typical`, `time`. If your detector\\n   421\u2192uses `lat_long`, `metric`, `rare`, or `freq_rare` functions, you can only\\n   422\u2192specify conditions that apply to `time`.\\n   423\u2192end::custom-rules-conditions-applies-to[]\\n   424\u2192\\n   425\u2192tag::custom-rules-conditions-operator[]\\n   426\u2192Specifies the condition operator. The available options are `gt` (greater than),\\n   427\u2192`gte` (greater than or equals), `lt` (less than) and `lte` (less than or\\n   428\u2192equals).\\n   429\u2192end::custom-rules-conditions-operator[]\\n   430\u2192\\n   431\u2192tag::custom-rules-conditions-value[]\\n   432\u2192The value that is compared against the `applies_to` field using the `operator`.\\n   433\u2192end::custom-rules-conditions-value[]\\n   434\u2192\\n   435\u2192tag::custom-rules-params[]\\n   436\u2192A set of parameter objects that customize the actions defined in the custom rules\\n   437\u2192actions array. The available parameters (depending on the specified actions) include:\\n   438\u2192`force_time_shift`.\\n   439\u2192end::custom-rules-params[]\\n   440\u2192\\n   441\u2192tag::custom-rules-params-force-time-shift[]\\n   442\u2192Set `time_shift_amount` to the signed number of seconds by which you want to shift the time.\\n   443\u2192end::custom-rules-params-force-time-shift[]\\n   444\u2192\\n   445\u2192tag::custom-settings[]\\n   446\u2192Advanced configuration option. Contains custom metadata about the job. For\\n   447\u2192example, it can contain custom URL information as shown in\\n   448\u2192{ml-docs}/ml-configuring-url.html[Adding custom URLs to {ml} results].\\n   449\u2192end::custom-settings[]\\n   450\u2192\\n   451\u2192tag::daily-model-snapshot-retention-after-days[]\\n   452\u2192Advanced configuration option, which affects the automatic removal of old model\\n   453\u2192snapshots for this job. It specifies a period of time (in days) after which only\\n   454\u2192the first snapshot per day is retained. This period is relative to the timestamp\\n   455\u2192of the most recent snapshot for this job. Valid values range from `0` to\\n   456\u2192`model_snapshot_retention_days`. For new jobs, the default value is `1`. For\\n   457\u2192jobs created before version 7.8.0, the default value matches\\n   458\u2192`model_snapshot_retention_days`. For more information, refer to\\n   459\u2192{ml-docs}/ml-ad-run-jobs.html#ml-ad-model-snapshots[Model snapshots].\\n   460\u2192+\\n   461\u2192--\\n   462\u2192NOTE: From {es} 8.10.0,  a new version number is used to\\n   463\u2192track the configuration and state changes in the {ml} plugin. This new\\n   464\u2192version number is decoupled from the product version and will increment\\n   465\u2192independently.\\n   466\u2192--\\n   467\u2192end::daily-model-snapshot-retention-after-days[]\\n   468\u2192\\n   469\u2192tag::data-description[]\\n   470\u2192The data description defines the format of the input data when you send data to\\n   471\u2192the job by using the <<ml-post-data,post data>> API. Note that when using a\\n   472\u2192{dfeed}, only the `time_field` needs to be set, the rest of the properties are\\n   473\u2192automatically set. When data is received via the <<ml-post-data,post data>> API,\\n   474\u2192it is not stored in {es}. Only the results for {anomaly-detect} are retained.\\n   475\u2192+\\n   476\u2192.Properties of `data_description`\\n   477\u2192[%collapsible%open]\\n   478\u2192====\\n   479\u2192`format`:::\\n   480\u2192  (string) Only `xcontent` format is supported at this time, and this is the\\n   481\u2192  default value.\\n   482\u2192\\n   483\u2192`time_field`:::\\n   484\u2192  (string) The name of the field that contains the timestamp.\\n   485\u2192  The default value is `time`.\\n   486\u2192\\n   487\u2192`time_format`:::\\n   488\u2192(string)\\n   489\u2192include::{es-ref-dir}/ml/ml-shared.asciidoc[tag=time-format]\\n   490\u2192====\\n   491\u2192end::data-description[]\\n   492\u2192\\n   493\u2192tag::datafeed-id[]\\n   494\u2192A numerical character string that uniquely identifies the\\n   495\u2192{dfeed}. This identifier can contain lowercase alphanumeric characters (a-z\\n   496\u2192and 0-9), hyphens, and underscores. It must start and end with alphanumeric\\n   497\u2192characters.\\n   498\u2192end::datafeed-id[]\\n   499\u2192\\n   500\u2192tag::datafeed-id-wildcard[]\\n   501\u2192Identifier for the {dfeed}. It can be a {dfeed} identifier or a wildcard\\n   502\u2192expression.\\n   503\u2192end::datafeed-id-wildcard[]\\n   504\u2192\\n   505\u2192tag::dead-category-count[]\\n   506\u2192The number of categories created by categorization that will never be assigned\\n   507\u2192again because another category's definition makes it a superset of the dead\\n   508\u2192category. (Dead categories are a side effect of the way categorization has no\\n   509\u2192prior training.)\\n   510\u2192end::dead-category-count[]\\n   511\u2192\\n   512\u2192tag::delayed-data-check-config[]\\n   513\u2192Specifies whether the {dfeed} checks for missing data and the size of the\\n   514\u2192window. For example: `{\\\"enabled\\\": true, \\\"check_window\\\": \\\"1h\\\"}`.\\n   515\u2192+\\n   516\u2192The {dfeed} can optionally search over indices that have already been read in\\n   517\u2192an effort to determine whether any data has subsequently been added to the\\n   518\u2192index. If missing data is found, it is a good indication that the `query_delay`\\n   519\u2192option is set too low and the data is being indexed after the {dfeed} has passed\\n   520\u2192that moment in time. See\\n   521\u2192{ml-docs}/ml-delayed-data-detection.html[Working with delayed data].\\n   522\u2192+\\n   523\u2192This check runs only on real-time {dfeeds}.\\n   524\u2192end::delayed-data-check-config[]\\n   525\u2192\\n   526\u2192tag::delayed-data-check-config-check-window[]\\n   527\u2192The window of time that is searched for late data. This window of time ends with\\n   528\u2192the latest finalized bucket. It defaults to `null`, which causes an appropriate\\n   529\u2192`check_window` to be calculated when the real-time {dfeed} runs. In particular,\\n   530\u2192the default `check_window` span calculation is based on the maximum of `2h` or\\n   531\u2192`8 * bucket_span`.\\n   532\u2192end::delayed-data-check-config-check-window[]\\n   533\u2192\\n   534\u2192tag::delayed-data-check-config-enabled[]\\n   535\u2192Specifies whether the {dfeed} periodically checks for delayed data. Defaults to\\n   536\u2192`true`.\\n   537\u2192end::delayed-data-check-config-enabled[]\\n   538\u2192\\n   539\u2192tag::dependent-variable[]\\n   540\u2192Defines which field of the document is to be predicted.\\n   541\u2192This parameter is supplied by field name and must match one of the fields in\\n   542\u2192the index being used to train. If this field is missing from a document, then\\n   543\u2192that document will not be used for training, but a prediction with the trained\\n   544\u2192model will be generated for it. It is also known as continuous target variable.\\n   545\u2192end::dependent-variable[]\\n   546\u2192\\n   547\u2192tag::deployment-id[]\\n   548\u2192A unique identifier for the deployment of the model.\\n   549\u2192end::deployment-id[]\\n   550\u2192\\n   551\u2192tag::desc-results[]\\n   552\u2192If true, the results are sorted in descending order.\\n   553\u2192end::desc-results[]\\n   554\u2192\\n   555\u2192tag::description-dfa[]\\n   556\u2192A description of the job.\\n   557\u2192end::description-dfa[]\\n   558\u2192\\n   559\u2192tag::dest[]\\n   560\u2192The destination configuration, consisting of `index` and optionally\\n   561\u2192`results_field` (`ml` by default).\\n   562\u2192+\\n   563\u2192.Properties of `dest`\\n   564\u2192[%collapsible%open]\\n   565\u2192====\\n   566\u2192`index`:::\\n   567\u2192(Required, string) Defines the _destination index_ to store the results of the\\n   568\u2192{dfanalytics-job}.\\n   569\u2192\\n   570\u2192`results_field`:::\\n   571\u2192(Optional, string) Defines the name of the field in which to store the results\\n   572\u2192of the analysis. Defaults to `ml`.\\n   573\u2192====\\n   574\u2192end::dest[]\\n   575\u2192\\n   576\u2192tag::detector-description[]\\n   577\u2192A description of the detector. For example, `Low event rate`.\\n   578\u2192end::detector-description[]\\n   579\u2192\\n   580\u2192tag::detector-field-name[]\\n   581\u2192The field that the detector uses in the function. If you use an event rate\\n   582\u2192function such as `count` or `rare`, do not specify this field.\\n   583\u2192+\\n   584\u2192--\\n   585\u2192NOTE: The `field_name` cannot contain double quotes or backslashes.\\n   586\u2192\\n   587\u2192--\\n   588\u2192end::detector-field-name[]\\n   589\u2192\\n   590\u2192tag::detector-index[]\\n   591\u2192A unique identifier for the detector. This identifier is based on the order of\\n   592\u2192the detectors in the `analysis_config`, starting at zero.\\n   593\u2192end::detector-index[]\\n   594\u2192\\n   595\u2192tag::dfas-alpha[]\\n   596\u2192Advanced configuration option. {ml-cap} uses loss guided tree growing, which\\n   597\u2192means that the decision trees grow where the regularized loss decreases most\\n   598\u2192quickly. This parameter affects loss calculations by acting as a multiplier of\\n   599\u2192the tree depth. Higher alpha values result in shallower trees and faster\\n   600\u2192training times. By default, this value is calculated during hyperparameter\\n   601\u2192optimization. It must be greater than or equal to zero.\\n   602\u2192end::dfas-alpha[]\\n   603\u2192\\n   604\u2192tag::dfas-downsample-factor[]\\n   605\u2192Advanced configuration option. Controls the fraction of data that is used to\\n   606\u2192compute the derivatives of the loss function for tree training. A small value\\n   607\u2192results in the use of a small fraction of the data. If this value is set to be\\n   608\u2192less than 1, accuracy typically improves. However, too small a value may result\\n   609\u2192in poor convergence for the ensemble and so require more trees. For more\\n   610\u2192information about shrinkage, refer to\\n   611\u2192{wikipedia}/Gradient_boosting#Stochastic_gradient_boosting[this wiki article].\\n   612\u2192By default, this value is calculated during hyperparameter optimization. It\\n   613\u2192must be greater than zero and less than or equal to 1.\\n   614\u2192end::dfas-downsample-factor[]\\n   615\u2192\\n   616\u2192tag::dfas-early-stopping-enabled[]\\n   617\u2192Advanced configuration option.\\n   618\u2192Specifies whether the training process should finish if it is not finding any\\n   619\u2192better performing models. If disabled, the training process can take significantly\\n   620\u2192longer and the chance of finding a better performing model is unremarkable.\\n   621\u2192By default, early stoppping is enabled.\\n   622\u2192end::dfas-early-stopping-enabled[]\\n   623\u2192\\n   624\u2192tag::dfas-eta-growth[]\\n   625\u2192Advanced configuration option. Specifies the rate at which `eta` increases for\\n   626\u2192each new tree that is added to the forest. For example, a rate of 1.05\\n   627\u2192increases `eta` by 5% for each extra tree. By default, this value is calculated\\n   628\u2192during hyperparameter optimization. It must be between 0.5 and 2.\\n   629\u2192end::dfas-eta-growth[]\\n   630\u2192\\n   631\u2192tag::dfas-feature-bag-fraction[]\\n   632\u2192The fraction of features that is used when selecting a random bag for each\\n   633\u2192candidate split.\\n   634\u2192end::dfas-feature-bag-fraction[]\\n   635\u2192\\n   636\u2192tag::dfas-feature-processors[]\\n   637\u2192Advanced configuration option. A collection of feature preprocessors that modify\\n   638\u2192one or more included fields. The analysis uses the resulting one or more\\n   639\u2192features instead of the original document field. However, these features are\\n   640\u2192ephemeral; they are not stored in the destination index. Multiple\\n   641\u2192`feature_processors` entries can refer to the same document fields. Automatic\\n   642\u2192categorical {ml-docs}/ml-feature-encoding.html[feature encoding] still occurs\\n   643\u2192for the fields that are unprocessed by a custom processor or that have\\n   644\u2192categorical values. Use this property only if you want to override the automatic\\n   645\u2192feature encoding of the specified fields. Refer to\\n   646\u2192{ml-docs}/ml-feature-processors.html[{dfanalytics} feature processors] to learn\\n   647\u2192more.\\n   648\u2192end::dfas-feature-processors[]\\n   649\u2192\\n   650\u2192tag::dfas-feature-processors-feat-name[]\\n   651\u2192The resulting feature name.\\n   652\u2192end::dfas-feature-processors-feat-name[]\\n   653\u2192\\n   654\u2192tag::dfas-feature-processors-field[]\\n   655\u2192The name of the field to encode.\\n   656\u2192end::dfas-feature-processors-field[]\\n   657\u2192\\n   658\u2192tag::dfas-feature-processors-frequency[]\\n   659\u2192The configuration information necessary to perform frequency encoding.\\n   660\u2192end::dfas-feature-processors-frequency[]\\n   661\u2192\\n   662\u2192tag::dfas-feature-processors-frequency-map[]\\n   663\u2192The resulting frequency map for the field value. If the field value is missing\\n   664\u2192from the `frequency_map`, the resulting value is `0`.\\n   665\u2192end::dfas-feature-processors-frequency-map[]\\n   666\u2192\\n   667\u2192tag::dfas-feature-processors-multi[]\\n   668\u2192The configuration information necessary to perform multi encoding. It allows\\n   669\u2192multiple processors to be changed together. This way the output of a processor\\n   670\u2192can then be passed to another as an input.\\n   671\u2192end::dfas-feature-processors-multi[]\\n   672\u2192\\n   673\u2192tag::dfas-feature-processors-multi-proc[]\\n   674\u2192The ordered array of custom processors to execute. Must be more than 1.\\n   675\u2192end::dfas-feature-processors-multi-proc[]\\n   676\u2192\\n   677\u2192tag::dfas-feature-processors-ngram[]\\n   678\u2192The configuration information necessary to perform n-gram encoding. Features\\n   679\u2192created by this encoder have the following name format:\\n   680\u2192`<feature_prefix>.<ngram><string position>`. For example, if the\\n   681\u2192`feature_prefix` is `f`, the feature name for the second unigram in a string is\\n   682\u2192`f.11`.\\n   683\u2192end::dfas-feature-processors-ngram[]\\n   684\u2192\\n   685\u2192tag::dfas-feature-processors-ngram-feat-pref[]\\n   686\u2192The feature name prefix. Defaults to `ngram_<start>_<length>`.\\n   687\u2192end::dfas-feature-processors-ngram-feat-pref[]\\n   688\u2192\\n   689\u2192tag::dfas-feature-processors-ngram-field[]\\n   690\u2192The name of the text field to encode.\\n   691\u2192end::dfas-feature-processors-ngram-field[]\\n   692\u2192\\n   693\u2192tag::dfas-feature-processors-ngram-length[]\\n   694\u2192Specifies the length of the n-gram substring. Defaults to `50`. Must be greater\\n   695\u2192than `0`.\\n   696\u2192end::dfas-feature-processors-ngram-length[]\\n   697\u2192\\n   698\u2192tag::dfas-feature-processors-ngram-ngrams[]\\n   699\u2192Specifies which n-grams to gather. It\u2019s an array of integer values where the\\n   700\u2192minimum value is 1, and a maximum value is 5.\\n   701\u2192end::dfas-feature-processors-ngram-ngrams[]\\n   702\u2192\\n   703\u2192tag::dfas-feature-processors-ngram-start[]\\n   704\u2192Specifies the zero-indexed start of the n-gram substring. Negative values are\\n   705\u2192allowed for encoding n-grams of string suffixes. Defaults to `0`.\\n   706\u2192end::dfas-feature-processors-ngram-start[]\\n   707\u2192\\n   708\u2192tag::dfas-feature-processors-one-hot[]\\n   709\u2192The configuration information necessary to perform one hot encoding.\\n   710\u2192end::dfas-feature-processors-one-hot[]\\n   711\u2192\\n   712\u2192tag::dfas-feature-processors-one-hot-map[]\\n   713\u2192The one hot map mapping the field value with the column name.\\n   714\u2192end::dfas-feature-processors-one-hot-map[]\\n   715\u2192\\n   716\u2192tag::dfas-feature-processors-target-mean[]\\n   717\u2192The configuration information necessary to perform target mean encoding.\\n   718\u2192end::dfas-feature-processors-target-mean[]\\n   719\u2192\\n   720\u2192tag::dfas-feature-processors-target-mean-default[]\\n   721\u2192The default value if field value is not found in the `target_map`.\\n   722\u2192end::dfas-feature-processors-target-mean-default[]\\n   723\u2192\\n   724\u2192tag::dfas-feature-processors-target-mean-map[]\\n   725\u2192The field value to target mean transition map.\\n   726\u2192end::dfas-feature-processors-target-mean-map[]\\n   727\u2192\\n   728\u2192tag::dfas-iteration[]\\n   729\u2192The number of iterations on the analysis.\\n   730\u2192end::dfas-iteration[]\\n   731\u2192\\n   732\u2192tag::dfas-max-attempts[]\\n   733\u2192If the algorithm fails to determine a non-trivial tree (more than a single\\n   734\u2192leaf), this parameter determines how many of such consecutive failures are\\n   735\u2192tolerated. Once the number of attempts exceeds the threshold, the forest\\n   736\u2192training stops.\\n   737\u2192end::dfas-max-attempts[]\\n   738\u2192\\n   739\u2192tag::dfas-max-optimization-rounds[]\\n   740\u2192Advanced configuration option.\\n   741\u2192A multiplier responsible for determining the maximum number of\\n   742\u2192hyperparameter optimization steps in the Bayesian optimization procedure.\\n   743\u2192The maximum number of steps is determined based on the number of undefined\\n   744\u2192hyperparameters times the maximum optimization rounds per hyperparameter.\\n   745\u2192By default, this value is calculated during hyperparameter optimization.\\n   746\u2192end::dfas-max-optimization-rounds[]\\n   747\u2192\\n   748\u2192tag::dfas-num-folds[]\\n   749\u2192The maximum number of folds for the cross-validation procedure.\\n   750\u2192end::dfas-num-folds[]\\n   751\u2192\\n   752\u2192tag::dfas-num-splits[]\\n   753\u2192Determines the maximum number of splits for every feature that can occur in a\\n   754\u2192decision tree when the tree is trained.\\n   755\u2192end::dfas-num-splits[]\\n   756\u2192\\n   757\u2192tag::dfas-soft-limit[]\\n   758\u2192Advanced configuration option. {ml-cap} uses loss guided tree growing, which\\n   759\u2192means that the decision trees grow where the regularized loss decreases most\\n   760\u2192quickly. This soft limit combines with the `soft_tree_depth_tolerance` to\\n   761\u2192penalize trees that exceed the specified depth; the regularized loss increases\\n   762\u2192quickly beyond this depth. By default, this value is calculated during\\n   763\u2192hyperparameter optimization. It must be greater than or equal to 0.\\n   764\u2192end::dfas-soft-limit[]\\n   765\u2192\\n   766\u2192tag::dfas-soft-tolerance[]\\n   767\u2192Advanced configuration option. This option controls how quickly the regularized\\n   768\u2192loss increases when the tree depth exceeds `soft_tree_depth_limit`. By default,\\n   769\u2192this value is calculated during hyperparameter optimization. It must be greater\\n   770\u2192than or equal to 0.01.\\n   771\u2192end::dfas-soft-tolerance[]\\n   772\u2192\\n   773\u2192tag::dfas-timestamp[]\\n   774\u2192The timestamp when the statistics were reported in milliseconds since the epoch.\\n   775\u2192end::dfas-timestamp[]\\n   776\u2192\\n   777\u2192tag::dfas-timing-stats[]\\n   778\u2192An object containing time statistics about the {dfanalytics-job}.\\n   779\u2192end::dfas-timing-stats[]\\n   780\u2192\\n   781\u2192tag::dfas-timing-stats-elapsed[]\\n   782\u2192Runtime of the analysis in milliseconds.\\n   783\u2192end::dfas-timing-stats-elapsed[]\\n   784\u2192\\n   785\u2192tag::dfas-timing-stats-iteration[]\\n   786\u2192Runtime of the latest iteration of the analysis in milliseconds.\\n   787\u2192end::dfas-timing-stats-iteration[]\\n   788\u2192\\n   789\u2192tag::dfas-validation-loss[]\\n   790\u2192An object containing information about validation loss.\\n   791\u2192end::dfas-validation-loss[]\\n   792\u2192\\n   793\u2192tag::dfas-validation-loss-fold[]\\n   794\u2192Validation loss values for every added decision tree during the forest growing\\n   795\u2192procedure.\\n   796\u2192end::dfas-validation-loss-fold[]\\n   797\u2192\\n   798\u2192tag::dfas-validation-loss-type[]\\n   799\u2192The type of the loss metric. For example, `binomial_logistic`.\\n   800\u2192end::dfas-validation-loss-type[]\\n   801\u2192\\n   802\u2192tag::earliest-record-timestamp[]\\n   803\u2192The timestamp of the earliest chronologically input document.\\n   804\u2192end::earliest-record-timestamp[]\\n   805\u2192\\n   806\u2192tag::empty-bucket-count[]\\n   807\u2192The number of buckets which did not contain any data. If your data\\n   808\u2192contains many empty buckets, consider increasing your `bucket_span` or using\\n   809\u2192functions that are tolerant to gaps in data such as `mean`, `non_null_sum` or\\n   810\u2192`non_zero_count`.\\n   811\u2192end::empty-bucket-count[]\\n   812\u2192\\n   813\u2192tag::eta[]\\n   814\u2192Advanced configuration option. The shrinkage applied to the weights. Smaller\\n   815\u2192values result in larger forests which have a better generalization error.\\n   816\u2192However, larger forests cause slower training. For more information about\\n   817\u2192shrinkage, refer to\\n   818\u2192{wikipedia}/Gradient_boosting#Shrinkage[this wiki article].\\n   819\u2192By default, this value is calculated during hyperparameter optimization. It must\\n   820\u2192be a value between 0.001 and 1.\\n   821\u2192end::eta[]\\n   822\u2192\\n   823\u2192tag::exclude-frequent[]\\n   824\u2192Contains one of the following values: `all`, `none`, `by`, or `over`. If set,\\n   825\u2192frequent entities are excluded from influencing the anomaly results. Entities\\n   826\u2192can be considered frequent over time or frequent in a population. If you are\\n   827\u2192working with both over and by fields, then you can set `exclude_frequent` to\\n   828\u2192`all` for both fields, or to `by` or `over` for those specific fields.\\n   829\u2192end::exclude-frequent[]\\n   830\u2192\\n   831\u2192tag::exclude-interim-results[]\\n   832\u2192If `true`, the output excludes interim results. Defaults to `false`, which means interim results are included.\\n   833\u2192end::exclude-interim-results[]\\n   834\u2192\\n   835\u2192tag::failed-category-count[]\\n   836\u2192The number of times that categorization wanted to create a new category but\\n   837\u2192couldn't because the job had hit its `model_memory_limit`. This count does not\\n   838\u2192track which specific categories failed to be created. Therefore you cannot use\\n   839\u2192this value to determine the number of unique categories that were missed.\\n   840\u2192end::failed-category-count[]\\n   841\u2192\\n   842\u2192tag::feature-bag-fraction[]\\n   843\u2192Advanced configuration option. Defines the fraction of features that will be\\n   844\u2192used when selecting a random bag for each candidate split. By default, this\\n   845\u2192value is calculated during hyperparameter optimization.\\n   846\u2192end::feature-bag-fraction[]\\n   847\u2192\\n   848\u2192tag::feature-influence-threshold[]\\n   849\u2192The minimum {olscore} that a document needs to have in order to calculate its\\n   850\u2192{fiscore}. Value range: 0-1 (`0.1` by default).\\n   851\u2192end::feature-influence-threshold[]\\n   852\u2192\\n   853\u2192tag::filter[]\\n   854\u2192One or more <<analysis-tokenfilters,token filters>>. In addition to the built-in\\n   855\u2192token filters, other plugins can provide more token filters. This property is\\n   856\u2192optional. If it is not specified, no token filters are applied prior to\\n   857\u2192categorization.\\n   858\u2192end::filter[]\\n   859\u2192\\n   860\u2192tag::filter-id[]\\n   861\u2192A string that uniquely identifies a filter.\\n   862\u2192end::filter-id[]\\n   863\u2192\\n   864\u2192tag::forecast-total[]\\n   865\u2192The number of individual forecasts currently available for the job. A value of\\n   866\u2192`1` or more indicates that forecasts exist.\\n   867\u2192end::forecast-total[]\\n   868\u2192\\n   869\u2192tag::exclude-generated[]\\n   870\u2192Indicates if certain fields should be removed from the configuration on\\n   871\u2192retrieval. This allows the configuration to be in an acceptable format to be retrieved\\n   872\u2192and then added to another cluster. Default is false.\\n   873\u2192end::exclude-generated[]\\n   874\u2192\\n   875\u2192tag::frequency[]\\n   876\u2192The interval at which scheduled queries are made while the {dfeed} runs in real\\n   877\u2192time. The default value is either the bucket span for short bucket spans, or,\\n   878\u2192for longer bucket spans, a sensible fraction of the bucket span. For example:\\n   879\u2192`150s`. When `frequency` is shorter than the bucket span, interim results for\\n   880\u2192the last (partial) bucket are written then eventually overwritten by the full\\n   881\u2192bucket results. If the {dfeed} uses aggregations, this value must be divisible\\n   882\u2192by the interval of the date histogram aggregation.\\n   883\u2192end::frequency[]\\n   884\u2192\\n   885\u2192tag::frequent-category-count[]\\n   886\u2192The number of categories that match more than 1% of categorized documents.\\n   887\u2192end::frequent-category-count[]\\n   888\u2192\\n   889\u2192tag::from[]\\n   890\u2192Skips the specified number of {dfanalytics-jobs}. The default value is `0`.\\n   891\u2192end::from[]\\n   892\u2192\\n   893\u2192tag::from-models[]\\n   894\u2192Skips the specified number of models. The default value is `0`.\\n   895\u2192end::from-models[]\\n   896\u2192\\n   897\u2192tag::function[]\\n   898\u2192The analysis function that is used. For example, `count`, `rare`, `mean`, `min`,\\n   899\u2192`max`, and `sum`. For more information, see\\n   900\u2192{ml-docs}/ml-functions.html[Function reference].\\n   901\u2192end::function[]\\n   902\u2192\\n   903\u2192tag::gamma[]\\n   904\u2192Advanced configuration option. Regularization parameter to prevent overfitting\\n   905\u2192on the training data set. Multiplies a linear penalty associated with the size\\n   906\u2192of individual trees in the forest. A high gamma value causes training to prefer\\n   907\u2192small trees. A small gamma value results in larger individual trees and slower\\n   908\u2192training. By default, this value is calculated during hyperparameter\\n   909\u2192optimization. It must be a nonnegative value.\\n   910\u2192end::gamma[]\\n   911\u2192\\n   912\u2192tag::groups[]\\n   913\u2192A list of job groups. A job can belong to no groups or many.\\n   914\u2192end::groups[]\\n   915\u2192\\n   916\u2192tag::indices[]\\n   917\u2192An array of index names. Wildcards are supported. For example:\\n   918\u2192`[\\\"it_ops_metrics\\\", \\\"server*\\\"]`.\\n   919\u2192+\\n   920\u2192--\\n   921\u2192NOTE: If any indices are in remote clusters then the {ml} nodes need to have the\\n   922\u2192`remote_cluster_client` role.\\n   923\u2192\\n   924\u2192--\\n   925\u2192end::indices[]\\n   926\u2192\\n   927\u2192tag::indices-options[]\\n   928\u2192Specifies index expansion options that are used during search.\\n   929\u2192+\\n   930\u2192--\\n   931\u2192For example:\\n   932\u2192```\\n   933\u2192{\\n   934\u2192   \\\"expand_wildcards\\\": [\\\"all\\\"],\\n   935\u2192   \\\"ignore_unavailable\\\": true,\\n   936\u2192   \\\"allow_no_indices\\\": \\\"false\\\",\\n   937\u2192   \\\"ignore_throttled\\\": true\\n   938\u2192}\\n   939\u2192```\\n   940\u2192For more information about these options, see <<api-multi-index>>.\\n   941\u2192--\\n   942\u2192end::indices-options[]\\n   943\u2192\\n   944\u2192tag::runtime-mappings[]\\n   945\u2192Specifies runtime fields for the datafeed search.\\n   946\u2192+\\n   947\u2192--\\n   948\u2192For example:\\n   949\u2192```\\n   950\u2192{\\n   951\u2192  \\\"day_of_week\\\": {\\n   952\u2192    \\\"type\\\": \\\"keyword\\\",\\n   953\u2192    \\\"script\\\": {\\n   954\u2192      \\\"source\\\": \\\"emit(doc['@timestamp'].value.dayOfWeekEnum.getDisplayName(TextStyle.FULL, Locale.ENGLISH))\\\"\\n   955\u2192    }\\n   956\u2192  }\\n   957\u2192}\\n   958\u2192```\\n   959\u2192\\n   960\u2192--\\n   961\u2192end::runtime-mappings[]\\n   962\u2192\\n   963\u2192tag::inference-config-classification-num-top-classes[]\\n   964\u2192Specifies the number of top class predictions to return. Defaults to 0.\\n   965\u2192end::inference-config-classification-num-top-classes[]\\n   966\u2192\\n   967\u2192tag::inference-config-classification-num-top-feature-importance-values[]\\n   968\u2192Specifies the maximum number of\\n   969\u2192{ml-docs}/ml-feature-importance.html[{feat-imp}] values per document. Defaults\\n   970\u2192to 0 which means no {feat-imp} calculation occurs.\\n   971\u2192end::inference-config-classification-num-top-feature-importance-values[]\\n   972\u2192\\n   973\u2192tag::inference-config-classification-top-classes-results-field[]\\n   974\u2192Specifies the field to which the top classes are written. Defaults to\\n   975\u2192`top_classes`.\\n   976\u2192end::inference-config-classification-top-classes-results-field[]\\n   977\u2192\\n   978\u2192tag::inference-config-classification-prediction-field-type[]\\n   979\u2192Specifies the type of the predicted field to write.\\n   980\u2192Valid values are: `string`, `number`, `boolean`. When `boolean` is provided\\n   981\u2192`1.0` is transformed to `true` and `0.0` to `false`.\\n   982\u2192end::inference-config-classification-prediction-field-type[]\\n   983\u2192\\n   984\u2192tag::inference-config-nlp-tokenization[]\\n   985\u2192Indicates the tokenization to perform and the desired settings.\\n   986\u2192The default tokenization configuration is `bert`. Valid tokenization\\n   987\u2192values are\\n   988\u2192+\\n   989\u2192--\\n   990\u2192* `bert`: Use for BERT-style models\\n   991\u2192* `deberta_v2`: Use for DeBERTa v2 and v3-style models\\n   992\u2192* `mpnet`: Use for MPNet-style models\\n   993\u2192* `roberta`: Use for RoBERTa-style and BART-style models\\n   994\u2192* experimental:[] `xlm_roberta`: Use for XLMRoBERTa-style models\\n   995\u2192* experimental:[] `bert_ja`: Use for BERT-style models trained for the Japanese\\n   996\u2192language.\\n   997\u2192--\\n   998\u2192end::inference-config-nlp-tokenization[]\\n   999\u2192\\n  1000\u2192tag::inference-config-nlp-tokenization-bert[]\\n  1001\u2192BERT-style tokenization is to be performed with the enclosed settings.\\n  1002\u2192end::inference-config-nlp-tokenization-bert[]\\n  1003\u2192\\n  1004\u2192tag::inference-config-nlp-tokenization-bert-ja[]\\n  1005\u2192experimental:[] BERT-style tokenization for Japanese text is to be performed\\n  1006\u2192with the enclosed settings.\\n  1007\u2192end::inference-config-nlp-tokenization-bert-ja[]\\n  1008\u2192\\n  1009\u2192tag::inference-config-nlp-tokenization-do-lower-case[]\\n  1010\u2192Specifies if the tokenization lower case the text sequence when building the\\n  1011\u2192tokens.\\n  1012\u2192end::inference-config-nlp-tokenization-do-lower-case[]\\n  1013\u2192\\n  1014\u2192tag::inference-config-nlp-tokenization-span[]\\n  1015\u2192When `truncate` is `none`, you can partition longer text sequences\\n  1016\u2192for inference. The value indicates how many tokens overlap between each\\n  1017\u2192subsequence.\\n  1018\u2192+\\n  1019\u2192The default value is `-1`, indicating no windowing or spanning occurs.\\n  1020\u2192+\\n  1021\u2192NOTE: When your typical input is just slightly larger than `max_sequence_length`, it may be best to simply truncate;\\n  1022\u2192there will be very little information in the second subsequence.\\n  1023\u2192end::inference-config-nlp-tokenization-span[]\\n  1024\u2192\\n  1025\u2192tag::inference-config-nlp-tokenization-truncate[]\\n  1026\u2192Indicates how tokens are truncated when they exceed `max_sequence_length`.\\n  1027\u2192The default value is `first`.\\n  1028\u2192+\\n  1029\u2192--\\n  1030\u2192* `none`: No truncation occurs; the inference request receives an error.\\n  1031\u2192* `first`: Only the first sequence is truncated.\\n  1032\u2192* `second`: Only the second sequence is truncated. If there is just one sequence,\\n  1033\u2192\\t\\t\\t\\t\\t that sequence is truncated.\\n  1034\u2192--\\n  1035\u2192\\n  1036\u2192NOTE: For `zero_shot_classification`, the hypothesis sequence is always the second\\n  1037\u2192sequence. Therefore, do not use `second` in this case.\\n  1038\u2192\\n  1039\u2192end::inference-config-nlp-tokenization-truncate[]\\n  1040\u2192\\n  1041\u2192tag::inference-config-nlp-tokenization-truncate-deberta-v2[]\\n  1042\u2192Indicates how tokens are truncated when they exceed `max_sequence_length`.\\n  1043\u2192The default value is `first`.\\n  1044\u2192+\\n  1045\u2192--\\n  1046\u2192* `balanced`: One or both of the first and second sequences may be truncated so as to balance the tokens included from both sequences.\\n  1047\u2192* `none`: No truncation occurs; the inference request receives an error.\\n  1048\u2192* `first`: Only the first sequence is truncated.\\n  1049\u2192* `second`: Only the second sequence is truncated. If there is just one sequence, that sequence is truncated.\\n  1050\u2192--\\n  1051\u2192\\n  1052\u2192end::inference-config-nlp-tokenization-truncate-deberta-v2[]\\n  1053\u2192\\n  1054\u2192tag::inference-config-nlp-tokenization-bert-with-special-tokens[]\\n  1055\u2192Tokenize with special tokens. The tokens typically included in BERT-style tokenization are:\\n  1056\u2192+\\n  1057\u2192--\\n  1058\u2192* `[CLS]`: The first token of the sequence being classified.\\n  1059\u2192* `[SEP]`: Indicates sequence separation.\\n  1060\u2192--\\n  1061\u2192end::inference-config-nlp-tokenization-bert-with-special-tokens[]\\n  1062\u2192\\n  1063\u2192tag::inference-config-nlp-tokenization-bert-ja-with-special-tokens[]\\n  1064\u2192Tokenize with special tokens if `true`.\\n  1065\u2192end::inference-config-nlp-tokenization-bert-ja-with-special-tokens[]\\n  1066\u2192\\n  1067\u2192tag::inference-config-nlp-tokenization-deberta-v2[]\\n  1068\u2192DeBERTa-style tokenization is to be performed with the enclosed settings.\\n  1069\u2192end::inference-config-nlp-tokenization-deberta-v2[]\\n  1070\u2192\\n  1071\u2192tag::inference-config-nlp-tokenization-max-sequence-length[]\\n  1072\u2192Specifies the maximum number of tokens allowed to be output by the tokenizer.\\n  1073\u2192end::inference-config-nlp-tokenization-max-sequence-length[]\\n  1074\u2192\\n  1075\u2192tag::inference-config-nlp-tokenization-deberta-v2-with-special-tokens[]\\n  1076\u2192Tokenize with special tokens. The tokens typically included in DeBERTa-style tokenization are:\\n  1077\u2192+\\n  1078\u2192--\\n  1079\u2192* `[CLS]`: The first token of the sequence being classified.\\n  1080\u2192* `[SEP]`: Indicates sequence separation and sequence end.\\n  1081\u2192--\\n  1082\u2192end::inference-config-nlp-tokenization-deberta-v2-with-special-tokens[]\\n  1083\u2192\\n  1084\u2192tag::inference-config-nlp-tokenization-roberta[]\\n  1085\u2192RoBERTa-style tokenization is to be performed with the enclosed settings.\\n  1086\u2192end::inference-config-nlp-tokenization-roberta[]\\n  1087\u2192\\n  1088\u2192tag::inference-config-nlp-tokenization-roberta-add-prefix-space[]\\n  1089\u2192Specifies if the tokenization should prefix a space to the tokenized input to the model.\\n  1090\u2192end::inference-config-nlp-tokenization-roberta-add-prefix-space[]\\n  1091\u2192\\n  1092\u2192tag::inference-config-nlp-tokenization-roberta-with-special-tokens[]\\n  1093\u2192Tokenize with special tokens. The tokens typically included in RoBERTa-style tokenization are:\\n  1094\u2192+\\n  1095\u2192--\\n  1096\u2192* `<s>`: The first token of the sequence being classified.\\n  1097\u2192* `</s>`: Indicates sequence separation.\\n  1098\u2192--\\n  1099\u2192end::inference-config-nlp-tokenization-roberta-with-special-tokens[]\\n  1100\u2192\\n  1101\u2192tag::inference-config-nlp-tokenization-mpnet[]\\n  1102\u2192MPNet-style tokenization is to be performed with the enclosed settings.\\n  1103\u2192end::inference-config-nlp-tokenization-mpnet[]\\n  1104\u2192\\n  1105\u2192tag::inference-config-nlp-tokenization-mpnet-with-special-tokens[]\\n  1106\u2192Tokenize with special tokens. The tokens typically included in MPNet-style tokenization are:\\n  1107\u2192+\\n  1108\u2192--\\n  1109\u2192* `<s>`: The first token of the sequence being classified.\\n  1110\u2192* `</s>`: Indicates sequence separation.\\n  1111\u2192--\\n  1112\u2192end::inference-config-nlp-tokenization-mpnet-with-special-tokens[]\\n  1113\u2192\\n  1114\u2192tag::inference-config-nlp-tokenization-xlm-roberta[]\\n  1115\u2192experimental:[] XLMRoBERTa-style tokenization is to be performed with the enclosed settings.\\n  1116\u2192end::inference-config-nlp-tokenization-xlm-roberta[]\\n  1117\u2192\\n  1118\u2192tag::inference-config-nlp-vocabulary[]\\n  1119\u2192The configuration for retrieving the vocabulary of the model. The vocabulary is\\n  1120\u2192then used at inference time. This information is usually provided automatically\\n  1121\u2192by storing vocabulary in a known, internally managed index.\\n  1122\u2192end::inference-config-nlp-vocabulary[]\\n  1123\u2192\\n  1124\u2192tag::inference-config-nlp-fill-mask[]\\n  1125\u2192Configuration for a fill_mask natural language processing (NLP) task. The\\n  1126\u2192fill_mask task works with models optimized for a fill mask action. For example,\\n  1127\u2192for BERT models, the following text may be provided: \\\"The capital of France is\\n  1128\u2192[MASK].\\\". The response indicates the value most likely to replace `[MASK]`. In\\n  1129\u2192this instance, the most probable token is `paris`.\\n  1130\u2192end::inference-config-nlp-fill-mask[]\\n  1131\u2192\\n  1132\u2192tag::inference-config-ner[]\\n  1133\u2192Configures a named entity recognition (NER) task. NER is a special case of token\\n  1134\u2192classification. Each token in the sequence is classified according to the\\n  1135\u2192provided classification labels. Currently, the NER task requires the\\n  1136\u2192`classification_labels` Inside-Outside-Beginning (IOB) formatted labels. Only\\n  1137\u2192person, organization, location, and miscellaneous are supported.\\n  1138\u2192end::inference-config-ner[]\\n  1139\u2192\\n  1140\u2192tag::inference-config-pass-through[]\\n  1141\u2192Configures a `pass_through` task. This task is useful for debugging as no\\n  1142\u2192post-processing is done to the inference output and the raw pooling layer\\n  1143\u2192results are returned to the caller.\\n  1144\u2192end::inference-config-pass-through[]\\n  1145\u2192\\n  1146\u2192tag::inference-config-nlp-question-answering[]\\n  1147\u2192Configures a question answering natural language processing (NLP) task. Question\\n  1148\u2192answering is useful for extracting answers for certain questions from a large\\n  1149\u2192corpus of text.\\n  1150\u2192end::inference-config-nlp-question-answering[]\\n  1151\u2192\\n  1152\u2192tag::inference-config-text-classification[]\\n  1153\u2192A text classification task. Text classification classifies a provided text\\n  1154\u2192sequence into previously known target classes. A specific example of this is\\n  1155\u2192sentiment analysis, which returns the likely target classes indicating text\\n  1156\u2192sentiment, such as \\\"sad\\\", \\\"happy\\\", or \\\"angry\\\".\\n  1157\u2192end::inference-config-text-classification[]\\n  1158\u2192\\n  1159\u2192tag::inference-config-text-embedding[]\\n  1160\u2192Text embedding takes an input sequence and transforms it into a vector of\\n  1161\u2192numbers. These embeddings capture not simply tokens, but semantic meanings and\\n  1162\u2192context. These embeddings can be used in a <<dense-vector,dense vector>> field\\n  1163\u2192for powerful insights.\\n  1164\u2192end::inference-config-text-embedding[]\\n  1165\u2192\\n  1166\u2192tag::inference-config-text-embedding-size[]\\n  1167\u2192The number of dimensions in the embedding vector produced by the model.\\n  1168\u2192end::inference-config-text-embedding-size[]\\n  1169\u2192\\n  1170\u2192tag::inference-config-text-similarity[]\\n  1171\u2192Text similarity takes an input sequence and compares it with another input sequence. This is commonly referred to\\n  1172\u2192as cross-encoding. This task is useful for ranking document text when comparing it to another provided text input.\\n  1173\u2192end::inference-config-text-similarity[]\\n  1174\u2192\\n  1175\u2192tag::inference-config-text-similarity-span-score-func[]\\n  1176\u2192Identifies how to combine the resulting similarity score when a provided text passage is longer than `max_sequence_length` and must be\\n  1177\u2192automatically separated for multiple calls. This only is applicable when `truncate` is `none` and `span` is a non-negative\\n  1178\u2192number. The default value is `max`. Available options are:\\n  1179\u2192+\\n  1180\u2192--\\n  1181\u2192* `max`: The maximum score from all the spans is returned.\\n  1182\u2192* `mean`: The mean score over all the spans is returned.\\n  1183\u2192--\\n  1184\u2192end::inference-config-text-similarity-span-score-func[]\\n  1185\u2192\\n  1186\u2192tag::inference-config-text-similarity-text[]\\n  1187\u2192This is the text with which to compare all document provided text inputs.\\n  1188\u2192end::inference-config-text-similarity-text[]\\n  1189\u2192\\n  1190\u2192tag::inference-config-regression-num-top-feature-importance-values[]\\n  1191\u2192Specifies the maximum number of\\n  1192\u2192{ml-docs}/ml-feature-importance.html[{feat-imp}] values per document.\\n  1193\u2192By default, it is zero and no {feat-imp} calculation occurs.\\n  1194\u2192end::inference-config-regression-num-top-feature-importance-values[]\\n  1195\u2192\\n  1196\u2192tag::inference-config-results-field[]\\n  1197\u2192The field that is added to incoming documents to contain the inference\\n  1198\u2192prediction. Defaults to `predicted_value`.\\n  1199\u2192end::inference-config-results-field[]\\n  1200\u2192\\n  1201\u2192tag::inference-config-mask-token[]\\n  1202\u2192The string/token which will be removed from incoming documents and replaced with the inference prediction(s). In a response, this field contains the mask token for the specified model/tokenizer. Each model and tokenizer has a predefined mask token which cannot be changed. Thus, it is recommended not to set this value in requests. However, if this field is present in a request, its value must match the predefined value for that model/tokenizer, otherwise the request will fail.\\n  1203\u2192end::inference-config-mask-token[]\\n  1204\u2192\\n  1205\u2192tag::inference-config-results-field-processor[]\\n  1206\u2192The field that is added to incoming documents to contain the inference\\n  1207\u2192prediction. Defaults to the `results_field` value of the {dfanalytics-job} that was\\n  1208\u2192used to train the model, which defaults to `<dependent_variable>_prediction`.\\n  1209\u2192end::inference-config-results-field-processor[]\\n  1210\u2192\\n  1211\u2192tag::inference-config-zero-shot-classification[]\\n  1212\u2192Configures a zero-shot classification task. Zero-shot classification allows for\\n  1213\u2192text classification to occur without pre-determined labels. At inference time,\\n  1214\u2192it is possible to adjust the labels to classify. This makes this type of model\\n  1215\u2192and task exceptionally flexible.\\n  1216\u2192+\\n  1217\u2192--\\n  1218\u2192If consistently classifying the same labels, it may be better to use a\\n  1219\u2192fine-tuned text classification model.\\n  1220\u2192--\\n  1221\u2192end::inference-config-zero-shot-classification[]\\n  1222\u2192\\n  1223\u2192tag::inference-config-zero-shot-classification-classification-labels[]\\n  1224\u2192The classification labels used during the zero-shot classification. Classification\\n  1225\u2192labels must not be empty or null and only set at model creation. They must be all three\\n  1226\u2192of [\\\"entailment\\\", \\\"neutral\\\", \\\"contradiction\\\"].\\n  1227\u2192\\n  1228\u2192NOTE: This is NOT the same as `labels` which are the values that zero-shot is attempting to\\n  1229\u2192      classify.\\n  1230\u2192end::inference-config-zero-shot-classification-classification-labels[]\\n  1231\u2192\\n  1232\u2192tag::inference-config-zero-shot-classification-hypothesis-template[]\\n  1233\u2192This is the template used when tokenizing the sequences for classification.\\n  1234\u2192+\\n  1235\u2192--\\n  1236\u2192The labels replace the `{}` value in the text. The default value is:\\n  1237\u2192`This example is {}.`\\n  1238\u2192--\\n  1239\u2192end::inference-config-zero-shot-classification-hypothesis-template[]\\n  1240\u2192\\n  1241\u2192tag::inference-config-zero-shot-classification-labels[]\\n  1242\u2192The labels to classify. Can be set at creation for default labels, and\\n  1243\u2192then updated during inference.\\n  1244\u2192end::inference-config-zero-shot-classification-labels[]\\n  1245\u2192\\n  1246\u2192tag::inference-config-zero-shot-classification-multi-label[]\\n  1247\u2192Indicates if more than one `true` label is possible given the input.\\n  1248\u2192This is useful when labeling text that could pertain to more than one of the\\n  1249\u2192input labels. Defaults to `false`.\\n  1250\u2192end::inference-config-zero-shot-classification-multi-label[]\\n  1251\u2192\\n  1252\u2192tag::inference-metadata-feature-importance-feature-name[]\\n  1253\u2192The feature for which this importance was calculated.\\n  1254\u2192end::inference-metadata-feature-importance-feature-name[]\\n  1255\u2192tag::inference-metadata-feature-importance-magnitude[]\\n  1256\u2192The average magnitude of this feature across all the training data.\\n  1257\u2192This value is the average of the absolute values of the importance\\n  1258\u2192for this feature.\\n  1259\u2192end::inference-metadata-feature-importance-magnitude[]\\n  1260\u2192tag::inference-metadata-feature-importance-max[]\\n  1261\u2192The maximum importance value across all the training data for this\\n  1262\u2192feature.\\n  1263\u2192end::inference-metadata-feature-importance-max[]\\n  1264\u2192tag::inference-metadata-feature-importance-min[]\\n  1265\u2192The minimum importance value across all the training data for this\\n  1266\u2192feature.\\n  1267\u2192end::inference-metadata-feature-importance-min[]\\n  1268\u2192\\n  1269\u2192tag::influencers[]\\n  1270\u2192A comma separated list of influencer field names. Typically these can be the by,\\n  1271\u2192over, or partition fields that are used in the detector configuration. You might\\n  1272\u2192also want to use a field name that is not specifically named in a detector, but\\n  1273\u2192is available as part of the input data. When you use multiple detectors, the use\\n  1274\u2192of influencers is recommended as it aggregates results for each influencer\\n  1275\u2192entity.\\n  1276\u2192end::influencers[]\\n  1277\u2192\\n  1278\u2192tag::input-bytes[]\\n  1279\u2192The number of bytes of input data posted to the {anomaly-job}.\\n  1280\u2192end::input-bytes[]\\n  1281\u2192\\n  1282\u2192tag::input-field-count[]\\n  1283\u2192The total number of fields in input documents posted to the {anomaly-job}. This\\n  1284\u2192count includes fields that are not used in the analysis. However, be aware that\\n  1285\u2192if you are using a {dfeed}, it extracts only the required fields from the\\n  1286\u2192documents it retrieves before posting them to the job.\\n  1287\u2192end::input-field-count[]\\n  1288\u2192\\n  1289\u2192tag::input-record-count[]\\n  1290\u2192The number of input documents posted to the {anomaly-job}.\\n  1291\u2192end::input-record-count[]\\n  1292\u2192\\n  1293\u2192tag::invalid-date-count[]\\n  1294\u2192The number of input documents with either a missing date field or a date that\\n  1295\u2192could not be parsed.\\n  1296\u2192end::invalid-date-count[]\\n  1297\u2192\\n  1298\u2192tag::is-interim[]\\n  1299\u2192If `true`, this is an interim result. In other words, the results are calculated\\n  1300\u2192based on partial input data.\\n  1301\u2192end::is-interim[]\\n  1302\u2192\\n  1303\u2192tag::job-id-anomaly-detection[]\\n  1304\u2192Identifier for the {anomaly-job}.\\n  1305\u2192end::job-id-anomaly-detection[]\\n  1306\u2192\\n  1307\u2192tag::job-id-data-frame-analytics[]\\n  1308\u2192Identifier for the {dfanalytics-job}.\\n  1309\u2192end::job-id-data-frame-analytics[]\\n  1310\u2192\\n  1311\u2192tag::job-id-anomaly-detection-default[]\\n  1312\u2192Identifier for the {anomaly-job}. It can be a job identifier, a group name, or a\\n  1313\u2192wildcard expression. If you do not specify one of these options, the API returns\\n  1314\u2192information for all {anomaly-jobs}.\\n  1315\u2192end::job-id-anomaly-detection-default[]\\n  1316\u2192\\n  1317\u2192tag::job-id-data-frame-analytics-default[]\\n  1318\u2192Identifier for the {dfanalytics-job}. If you do not specify this option, the API\\n  1319\u2192returns information for the first hundred {dfanalytics-jobs}.\\n  1320\u2192end::job-id-data-frame-analytics-default[]\\n  1321\u2192\\n  1322\u2192tag::job-id-anomaly-detection-list[]\\n  1323\u2192An identifier for the {anomaly-jobs}. It can be a job\\n  1324\u2192identifier, a group name, or a comma-separated list of jobs or groups.\\n  1325\u2192end::job-id-anomaly-detection-list[]\\n  1326\u2192\\n  1327\u2192tag::job-id-anomaly-detection-wildcard[]\\n  1328\u2192Identifier for the {anomaly-job}. It can be a job identifier, a group name, or a\\n  1329\u2192wildcard expression.\\n  1330\u2192end::job-id-anomaly-detection-wildcard[]\\n  1331\u2192\\n  1332\u2192tag::job-id-anomaly-detection-wildcard-list[]\\n  1333\u2192Identifier for the {anomaly-job}. It can be a job identifier, a group name, a\\n  1334\u2192comma-separated list of jobs or groups, or a wildcard expression.\\n  1335\u2192end::job-id-anomaly-detection-wildcard-list[]\\n  1336\u2192\\n  1337\u2192tag::job-id-anomaly-detection-define[]\\n  1338\u2192Identifier for the {anomaly-job}. This identifier can contain lowercase\\n  1339\u2192alphanumeric characters (a-z and 0-9), hyphens, and underscores. It must start\\n  1340\u2192and end with alphanumeric characters.\\n  1341\u2192end::job-id-anomaly-detection-define[]\\n  1342\u2192\\n  1343\u2192tag::job-id-data-frame-analytics-define[]\\n  1344\u2192Identifier for the {dfanalytics-job}. This identifier can contain lowercase\\n  1345\u2192alphanumeric characters (a-z and 0-9), hyphens, and underscores. It must start\\n  1346\u2192and end with alphanumeric characters.\\n  1347\u2192end::job-id-data-frame-analytics-define[]\\n  1348\u2192\\n  1349\u2192tag::job-id-datafeed[]\\n  1350\u2192The unique identifier for the job to which the {dfeed} sends data.\\n  1351\u2192end::job-id-datafeed[]\\n  1352\u2192\\n  1353\u2192tag::output-memory-allocator-bytes[]\\n  1354\u2192The amount of memory, in bytes, used to output {anomaly-job} documents.\\n  1355\u2192end::output-memory-allocator-bytes[]\\n  1356\u2192\\n  1357\u2192tag::lambda[]\\n  1358\u2192Advanced configuration option. Regularization parameter to prevent overfitting\\n  1359\u2192on the training data set. Multiplies an L2 regularization term which applies to\\n  1360\u2192leaf weights of the individual trees in the forest. A high lambda value causes\\n  1361\u2192training to favor small leaf weights. This behavior makes the prediction\\n  1362\u2192function smoother at the expense of potentially not being able to capture\\n  1363\u2192relevant relationships between the features and the {depvar}. A small lambda\\n  1364\u2192value results in large individual trees and slower training. By default, this\\n  1365\u2192value is calculated during hyperparameter optimization. It must be a nonnegative\\n  1366\u2192value.\\n  1367\u2192end::lambda[]\\n  1368\u2192\\n  1369\u2192tag::last-data-time[]\\n  1370\u2192The timestamp at which data was last analyzed, according to server time.\\n  1371\u2192end::last-data-time[]\\n  1372\u2192\\n  1373\u2192tag::latency[]\\n  1374\u2192The size of the window in which to expect data that is out of time order. The\\n  1375\u2192default value is 0 (no latency). If you specify a non-zero value, it must be\\n  1376\u2192greater than or equal to one second. For more information about time units, see\\n  1377\u2192<<time-units>>.\\n  1378\u2192+\\n  1379\u2192--\\n  1380\u2192NOTE: Latency is only applicable when you send data by using\\n  1381\u2192the <<ml-post-data,post data>> API.\\n  1382\u2192\\n  1383\u2192--\\n  1384\u2192end::latency[]\\n  1385\u2192\\n  1386\u2192tag::latest-empty-bucket-timestamp[]\\n  1387\u2192The timestamp of the last bucket that did not contain any data.\\n  1388\u2192end::latest-empty-bucket-timestamp[]\\n  1389\u2192\\n  1390\u2192tag::latest-record-timestamp[]\\n  1391\u2192The timestamp of the latest chronologically input document.\\n  1392\u2192end::latest-record-timestamp[]\\n  1393\u2192\\n  1394\u2192tag::latest-sparse-record-timestamp[]\\n  1395\u2192The timestamp of the last bucket that was considered sparse.\\n  1396\u2192end::latest-sparse-record-timestamp[]\\n  1397\u2192\\n  1398\u2192tag::max-empty-searches[]\\n  1399\u2192If a real-time {dfeed} has never seen any data (including during any initial\\n  1400\u2192training period) then it will automatically stop itself and close its associated\\n  1401\u2192job after this many real-time searches that return no documents. In other words,\\n  1402\u2192it will stop after `frequency` times `max_empty_searches` of real-time\\n  1403\u2192operation. If not set then a {dfeed} with no end time that sees no data will\\n  1404\u2192remain started until it is explicitly stopped. By default this setting is not\\n  1405\u2192set.\\n  1406\u2192end::max-empty-searches[]\\n  1407\u2192\\n  1408\u2192tag::max-trees[]\\n  1409\u2192Advanced configuration option. Defines the maximum number of decision trees in\\n  1410\u2192the forest. The maximum value is 2000. By default, this value is calculated\\n  1411\u2192during hyperparameter optimization.\\n  1412\u2192end::max-trees[]\\n  1413\u2192\\n  1414\u2192tag::max-trees-trained-models[]\\n  1415\u2192The maximum number of decision trees in the forest. The maximum value is 2000.\\n  1416\u2192By default, this value is calculated during hyperparameter optimization.\\n  1417\u2192end::max-trees-trained-models[]\\n  1418\u2192\\n  1419\u2192tag::meta[]\\n  1420\u2192Advanced configuration option. Contains custom metadata about the job. For\\n  1421\u2192example, it can contain custom URL information.\\n  1422\u2192end::meta[]\\n  1423\u2192\\n  1424\u2192tag::method[]\\n  1425\u2192The method that {oldetection} uses. Available methods are `lof`, `ldof`,\\n  1426\u2192`distance_kth_nn`, `distance_knn`, and `ensemble`. The default value is\\n  1427\u2192`ensemble`, which means that {oldetection} uses an ensemble of different methods\\n  1428\u2192and normalises and combines their individual {olscores} to obtain the overall\\n  1429\u2192{olscore}.\\n  1430\u2192end::method[]\\n  1431\u2192\\n  1432\u2192tag::missing-field-count[]\\n  1433\u2192The number of input documents that are missing a field that the {anomaly-job} is\\n  1434\u2192configured to analyze. Input documents with missing fields are still processed\\n  1435\u2192because it is possible that not all fields are missing.\\n  1436\u2192+\\n  1437\u2192--\\n  1438\u2192NOTE: If you are using {dfeeds} or posting data to the job in JSON format, a\\n  1439\u2192high `missing_field_count` is often not an indication of data issues. It is not\\n  1440\u2192necessarily a cause for concern.\\n  1441\u2192\\n  1442\u2192--\\n  1443\u2192end::missing-field-count[]\\n  1444\u2192\\n  1445\u2192tag::mode[]\\n  1446\u2192There are three available modes:\\n  1447\u2192+\\n  1448\u2192--\\n  1449\u2192* `auto`: The chunk size is dynamically calculated. This is the default and\\n  1450\u2192recommended value when the {dfeed} does not use aggregations.\\n  1451\u2192* `manual`: Chunking is applied according to the specified `time_span`. Use this\\n  1452\u2192mode when the {dfeed} uses aggregations.\\n  1453\u2192* `off`: No chunking is applied.\\n  1454\u2192--\\n  1455\u2192end::mode[]\\n  1456\u2192\\n  1457\u2192tag::model-bytes[]\\n  1458\u2192The number of bytes of memory used by the models. This is the maximum value\\n  1459\u2192since the last time the model was persisted. If the job is closed, this value\\n  1460\u2192indicates the latest size.\\n  1461\u2192end::model-bytes[]\\n  1462\u2192\\n  1463\u2192tag::model-bytes-exceeded[]\\n  1464\u2192The number of bytes over the high limit for memory usage at the last allocation\\n  1465\u2192failure.\\n  1466\u2192end::model-bytes-exceeded[]\\n  1467\u2192\\n  1468\u2192tag::model-id[]\\n  1469\u2192The unique identifier of the trained model.\\n  1470\u2192end::model-id[]\\n  1471\u2192\\n  1472\u2192tag::model-id-or-alias[]\\n  1473\u2192The unique identifier of the trained model or a model alias.\\n  1474\u2192end::model-id-or-alias[]\\n  1475\u2192\\n  1476\u2192tag::model-memory-limit-ad[]\\n  1477\u2192The approximate maximum amount of memory resources that are required for\\n  1478\u2192analytical processing. Once this limit is approached, data pruning becomes\\n  1479\u2192more aggressive. Upon exceeding this limit, new entities are not modeled. The\\n  1480\u2192default value for jobs created in version 6.1 and later is `1024mb`. If the\\n  1481\u2192`xpack.ml.max_model_memory_limit` setting has a value greater than `0` and less\\n  1482\u2192than `1024mb`, however, that value is used instead. If\\n  1483\u2192`xpack.ml.max_model_memory_limit` is not set, but\\n  1484\u2192`xpack.ml.use_auto_machine_memory_percent` is set, then the default\\n  1485\u2192`model_memory_limit` will be set to the largest size that could be assigned in\\n  1486\u2192the cluster, capped at `1024mb`. The default value is relatively small to\\n  1487\u2192ensure that high resource usage is a conscious decision. If you have jobs that\\n  1488\u2192are expected to analyze high cardinality fields, you will likely need to use a\\n  1489\u2192higher value.\\n  1490\u2192+\\n  1491\u2192--\\n  1492\u2192NOTE: From {es} 8.10.0,  a new version number is used to\\n  1493\u2192track the configuration and state changes in the {ml} plugin. This new\\n  1494\u2192version number is decoupled from the product version and will increment\\n  1495\u2192independently.\\n  1496\u2192--\\n  1497\u2192+\\n  1498\u2192If you specify a number instead of a string, the units are assumed to be MiB.\\n  1499\u2192Specifying a string is recommended for clarity. If you specify a byte size unit\\n  1500\u2192of `b` or `kb` and the number does not equate to a discrete number of megabytes,\\n  1501\u2192it is rounded down to the closest MiB. The minimum valid value is 1 MiB. If you\\n  1502\u2192specify a value less than 1 MiB, an error occurs. For more information about\\n  1503\u2192supported byte size units, see <<byte-units>>.\\n  1504\u2192+\\n  1505\u2192If you specify a value for the `xpack.ml.max_model_memory_limit` setting, an\\n  1506\u2192error occurs when you try to create jobs that have `model_memory_limit` values\\n  1507\u2192greater than that setting value. For more information, see <<ml-settings>>.\\n  1508\u2192end::model-memory-limit-ad[]\\n  1509\u2192\\n  1510\u2192tag::model-memory-limit-anomaly-jobs[]\\n  1511\u2192The upper limit for model memory usage, checked on increasing values.\\n  1512\u2192end::model-memory-limit-anomaly-jobs[]\\n  1513\u2192\\n  1514\u2192tag::model-memory-limit-dfa[]\\n  1515\u2192The approximate maximum amount of memory resources that are permitted for\\n  1516\u2192analytical processing. The default value for {dfanalytics-jobs} is `1gb`. If\\n  1517\u2192you specify a value for the `xpack.ml.max_model_memory_limit` setting, an error\\n  1518\u2192occurs when you try to create jobs that have `model_memory_limit` values greater\\n  1519\u2192than that setting value. For more information, see\\n  1520\u2192<<ml-settings>>.\\n  1521\u2192end::model-memory-limit-dfa[]\\n  1522\u2192\\n  1523\u2192tag::model-memory-status[]\\n  1524\u2192The status of the mathematical models, which can have one of the following\\n  1525\u2192values:\\n  1526\u2192+\\n  1527\u2192--\\n  1528\u2192* `ok`: The models stayed below the configured value.\\n  1529\u2192* `soft_limit`: The models used more than 60% of the configured memory limit\\n  1530\u2192and older unused models will be pruned to free up space. Additionally, in\\n  1531\u2192categorization jobs no further category examples will be stored.\\n  1532\u2192* `hard_limit`: The models used more space than the configured memory limit.\\n  1533\u2192As a result, not all incoming data was processed.\\n  1534\u2192--\\n  1535\u2192end::model-memory-status[]\\n  1536\u2192\\n  1537\u2192tag::model-plot-config[]\\n  1538\u2192This advanced configuration option stores model information along with the\\n  1539\u2192results. It provides a more detailed view into {anomaly-detect}.\\n  1540\u2192+\\n  1541\u2192--\\n  1542\u2192WARNING: If you enable model plot it can add considerable overhead to the\\n  1543\u2192performance of the system; it is not feasible for jobs with many entities.\\n  1544\u2192\\n  1545\u2192Model plot provides a simplified and indicative view of the model and its\\n  1546\u2192bounds. It does not display complex features such as multivariate correlations\\n  1547\u2192or multimodal data. As such, anomalies may occasionally be reported which cannot\\n  1548\u2192be seen in the model plot.\\n  1549\u2192\\n  1550\u2192Model plot config can be configured when the job is created or updated later. It\\n  1551\u2192must be disabled if performance issues are experienced.\\n  1552\u2192--\\n  1553\u2192end::model-plot-config[]\\n  1554\u2192\\n  1555\u2192tag::model-plot-config-annotations-enabled[]\\n  1556\u2192If true, enables calculation and storage of the model change annotations\\n  1557\u2192for each entity that is being analyzed. Defaults to `enabled`.\\n  1558\u2192end::model-plot-config-annotations-enabled[]\\n  1559\u2192\\n  1560\u2192tag::model-plot-config-enabled[]\\n  1561\u2192If true, enables calculation and storage of the model bounds for each entity\\n  1562\u2192that is being analyzed. By default, this is not enabled.\\n  1563\u2192end::model-plot-config-enabled[]\\n  1564\u2192\\n  1565\u2192tag::model-plot-config-terms[]\\n  1566\u2192Limits data collection to this comma separated list of partition or by field\\n  1567\u2192values. If terms are not specified or it is an empty string, no filtering is\\n  1568\u2192applied. For example, \\\"CPU,NetworkIn,DiskWrites\\\". Wildcards are not supported.\\n  1569\u2192Only the specified `terms` can be viewed when using the Single Metric Viewer.\\n  1570\u2192end::model-plot-config-terms[]\\n  1571\u2192\\n  1572\u2192tag::model-prune-window[]\\n  1573\u2192Advanced configuration option.\\n  1574\u2192Affects the pruning of models that have not been updated for the given time\\n  1575\u2192duration. The value must be set to a multiple of the `bucket_span`. If set too\\n  1576\u2192low, important information may be removed from the model. Typically, set to\\n  1577\u2192`30d` or longer. If not set, model pruning only occurs if the model memory\\n  1578\u2192status reaches the soft limit or the hard limit. For jobs created in 8.1 and\\n  1579\u2192later, the default value is the greater of `30d` or 20 times `bucket_span`.\\n  1580\u2192end::model-prune-window[]\\n  1581\u2192\\n  1582\u2192tag::model-snapshot-id[]\\n  1583\u2192A numerical character string that uniquely identifies the model snapshot. For\\n  1584\u2192example, `1575402236000`.\\n  1585\u2192end::model-snapshot-id[]\\n  1586\u2192\\n  1587\u2192tag::model-snapshot-retention-days[]\\n  1588\u2192Advanced configuration option, which affects the automatic removal of old model\\n  1589\u2192snapshots for this job. It specifies the maximum period of time (in days) that\\n  1590\u2192snapshots are retained. This period is relative to the timestamp of the most\\n  1591\u2192recent snapshot for this job. The default value is `10`, which means snapshots\\n  1592\u2192ten days older than the newest snapshot are deleted. For more information, refer\\n  1593\u2192to {ml-docs}/ml-ad-run-jobs.html#ml-ad-model-snapshots[Model snapshots].\\n  1594\u2192end::model-snapshot-retention-days[]\\n  1595\u2192\\n  1596\u2192tag::model-timestamp[]\\n  1597\u2192The timestamp of the last record when the model stats were gathered.\\n  1598\u2192end::model-timestamp[]\\n  1599\u2192\\n  1600\u2192tag::multivariate-by-fields[]\\n  1601\u2192This functionality is reserved for internal use. It is not supported for use in\\n  1602\u2192customer environments and is not subject to the support SLA of official GA\\n  1603\u2192features.\\n  1604\u2192+\\n  1605\u2192--\\n  1606\u2192If set to `true`, the analysis will automatically find correlations between\\n  1607\u2192metrics for a given `by` field value and report anomalies when those\\n  1608\u2192correlations cease to hold. For example, suppose CPU and memory usage on host A\\n  1609\u2192is usually highly correlated with the same metrics on host B. Perhaps this\\n  1610\u2192correlation occurs because they are running a load-balanced application.\\n  1611\u2192If you enable this property, then anomalies will be reported when, for example,\\n  1612\u2192CPU usage on host A is high and the value of CPU usage on host B is low. That\\n  1613\u2192is to say, you'll see an anomaly when the CPU of host A is unusual given\\n  1614\u2192the CPU of host B.\\n  1615\u2192\\n  1616\u2192NOTE: To use the `multivariate_by_fields` property, you must also specify\\n  1617\u2192`by_field_name` in your detector.\\n  1618\u2192\\n  1619\u2192--\\n  1620\u2192end::multivariate-by-fields[]\\n  1621\u2192\\n  1622\u2192tag::n-neighbors[]\\n  1623\u2192Defines the value for how many nearest neighbors each method of {oldetection}\\n  1624\u2192uses to calculate its {olscore}. When the value is not set, different values are\\n  1625\u2192used for different ensemble members. This default behavior helps improve the\\n  1626\u2192diversity in the ensemble; only override it if you are confident that the value\\n  1627\u2192you choose is appropriate for the data set.\\n  1628\u2192end::n-neighbors[]\\n  1629\u2192\\n  1630\u2192tag::node-address[]\\n  1631\u2192The network address of the node.\\n  1632\u2192end::node-address[]\\n  1633\u2192\\n  1634\u2192tag::node-attributes[]\\n  1635\u2192Lists node attributes such as `ml.machine_memory` or `ml.max_open_jobs` settings.\\n  1636\u2192end::node-attributes[]\\n  1637\u2192\\n  1638\u2192tag::node-datafeeds[]\\n  1639\u2192For started {dfeeds} only, this information pertains to the node upon which the\\n  1640\u2192{dfeed} is started.\\n  1641\u2192end::node-datafeeds[]\\n  1642\u2192\\n  1643\u2192tag::node-ephemeral-id[]\\n  1644\u2192The ephemeral ID of the node.\\n  1645\u2192end::node-ephemeral-id[]\\n  1646\u2192\\n  1647\u2192tag::node-id[]\\n  1648\u2192The unique identifier of the node.\\n  1649\u2192end::node-id[]\\n  1650\u2192\\n  1651\u2192tag::node-jobs[]\\n  1652\u2192Contains properties for the node that runs the job. This information is\\n  1653\u2192available only for open jobs.\\n  1654\u2192end::node-jobs[]\\n  1655\u2192\\n  1656\u2192tag::node-transport-address[]\\n  1657\u2192The host and port where transport HTTP connections are accepted.\\n  1658\u2192end::node-transport-address[]\\n  1659\u2192\\n  1660\u2192tag::open-time[]\\n  1661\u2192For open jobs only, the elapsed time for which the job has been open.\\n  1662\u2192end::open-time[]\\n  1663\u2192\\n  1664\u2192tag::out-of-order-timestamp-count[]\\n  1665\u2192The number of input documents that have a timestamp chronologically\\n  1666\u2192preceding the start of the current anomaly detection bucket offset by\\n  1667\u2192the latency window. This information is applicable only when you provide\\n  1668\u2192data to the {anomaly-job} by using the <<ml-post-data,post data API>>.\\n  1669\u2192These out of order documents are discarded, since jobs require time\\n  1670\u2192series data to be in ascending chronological order.\\n  1671\u2192end::out-of-order-timestamp-count[]\\n  1672\u2192\\n  1673\u2192tag::outlier-fraction[]\\n  1674\u2192The proportion of the data set that is assumed to be outlying prior to\\n  1675\u2192{oldetection}. For example, 0.05 means it is assumed that 5% of values are real\\n  1676\u2192outliers and 95% are inliers.\\n  1677\u2192end::outlier-fraction[]\\n  1678\u2192\\n  1679\u2192tag::over-field-name[]\\n  1680\u2192The field used to split the data. In particular, this property is used for\\n  1681\u2192analyzing the splits with respect to the history of all splits. It is used for\\n  1682\u2192finding unusual values in the population of all splits. For more information,\\n  1683\u2192see {ml-docs}/ml-configuring-populations.html[Performing population analysis].\\n  1684\u2192end::over-field-name[]\\n  1685\u2192\\n  1686\u2192tag::partition-field-name[]\\n  1687\u2192The field used to segment the analysis. When you use this property, you have\\n  1688\u2192completely independent baselines for each value of this field.\\n  1689\u2192end::partition-field-name[]\\n  1690\u2192\\n  1691\u2192tag::peak-model-bytes[]\\n  1692\u2192The peak number of bytes of memory ever used by the models.\\n  1693\u2192end::peak-model-bytes[]\\n  1694\u2192\\n  1695\u2192tag::per-partition-categorization[]\\n  1696\u2192Settings related to how categorization interacts with partition fields.\\n  1697\u2192end::per-partition-categorization[]\\n  1698\u2192\\n  1699\u2192tag::per-partition-categorization-enabled[]\\n  1700\u2192To enable this setting, you must also set the partition_field_name property to\\n  1701\u2192the same value in every detector that uses the keyword mlcategory. Otherwise,\\n  1702\u2192job creation fails.\\n  1703\u2192end::per-partition-categorization-enabled[]\\n  1704\u2192\\n  1705\u2192tag::per-partition-categorization-stop-on-warn[]\\n  1706\u2192This setting can be set to true only if per-partition categorization is enabled.\\n  1707\u2192If true, both categorization and subsequent anomaly detection stops for\\n  1708\u2192partitions where the categorization status changes to `warn`. This setting makes\\n  1709\u2192it viable to have a job where it is expected that categorization works well for\\n  1710\u2192some partitions but not others; you do not pay the cost of bad categorization\\n  1711\u2192forever in the partitions where it works badly.\\n  1712\u2192end::per-partition-categorization-stop-on-warn[]\\n  1713\u2192\\n  1714\u2192tag::prediction-field-name[]\\n  1715\u2192Defines the name of the prediction field in the results.\\n  1716\u2192Defaults to `<dependent_variable>_prediction`.\\n  1717\u2192end::prediction-field-name[]\\n  1718\u2192\\n  1719\u2192tag::processed-field-count[]\\n  1720\u2192The total number of fields in all the documents that have been processed by the\\n  1721\u2192{anomaly-job}. Only fields that are specified in the detector configuration\\n  1722\u2192object contribute to this count. The timestamp is not included in this count.\\n  1723\u2192end::processed-field-count[]\\n  1724\u2192\\n  1725\u2192tag::processed-record-count[]\\n  1726\u2192The number of input documents that have been processed by the {anomaly-job}.\\n  1727\u2192This value includes documents with missing fields, since they are nonetheless\\n  1728\u2192analyzed. If you use {dfeeds} and have aggregations in your search query, the\\n  1729\u2192`processed_record_count` is the number of aggregation results processed, not the\\n  1730\u2192number of {es} documents.\\n  1731\u2192end::processed-record-count[]\\n  1732\u2192\\n  1733\u2192tag::randomize-seed[]\\n  1734\u2192Defines the seed for the random generator that is used to pick training data. By\\n  1735\u2192default, it is randomly generated. Set it to a specific value to use the same\\n  1736\u2192training data each time you start a job (assuming other related parameters such\\n  1737\u2192as `source` and `analyzed_fields` are the same).\\n  1738\u2192end::randomize-seed[]\\n  1739\u2192\\n  1740\u2192tag::query[]\\n  1741\u2192The {es} query domain-specific language (DSL). This value corresponds to the\\n  1742\u2192query object in an {es} search POST body. All the options that are supported by\\n  1743\u2192{es} can be used, as this object is passed verbatim to {es}. By default, this\\n  1744\u2192property has the following value: `{\\\"match_all\\\": {\\\"boost\\\": 1}}`.\\n  1745\u2192end::query[]\\n  1746\u2192\\n  1747\u2192tag::query-delay[]\\n  1748\u2192The number of seconds behind real time that data is queried. For example, if\\n  1749\u2192data from 10:04 a.m. might not be searchable in {es} until 10:06 a.m., set this\\n  1750\u2192property to 120 seconds. The default value is randomly selected between `60s`\\n  1751\u2192and `120s`. This randomness improves the query performance when there are\\n  1752\u2192multiple jobs running on the same node. For more information, see\\n  1753\u2192{ml-docs}/ml-delayed-data-detection.html[Handling delayed data].\\n  1754\u2192end::query-delay[]\\n  1755\u2192\\n  1756\u2192tag::rare-category-count[]\\n  1757\u2192The number of categories that match just one categorized document.\\n  1758\u2192end::rare-category-count[]\\n  1759\u2192\\n  1760\u2192tag::renormalization-window-days[]\\n  1761\u2192Advanced configuration option. The period over which adjustments to the score\\n  1762\u2192are applied, as new data is seen. The default value is the longer of 30 days or\\n  1763\u2192100 `bucket_spans`.\\n  1764\u2192end::renormalization-window-days[]\\n  1765\u2192\\n  1766\u2192tag::results-index-name[]\\n  1767\u2192A text string that affects the name of the {ml} results index. The default value\\n  1768\u2192is `shared`, which generates an index named `.ml-anomalies-shared`.\\n  1769\u2192end::results-index-name[]\\n  1770\u2192\\n  1771\u2192tag::results-retention-days[]\\n  1772\u2192Advanced configuration option. The period of time (in days) that results are\\n  1773\u2192retained. Age is calculated relative to the timestamp of the latest bucket\\n  1774\u2192result. If this property has a non-null value, once per day at 00:30 (server\\n  1775\u2192time), results that are the specified number of days older than the latest\\n  1776\u2192bucket result are deleted from {es}. The default value is null, which means all\\n  1777\u2192results are retained. Annotations generated by the system also count as results\\n  1778\u2192for retention purposes; they are deleted after the same number of days as\\n  1779\u2192results. Annotations added by users are retained forever.\\n  1780\u2192end::results-retention-days[]\\n  1781\u2192\\n  1782\u2192tag::retain[]\\n  1783\u2192If `true`, this snapshot will not be deleted during automatic cleanup of\\n  1784\u2192snapshots older than `model_snapshot_retention_days`. However, this snapshot\\n  1785\u2192will be deleted when the job is deleted. The default value is `false`.\\n  1786\u2192end::retain[]\\n  1787\u2192\\n  1788\u2192tag::script-fields[]\\n  1789\u2192Specifies scripts that evaluate custom expressions and returns script fields to\\n  1790\u2192the {dfeed}. The detector configuration objects in a job can contain functions\\n  1791\u2192that use these script fields. For more information, see\\n  1792\u2192{ml-docs}/ml-configuring-transform.html[Transforming data with script fields]\\n  1793\u2192and <<script-fields,Script fields>>.\\n  1794\u2192end::script-fields[]\\n  1795\u2192\\n  1796\u2192tag::scroll-size[]\\n  1797\u2192The `size` parameter that is used in {es} searches when the {dfeed} does not use\\n  1798\u2192aggregations. The default value is `1000`. The maximum value is the value of\\n  1799\u2192`index.max_result_window` which is 10,000 by default.\\n  1800\u2192end::scroll-size[]\\n  1801\u2192\\n  1802\u2192tag::search-bucket-avg[]\\n  1803\u2192The average search time per bucket, in milliseconds.\\n  1804\u2192end::search-bucket-avg[]\\n  1805\u2192\\n  1806\u2192tag::search-count[]\\n  1807\u2192The number of searches run by the {dfeed}.\\n  1808\u2192end::search-count[]\\n  1809\u2192\\n  1810\u2192tag::search-exp-avg-hour[]\\n  1811\u2192The exponential average search time per hour, in milliseconds.\\n  1812\u2192end::search-exp-avg-hour[]\\n  1813\u2192\\n  1814\u2192tag::search-time[]\\n  1815\u2192The total time the {dfeed} spent searching, in milliseconds.\\n  1816\u2192end::search-time[]\\n  1817\u2192\\n  1818\u2192tag::size[]\\n  1819\u2192Specifies the maximum number of {dfanalytics-jobs} to obtain. The default value\\n  1820\u2192is `100`.\\n  1821\u2192end::size[]\\n  1822\u2192\\n  1823\u2192tag::size-models[]\\n  1824\u2192Specifies the maximum number of models to obtain. The default value\\n  1825\u2192is `100`.\\n  1826\u2192end::size-models[]\\n  1827\u2192\\n  1828\u2192tag::snapshot-id[]\\n  1829\u2192Identifier for the model snapshot.\\n  1830\u2192end::snapshot-id[]\\n  1831\u2192\\n  1832\u2192tag::sparse-bucket-count[]\\n  1833\u2192The number of buckets that contained few data points compared to the expected\\n  1834\u2192number of data points. If your data contains many sparse buckets, consider using\\n  1835\u2192a longer `bucket_span`.\\n  1836\u2192end::sparse-bucket-count[]\\n  1837\u2192\\n  1838\u2192tag::standardization-enabled[]\\n  1839\u2192If `true`, the following operation is performed on the columns before computing\\n  1840\u2192outlier scores: (x_i - mean(x_i)) / sd(x_i). Defaults to `true`. For more\\n  1841\u2192information about this concept, see\\n  1842\u2192{wikipedia}/Feature_scaling#Standardization_(Z-score_Normalization)[Wikipedia].\\n  1843\u2192end::standardization-enabled[]\\n  1844\u2192\\n  1845\u2192tag::state-anomaly-job[]\\n  1846\u2192The status of the {anomaly-job}, which can be one of the following values:\\n  1847\u2192+\\n  1848\u2192--\\n  1849\u2192* `closed`: The job finished successfully with its model state persisted. The\\n  1850\u2192job must be opened before it can accept further data.\\n  1851\u2192* `closing`: The job close action is in progress and has not yet completed. A\\n  1852\u2192closing job cannot accept further data.\\n  1853\u2192* `failed`: The job did not finish successfully due to an error. This situation\\n  1854\u2192can occur due to invalid input data, a fatal error occurring during the\\n  1855\u2192analysis, or an external interaction such as the process being killed by the\\n  1856\u2192Linux out of memory (OOM) killer. If the job had irrevocably failed, it must be\\n  1857\u2192force closed and then deleted. If the {dfeed} can be corrected, the job can be\\n  1858\u2192closed and then re-opened.\\n  1859\u2192* `opened`: The job is available to receive and process data.\\n  1860\u2192* `opening`: The job open action is in progress and has not yet completed.\\n  1861\u2192--\\n  1862\u2192end::state-anomaly-job[]\\n  1863\u2192\\n  1864\u2192tag::state-datafeed[]\\n  1865\u2192The status of the {dfeed}, which can be one of the following values:\\n  1866\u2192+\\n  1867\u2192--\\n  1868\u2192* `starting`: The {dfeed} has been requested to start but has not yet started.\\n  1869\u2192* `started`: The {dfeed} is actively receiving data.\\n  1870\u2192* `stopping`: The {dfeed} has been requested to stop gracefully and is\\n  1871\u2192completing its final action.\\n  1872\u2192* `stopped`: The {dfeed} is stopped and will not receive data until it is\\n  1873\u2192re-started.\\n  1874\u2192--\\n  1875\u2192end::state-datafeed[]\\n  1876\u2192\\n  1877\u2192tag::summary-count-field-name[]\\n  1878\u2192If this property is specified, the data that is fed to the job is expected to be\\n  1879\u2192pre-summarized. This property value is the name of the field that contains the\\n  1880\u2192count of raw data points that have been summarized. The same\\n  1881\u2192`summary_count_field_name` applies to all detectors in the job.\\n  1882\u2192+\\n  1883\u2192--\\n  1884\u2192NOTE: The `summary_count_field_name` property cannot be used with the `metric`\\n  1885\u2192function.\\n  1886\u2192\\n  1887\u2192--\\n  1888\u2192end::summary-count-field-name[]\\n  1889\u2192\\n  1890\u2192tag::tags[]\\n  1891\u2192A comma delimited string of tags. A trained model can have many tags, or none.\\n  1892\u2192When supplied, only trained models that contain all the supplied tags are\\n  1893\u2192returned.\\n  1894\u2192end::tags[]\\n  1895\u2192\\n  1896\u2192tag::timeout-start[]\\n  1897\u2192Controls the amount of time to wait until the {dfanalytics-job} starts. Defaults\\n  1898\u2192to 20 seconds.\\n  1899\u2192end::timeout-start[]\\n  1900\u2192\\n  1901\u2192tag::timeout-stop[]\\n  1902\u2192Controls the amount of time to wait until the {dfanalytics-job} stops. Defaults\\n  1903\u2192to 20 seconds.\\n  1904\u2192end::timeout-stop[]\\n  1905\u2192\\n  1906\u2192tag::time-format[]\\n  1907\u2192The time format, which can be `epoch`, `epoch_ms`, or a custom pattern. The\\n  1908\u2192default value is `epoch`, which refers to UNIX or Epoch time (the number of\\n  1909\u2192seconds since 1 Jan 1970). The value `epoch_ms` indicates that time is measured\\n  1910\u2192in milliseconds since the epoch. The `epoch` and `epoch_ms` time formats accept\\n  1911\u2192either integer or real values. +\\n  1912\u2192+\\n  1913\u2192NOTE: Custom patterns must conform to the Java `DateTimeFormatter` class.\\n  1914\u2192When you use date-time formatting patterns, it is recommended that you provide\\n  1915\u2192the full date, time and time zone. For example: `yyyy-MM-dd'T'HH:mm:ssX`.\\n  1916\u2192If the pattern that you specify is not sufficient to produce a complete\\n  1917\u2192timestamp, job creation fails.\\n  1918\u2192end::time-format[]\\n  1919\u2192\\n  1920\u2192tag::time-span[]\\n  1921\u2192The time span that each search will be querying. This setting is only applicable\\n  1922\u2192when the mode is set to `manual`. For example: `3h`.\\n  1923\u2192end::time-span[]\\n  1924\u2192\\n  1925\u2192tag::timestamp-results[]\\n  1926\u2192The start time of the bucket for which these results were calculated.\\n  1927\u2192end::timestamp-results[]\\n  1928\u2192\\n  1929\u2192tag::tokenizer[]\\n  1930\u2192The name or definition of the <<analysis-tokenizers,tokenizer>> to use after\\n  1931\u2192character filters are applied. This property is compulsory if\\n  1932\u2192`categorization_analyzer` is specified as an object. Machine learning provides\\n  1933\u2192a tokenizer called `ml_standard` that tokenizes in a way that has been\\n  1934\u2192determined to produce good categorization results on a variety of log\\n  1935\u2192file formats for logs in English. If you want to use that tokenizer but\\n  1936\u2192change the character or token filters, specify `\\\"tokenizer\\\": \\\"ml_standard\\\"`\\n  1937\u2192in your `categorization_analyzer`. Additionally, the `ml_classic` tokenizer\\n  1938\u2192is available, which tokenizes in the same way as the non-customizable\\n  1939\u2192tokenizer in old versions of the product (before 6.2). `ml_classic` was\\n  1940\u2192the default categorization tokenizer in versions 6.2 to 7.13, so if you\\n  1941\u2192need categorization identical to the default for jobs created in these\\n  1942\u2192versions, specify `\\\"tokenizer\\\": \\\"ml_classic\\\"` in your `categorization_analyzer`.\\n  1943\u2192\\n  1944\u2192NOTE: From {es} 8.10.0,  a new version number is used to\\n  1945\u2192track the configuration and state changes in the {ml} plugin. This new\\n  1946\u2192version number is decoupled from the product version and will increment\\n  1947\u2192independently.\\n  1948\u2192end::tokenizer[]\\n  1949\u2192\\n  1950\u2192tag::total-by-field-count[]\\n  1951\u2192The number of `by` field values that were analyzed by the models. This value is\\n  1952\u2192cumulative for all detectors in the job.\\n  1953\u2192end::total-by-field-count[]\\n  1954\u2192\\n  1955\u2192tag::total-category-count[]\\n  1956\u2192The number of categories created by categorization.\\n  1957\u2192end::total-category-count[]\\n  1958\u2192\\n  1959\u2192tag::total-over-field-count[]\\n  1960\u2192The number of `over` field values that were analyzed by the models. This value\\n  1961\u2192is cumulative for all detectors in the job.\\n  1962\u2192end::total-over-field-count[]\\n  1963\u2192\\n  1964\u2192tag::total-partition-field-count[]\\n  1965\u2192The number of `partition` field values that were analyzed by the models. This\\n  1966\u2192value is cumulative for all detectors in the job.\\n  1967\u2192end::total-partition-field-count[]\\n  1968\u2192\\n  1969\u2192tag::training-percent[]\\n  1970\u2192Defines what percentage of the eligible documents that will\\n  1971\u2192be used for training. Documents that are ignored by the analysis (for example\\n  1972\u2192those that contain arrays with more than one value) won\u2019t be included in the\\n  1973\u2192calculation for used percentage. Defaults to `100`.\\n  1974\u2192end::training-percent[]\\n  1975\u2192\\n  1976\u2192tag::use-null[]\\n  1977\u2192Defines whether a new series is used as the null series when there is no value\\n  1978\u2192for the by or partition fields. The default value is `false`.\\n  1979\u2192end::use-null[]\\n  1980\u2192\\n  1981\u2192tag::verbose[]\\n  1982\u2192Defines whether the stats response should be verbose. The default value is `false`.\\n  1983\u2192end::verbose[]\\n  1984\u2192\\n\\n<system-reminder>\\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\\n</system-reminder>\\n\"}]},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"de2104ae-4adb-4c46-8f23-267d8570d451\"}\n{\"type\":\"assistant\",\"message\":{\"model\":\"claude-sonnet-4-5-20250929\",\"id\":\"msg_019DfqSkLjN9hMqfxxn8hRAh\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[{\"type\":\"text\",\"text\":\"Perfect! I found the issue. In the file `/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/ml-shared.asciidoc`, on line 6, there's a sentence that states: \\\"The number of model allocations cannot be scaled down to less than `1` this way.\\\"\\n\\nAccording to the task description, adaptive allocations can now scale down to `0` allocations, so this sentence needs to be removed. Let me read the file more carefully around that section and then make the edit.\"}],\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":8859,\"cache_creation_input_tokens\":29412,\"cache_read_input_tokens\":23631,\"cache_creation\":{\"ephemeral_5m_input_tokens\":29412,\"ephemeral_1h_input_tokens\":0},\"output_tokens\":1,\"service_tier\":\"standard\"}},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"bc4832f0-42af-4f32-b1d2-4bf330b4c80d\"}\n{\"type\":\"assistant\",\"message\":{\"model\":\"claude-sonnet-4-5-20250929\",\"id\":\"msg_019DfqSkLjN9hMqfxxn8hRAh\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[{\"type\":\"tool_use\",\"id\":\"toolu_01K7skizZKx1uBXkQNEe8csw\",\"name\":\"Read\",\"input\":{\"file_path\":\"/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/ml-shared.asciidoc\",\"offset\":1,\"limit\":25}}],\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":8859,\"cache_creation_input_tokens\":29412,\"cache_read_input_tokens\":23631,\"cache_creation\":{\"ephemeral_5m_input_tokens\":29412,\"ephemeral_1h_input_tokens\":0},\"output_tokens\":1,\"service_tier\":\"standard\"}},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"9e6ff1dc-80dc-41c7-a193-0caa4c92e306\"}\n{\"type\":\"user\",\"message\":{\"role\":\"user\",\"content\":[{\"tool_use_id\":\"toolu_01K7skizZKx1uBXkQNEe8csw\",\"type\":\"tool_result\",\"content\":\"     1\u2192tag::adaptive-allocation[]\\n     2\u2192Adaptive allocations configuration object.\\n     3\u2192If enabled, the number of allocations of the model is set based on the current load the process gets.\\n     4\u2192When the load is high, a new model allocation is automatically created (respecting the value of `max_number_of_allocations` if it's set).\\n     5\u2192When the load is low, a model allocation is automatically removed (respecting the value of `min_number_of_allocations` if it's set).\\n     6\u2192The number of model allocations cannot be scaled down to less than `1` this way.\\n     7\u2192If `adaptive_allocations` is enabled, do not set the number of allocations manually.\\n     8\u2192end::adaptive-allocation[]\\n     9\u2192\\n    10\u2192tag::adaptive-allocation-enabled[]\\n    11\u2192If `true`, `adaptive_allocations` is enabled.\\n    12\u2192Defaults to `false`.\\n    13\u2192end::adaptive-allocation-enabled[]\\n    14\u2192\\n    15\u2192tag::adaptive-allocation-max-number[]\\n    16\u2192Specifies the maximum number of allocations to scale to.\\n    17\u2192If set, it must be greater than or equal to `min_number_of_allocations`.\\n    18\u2192end::adaptive-allocation-max-number[]\\n    19\u2192\\n    20\u2192tag::adaptive-allocation-min-number[]\\n    21\u2192Specifies the minimum number of allocations to scale to.\\n    22\u2192If set, it must be greater than or equal to `1`.\\n    23\u2192end::adaptive-allocation-min-number[]\\n    24\u2192\\n    25\u2192tag::aggregations[]\\n\\n<system-reminder>\\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\\n</system-reminder>\\n\"}]},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"de94ba6f-648a-4f5e-b64f-c3d5e4e5f178\"}\n{\"type\":\"assistant\",\"message\":{\"model\":\"claude-sonnet-4-5-20250929\",\"id\":\"msg_01QdztcqofPqVZDqdvawFgG6\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[{\"type\":\"text\",\"text\":\"Perfect! I can see the issue. On line 6, there's the sentence \\\"The number of model allocations cannot be scaled down to less than `1` this way.\\\" that needs to be removed. I also notice on line 22 there's another constraint that says minimum allocations \\\"must be greater than or equal to `1`\\\" which may also need to be updated to allow `0`.\\n\\nLet me check if there are any other references to this constraint in the documentation:\"}],\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":5,\"cache_creation_input_tokens\":9634,\"cache_read_input_tokens\":53043,\"cache_creation\":{\"ephemeral_5m_input_tokens\":9634,\"ephemeral_1h_input_tokens\":0},\"output_tokens\":1,\"service_tier\":\"standard\"}},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"36156613-c294-4b27-9f74-eba59544e109\"}\n{\"type\":\"assistant\",\"message\":{\"model\":\"claude-sonnet-4-5-20250929\",\"id\":\"msg_01QdztcqofPqVZDqdvawFgG6\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[{\"type\":\"tool_use\",\"id\":\"toolu_01PVWA9QsTxP2NvwwMfdxrvy\",\"name\":\"Grep\",\"input\":{\"pattern\":\"greater than or equal to.*1|min.*allocat.*1\",\"output_mode\":\"content\",\"-n\":true,\"-C\":2,\"path\":\"/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs\"}}],\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":5,\"cache_creation_input_tokens\":9634,\"cache_read_input_tokens\":53043,\"cache_creation\":{\"ephemeral_5m_input_tokens\":9634,\"ephemeral_1h_input_tokens\":0},\"output_tokens\":1,\"service_tier\":\"standard\"}},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"a54a27dc-08e4-4d6d-b570-04699dd5305d\"}\n{\"type\":\"user\",\"message\":{\"role\":\"user\",\"content\":[{\"tool_use_id\":\"toolu_01PVWA9QsTxP2NvwwMfdxrvy\",\"type\":\"tool_result\",\"content\":\"/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/runtime.asciidoc-1179-You can now retrieve calculated values in a search query, and find documents\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/runtime.asciidoc-1180-based on precise values. The following range query returns all documents where\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/runtime.asciidoc:1181:the calculated `voltage_corrected` is greater than or equal to `16`, but less\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/runtime.asciidoc-1182-than or equal to `20`. Again, use the <<search-fields,`fields`>> parameter on\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/runtime.asciidoc-1183-the `_search` API to retrieve the fields you want:\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/runtime.asciidoc-1544-You can also run a <<query-dsl-range-query,range query>> that operates on the\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/runtime.asciidoc-1545-`timestamp` field. The following query returns any documents where the\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/runtime.asciidoc:1546:`timestamp` is greater than or equal to `2020-04-30T14:31:27-05:00`:\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/runtime.asciidoc-1547-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/mapping/runtime.asciidoc-1548-[source,console]\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/rest-api/common-parms.asciidoc-1336-query. A higher value will improve result relevance at the cost of performance. The final\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/rest-api/common-parms.asciidoc-1337-ranked result set is pruned down to the search request's <<search-size-param, size>>.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/rest-api/common-parms.asciidoc:1338:`rank_window_size` must be greater than or equal to `size` and greater than or equal to `1`.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/rest-api/common-parms.asciidoc-1339-Defaults to the `size` parameter.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/rest-api/common-parms.asciidoc-1340-end::rrf-rank-window-size[]\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/esql-examples.asciidoc-95-* Enriches the \\\"user.name\\\" field with LDAP group information.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/esql-examples.asciidoc-96-* Filters out results where \\\"group.name\\\" is not null.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/esql-examples.asciidoc:97:* Uses a \\\"CASE\\\" statement to create a \\\"follow_up\\\" field, setting it to \\\"true\\\" when \\\"destcount\\\" is greater than or equal to 100 and \\\"false\\\" otherwise.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/esql-examples.asciidoc-98-* Sorts the results by \\\"destcount\\\" in descending order.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/esql/esql-examples.asciidoc-99-* Keeps selected fields: \\\"destcount,\\\" \\\"host.name,\\\" \\\"user.name,\\\" \\\"group.name,\\\" and \\\"follow_up.\\\"\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc-217-The following example starts a new deployment of the `my_model` trained model\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc-218-with the ID `my_model_for_search` and enables adaptive allocations with the\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc:219:minimum number of 3 allocations and the maximum number of 10. \\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc-220-\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/trained-models/apis/start-trained-model-deployment.asciidoc-221-[source,console]\\n--\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/ml-shared.asciidoc-20-tag::adaptive-allocation-min-number[]\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/ml-shared.asciidoc-21-Specifies the minimum number of allocations to scale to.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/ml-shared.asciidoc:22:If set, it must be greater than or equal to `1`.\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/ml-shared.asciidoc-23-end::adaptive-allocation-min-number[]\\n/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/ml-shared.asciidoc-24-\"}]},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"efd16576-6764-4811-b6cc-57422d355312\"}\n{\"type\":\"assistant\",\"message\":{\"model\":\"claude-sonnet-4-5-20250929\",\"id\":\"msg_01LtUE1hv99h7B8We7eKGppS\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[{\"type\":\"text\",\"text\":\"Good! I found the two places in the documentation that need to be updated:\\n\\n1. Line 6: \\\"The number of model allocations cannot be scaled down to less than `1` this way.\\\" - This sentence needs to be removed.\\n2. Line 22: \\\"If set, it must be greater than or equal to `1`.\\\" - This needs to be changed to allow `0`.\\n\\nNow let me make the edits:\"}],\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":4,\"cache_creation_input_tokens\":2939,\"cache_read_input_tokens\":62677,\"cache_creation\":{\"ephemeral_5m_input_tokens\":2939,\"ephemeral_1h_input_tokens\":0},\"output_tokens\":1,\"service_tier\":\"standard\"}},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"c5310fbb-60c4-4ddf-aed2-ccb53cb4383f\"}\n{\"type\":\"assistant\",\"message\":{\"model\":\"claude-sonnet-4-5-20250929\",\"id\":\"msg_01LtUE1hv99h7B8We7eKGppS\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[{\"type\":\"tool_use\",\"id\":\"toolu_013uL97gXzj92Qs1dzhvK7pq\",\"name\":\"Edit\",\"input\":{\"file_path\":\"/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/ml-shared.asciidoc\",\"old_string\":\"tag::adaptive-allocation[]\\nAdaptive allocations configuration object.\\nIf enabled, the number of allocations of the model is set based on the current load the process gets.\\nWhen the load is high, a new model allocation is automatically created (respecting the value of `max_number_of_allocations` if it's set).\\nWhen the load is low, a model allocation is automatically removed (respecting the value of `min_number_of_allocations` if it's set).\\nThe number of model allocations cannot be scaled down to less than `1` this way.\\nIf `adaptive_allocations` is enabled, do not set the number of allocations manually.\\nend::adaptive-allocation[]\",\"new_string\":\"tag::adaptive-allocation[]\\nAdaptive allocations configuration object.\\nIf enabled, the number of allocations of the model is set based on the current load the process gets.\\nWhen the load is high, a new model allocation is automatically created (respecting the value of `max_number_of_allocations` if it's set).\\nWhen the load is low, a model allocation is automatically removed (respecting the value of `min_number_of_allocations` if it's set).\\nIf `adaptive_allocations` is enabled, do not set the number of allocations manually.\\nend::adaptive-allocation[]\"}}],\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":4,\"cache_creation_input_tokens\":2939,\"cache_read_input_tokens\":62677,\"cache_creation\":{\"ephemeral_5m_input_tokens\":2939,\"ephemeral_1h_input_tokens\":0},\"output_tokens\":1,\"service_tier\":\"standard\"}},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"d64f0877-6eed-477b-b142-5d3637e0c419\"}\n{\"type\":\"assistant\",\"message\":{\"model\":\"claude-sonnet-4-5-20250929\",\"id\":\"msg_01LtUE1hv99h7B8We7eKGppS\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[{\"type\":\"tool_use\",\"id\":\"toolu_01Ftrn1iyUsKbBnxk28D7MaV\",\"name\":\"Edit\",\"input\":{\"file_path\":\"/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/ml-shared.asciidoc\",\"old_string\":\"tag::adaptive-allocation-min-number[]\\nSpecifies the minimum number of allocations to scale to.\\nIf set, it must be greater than or equal to `1`.\\nend::adaptive-allocation-min-number[]\",\"new_string\":\"tag::adaptive-allocation-min-number[]\\nSpecifies the minimum number of allocations to scale to.\\nIf set, it must be greater than or equal to `0`.\\nend::adaptive-allocation-min-number[]\"}}],\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":4,\"cache_creation_input_tokens\":2939,\"cache_read_input_tokens\":62677,\"cache_creation\":{\"ephemeral_5m_input_tokens\":2939,\"ephemeral_1h_input_tokens\":0},\"output_tokens\":1,\"service_tier\":\"standard\"}},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"e6d75dab-01e5-49eb-8874-df38de17e809\"}\n{\"type\":\"user\",\"message\":{\"role\":\"user\",\"content\":[{\"tool_use_id\":\"toolu_013uL97gXzj92Qs1dzhvK7pq\",\"type\":\"tool_result\",\"content\":\"The file /private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/ml-shared.asciidoc has been updated. Here's the result of running `cat -n` on a snippet of the edited file:\\n     1\u2192tag::adaptive-allocation[]\\n     2\u2192Adaptive allocations configuration object.\\n     3\u2192If enabled, the number of allocations of the model is set based on the current load the process gets.\\n     4\u2192When the load is high, a new model allocation is automatically created (respecting the value of `max_number_of_allocations` if it's set).\\n     5\u2192When the load is low, a model allocation is automatically removed (respecting the value of `min_number_of_allocations` if it's set).\\n     6\u2192If `adaptive_allocations` is enabled, do not set the number of allocations manually.\\n     7\u2192end::adaptive-allocation[]\\n     8\u2192\\n     9\u2192tag::adaptive-allocation-enabled[]\\n    10\u2192If `true`, `adaptive_allocations` is enabled.\\n    11\u2192Defaults to `false`.\"}]},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"b7b1f5aa-b4d5-4a05-b4b1-e42f74f3e7c5\"}\n{\"type\":\"user\",\"message\":{\"role\":\"user\",\"content\":[{\"tool_use_id\":\"toolu_01Ftrn1iyUsKbBnxk28D7MaV\",\"type\":\"tool_result\",\"content\":\"The file /private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/ml-shared.asciidoc has been updated. Here's the result of running `cat -n` on a snippet of the edited file:\\n    15\u2192Specifies the maximum number of allocations to scale to.\\n    16\u2192If set, it must be greater than or equal to `min_number_of_allocations`.\\n    17\u2192end::adaptive-allocation-max-number[]\\n    18\u2192\\n    19\u2192tag::adaptive-allocation-min-number[]\\n    20\u2192Specifies the minimum number of allocations to scale to.\\n    21\u2192If set, it must be greater than or equal to `0`.\\n    22\u2192end::adaptive-allocation-min-number[]\\n    23\u2192\\n    24\u2192tag::aggregations[]\\n    25\u2192If set, the {dfeed} performs aggregation searches. Support for aggregations is\\n    26\u2192limited and should be used only with low cardinality data. For more information,\"}]},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"5242b8ce-e6ad-4433-a3fd-4da6500b6e5b\"}\n{\"type\":\"assistant\",\"message\":{\"model\":\"claude-sonnet-4-5-20250929\",\"id\":\"msg_01SNQfFKXCLxYC8Ee9h3QRBN\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[{\"type\":\"text\",\"text\":\"Perfect! I've successfully made both necessary changes to the documentation:\\n\\n1. **Removed the sentence** stating that \\\"The number of model allocations cannot be scaled down to less than `1` this way.\\\" from the `adaptive-allocation` section (previously line 6).\\n\\n2. **Updated the minimum allocation constraint** from \\\"greater than or equal to `1`\\\" to \\\"greater than or equal to `0`\\\" in the `adaptive-allocation-min-number` section (line 21).\\n\\nLet me verify the changes by reading the updated sections:\"}],\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":5,\"cache_creation_input_tokens\":1471,\"cache_read_input_tokens\":65616,\"cache_creation\":{\"ephemeral_5m_input_tokens\":1471,\"ephemeral_1h_input_tokens\":0},\"output_tokens\":1,\"service_tier\":\"standard\"}},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"913bb29c-2a8e-47cd-9451-bf04d3fe9c60\"}\n{\"type\":\"assistant\",\"message\":{\"model\":\"claude-sonnet-4-5-20250929\",\"id\":\"msg_01SNQfFKXCLxYC8Ee9h3QRBN\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[{\"type\":\"tool_use\",\"id\":\"toolu_011vohQcb6L1UfLNYby3gbY5\",\"name\":\"Read\",\"input\":{\"file_path\":\"/private/var/folders/1t/tn_3vh3x0nv_snwb7xrv97th0000gn/T/tmp9g6o4gv7/workspace/docs/reference/ml/ml-shared.asciidoc\",\"offset\":1,\"limit\":25}}],\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":5,\"cache_creation_input_tokens\":1471,\"cache_read_input_tokens\":65616,\"cache_creation\":{\"ephemeral_5m_input_tokens\":1471,\"ephemeral_1h_input_tokens\":0},\"output_tokens\":269,\"service_tier\":\"standard\"}},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"4da35d70-3f27-48e9-b1bd-5c16a3ddca17\"}\n{\"type\":\"user\",\"message\":{\"role\":\"user\",\"content\":[{\"tool_use_id\":\"toolu_011vohQcb6L1UfLNYby3gbY5\",\"type\":\"tool_result\",\"content\":\"     1\u2192tag::adaptive-allocation[]\\n     2\u2192Adaptive allocations configuration object.\\n     3\u2192If enabled, the number of allocations of the model is set based on the current load the process gets.\\n     4\u2192When the load is high, a new model allocation is automatically created (respecting the value of `max_number_of_allocations` if it's set).\\n     5\u2192When the load is low, a model allocation is automatically removed (respecting the value of `min_number_of_allocations` if it's set).\\n     6\u2192If `adaptive_allocations` is enabled, do not set the number of allocations manually.\\n     7\u2192end::adaptive-allocation[]\\n     8\u2192\\n     9\u2192tag::adaptive-allocation-enabled[]\\n    10\u2192If `true`, `adaptive_allocations` is enabled.\\n    11\u2192Defaults to `false`.\\n    12\u2192end::adaptive-allocation-enabled[]\\n    13\u2192\\n    14\u2192tag::adaptive-allocation-max-number[]\\n    15\u2192Specifies the maximum number of allocations to scale to.\\n    16\u2192If set, it must be greater than or equal to `min_number_of_allocations`.\\n    17\u2192end::adaptive-allocation-max-number[]\\n    18\u2192\\n    19\u2192tag::adaptive-allocation-min-number[]\\n    20\u2192Specifies the minimum number of allocations to scale to.\\n    21\u2192If set, it must be greater than or equal to `0`.\\n    22\u2192end::adaptive-allocation-min-number[]\\n    23\u2192\\n    24\u2192tag::aggregations[]\\n    25\u2192If set, the {dfeed} performs aggregation searches. Support for aggregations is\\n\\n<system-reminder>\\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\\n</system-reminder>\\n\"}]},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"189de564-5029-45b9-87f5-8c1d6ba8963e\"}\n{\"type\":\"assistant\",\"message\":{\"model\":\"claude-sonnet-4-5-20250929\",\"id\":\"msg_017ybn6xnqDiku1tXwfxEqTz\",\"type\":\"message\",\"role\":\"assistant\",\"content\":[{\"type\":\"text\",\"text\":\"Excellent! The documentation has been successfully updated. The changes are:\\n\\n## Summary of Changes\\n\\nI've updated the adaptive allocations reference documentation in `docs/reference/ml/ml-shared.asciidoc`:\\n\\n1. **Removed the incorrect limitation** (line 6): Deleted the sentence \\\"The number of model allocations cannot be scaled down to less than `1` this way.\\\" which incorrectly stated that adaptive allocations could not scale down to 0.\\n\\n2. **Updated the minimum allocation constraint** (line 21): Changed the requirement from \\\"greater than or equal to `1`\\\" to \\\"greater than or equal to `0`\\\", allowing adaptive allocations to scale down to 0 allocations.\\n\\nThese changes now correctly reflect that adaptive allocations can scale down to `0` allocations, removing the outdated restriction from the documentation.\"}],\"stop_reason\":null,\"stop_sequence\":null,\"usage\":{\"input_tokens\":4,\"cache_creation_input_tokens\":748,\"cache_read_input_tokens\":67087,\"cache_creation\":{\"ephemeral_5m_input_tokens\":748,\"ephemeral_1h_input_tokens\":0},\"output_tokens\":4,\"service_tier\":\"standard\"}},\"parent_tool_use_id\":null,\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"uuid\":\"5c5dde0a-6565-4bac-8f66-51efffc9e53c\"}\n{\"type\":\"result\",\"subtype\":\"success\",\"is_error\":false,\"duration_ms\":48611,\"duration_api_ms\":54257,\"num_turns\":29,\"result\":\"Excellent! The documentation has been successfully updated. The changes are:\\n\\n## Summary of Changes\\n\\nI've updated the adaptive allocations reference documentation in `docs/reference/ml/ml-shared.asciidoc`:\\n\\n1. **Removed the incorrect limitation** (line 6): Deleted the sentence \\\"The number of model allocations cannot be scaled down to less than `1` this way.\\\" which incorrectly stated that adaptive allocations could not scale down to 0.\\n\\n2. **Updated the minimum allocation constraint** (line 21): Changed the requirement from \\\"greater than or equal to `1`\\\" to \\\"greater than or equal to `0`\\\", allowing adaptive allocations to scale down to 0 allocations.\\n\\nThese changes now correctly reflect that adaptive allocations can scale down to `0` allocations, removing the outdated restriction from the documentation.\",\"session_id\":\"f82739dd-a32c-416a-b360-7b96cbe9692b\",\"total_cost_usd\":0.36559569999999997,\"usage\":{\"input_tokens\":8885,\"cache_creation_input_tokens\":55394,\"cache_read_input_tokens\":299604,\"output_tokens\":2427,\"server_tool_use\":{\"web_search_requests\":0},\"service_tier\":\"standard\",\"cache_creation\":{\"ephemeral_1h_input_tokens\":0,\"ephemeral_5m_input_tokens\":55394}},\"modelUsage\":{\"claude-haiku-4-5-20251001\":{\"inputTokens\":441,\"outputTokens\":167,\"cacheReadInputTokens\":0,\"cacheCreationInputTokens\":0,\"webSearchRequests\":0,\"costUSD\":0.001276,\"contextWindow\":200000},\"claude-sonnet-4-5-20250929\":{\"inputTokens\":452,\"outputTokens\":153,\"cacheReadInputTokens\":0,\"cacheCreationInputTokens\":0,\"webSearchRequests\":0,\"costUSD\":0.003651,\"contextWindow\":200000},\"claude-sonnet-4-5\":{\"inputTokens\":8885,\"outputTokens\":2427,\"cacheReadInputTokens\":299604,\"cacheCreationInputTokens\":55394,\"webSearchRequests\":0,\"costUSD\":0.3606687,\"contextWindow\":200000}},\"permission_denials\":[],\"uuid\":\"dfccb9de-8d06-4400-b768-0a1b35ee703a\"}\n", "stderr": "", "returncode": 0}
