{
  "repo_url": "https://github.com/elastic/elasticsearch.git",
  "pr_number": 114911,
  "base_commit": "f6a1e36d6be56a5d480765ad2d5f72f4adcaef5b",
  "runner": "auggie",
  "model": "sonnet4.5",
  "timeout_s": 1800,
  "status": "success",
  "elapsed_ms": 644997,
  "patch_unified": "diff --git a/server/src/main/java/org/elasticsearch/search/DefaultSearchContext.java b/server/src/main/java/org/elasticsearch/search/DefaultSearchContext.java\nindex 1521b17a..8ac35f7c 100644\n--- a/server/src/main/java/org/elasticsearch/search/DefaultSearchContext.java\n+++ b/server/src/main/java/org/elasticsearch/search/DefaultSearchContext.java\n@@ -291,7 +291,7 @@ final class DefaultSearchContext extends SearchContext {\n         ToLongFunction<String> fieldCardinality\n     ) {\n         return executor instanceof ThreadPoolExecutor tpe\n-            && tpe.getQueue().isEmpty()\n+            && tpe.getQueue().size() <= tpe.getMaximumPoolSize()\n             && isParallelCollectionSupportedForResults(resultsType, request.source(), fieldCardinality, enableQueryPhaseParallelCollection)\n                 ? tpe.getMaximumPoolSize()\n                 : 1;\ndiff --git a/server/src/test/java/org/elasticsearch/search/DefaultSearchContextTests.java b/server/src/test/java/org/elasticsearch/search/DefaultSearchContextTests.java\nindex 0e4945e8..61ae9608 100644\n--- a/server/src/test/java/org/elasticsearch/search/DefaultSearchContextTests.java\n+++ b/server/src/test/java/org/elasticsearch/search/DefaultSearchContextTests.java\n@@ -79,6 +79,7 @@ import org.elasticsearch.xcontent.XContentBuilder;\n \n import java.io.IOException;\n import java.util.UUID;\n+import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.Executors;\n import java.util.function.Function;\n@@ -640,6 +641,114 @@ public class DefaultSearchContextTests extends MapperServiceTestCase {\n         );\n     }\n \n+    public void testDetermineMaximumNumberOfSlicesWithQueueSize() throws InterruptedException {\n+        IndexShard indexShard = mock(IndexShard.class);\n+        when(indexShard.shardId()).thenReturn(new ShardId(\"index\", \"uuid\", 0));\n+        ShardSearchRequest parallelReq = new ShardSearchRequest(\n+            OriginalIndices.NONE,\n+            new SearchRequest().allowPartialSearchResults(randomBoolean()),\n+            indexShard.shardId(),\n+            0,\n+            1,\n+            AliasFilter.EMPTY,\n+            1f,\n+            System.currentTimeMillis(),\n+            null\n+        );\n+        ToLongFunction<String> fieldCardinality = name -> -1;\n+\n+        int executorPoolSize = randomIntBetween(2, 10);\n+        // Create a thread pool executor with a queue\n+        ExecutorService threadPoolExecutor = EsExecutors.newFixed(\n+            \"test\",\n+            executorPoolSize,\n+            executorPoolSize * 2, // queue size is 2x pool size\n+            Thread::new,\n+            new ThreadContext(Settings.EMPTY),\n+            EsExecutors.TaskTrackingConfig.DO_NOT_TRACK\n+        );\n+\n+        try {\n+            // With empty queue, slicing should be enabled\n+            assertEquals(\n+                executorPoolSize,\n+                DefaultSearchContext.determineMaximumNumberOfSlices(\n+                    threadPoolExecutor,\n+                    parallelReq,\n+                    SearchService.ResultsType.DFS,\n+                    true,\n+                    fieldCardinality\n+                )\n+            );\n+\n+            // Fill the queue with tasks up to the pool size\n+            CountDownLatch blockLatch = new CountDownLatch(1);\n+            CountDownLatch startLatch = new CountDownLatch(executorPoolSize);\n+            for (int i = 0; i < executorPoolSize; i++) {\n+                threadPoolExecutor.execute(() -> {\n+                    startLatch.countDown();\n+                    try {\n+                        blockLatch.await();\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                });\n+            }\n+            // Wait for all threads to start\n+            startLatch.await();\n+\n+            // Add tasks to the queue up to pool size\n+            for (int i = 0; i < executorPoolSize; i++) {\n+                threadPoolExecutor.execute(() -> {\n+                    try {\n+                        blockLatch.await();\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                });\n+            }\n+\n+            // With queue size == pool size, slicing should still be enabled\n+            assertEquals(\n+                executorPoolSize,\n+                DefaultSearchContext.determineMaximumNumberOfSlices(\n+                    threadPoolExecutor,\n+                    parallelReq,\n+                    SearchService.ResultsType.DFS,\n+                    true,\n+                    fieldCardinality\n+                )\n+            );\n+\n+            // Add one more task to exceed the pool size threshold\n+            threadPoolExecutor.execute(() -> {\n+                try {\n+                    blockLatch.await();\n+                } catch (InterruptedException e) {\n+                    Thread.currentThread().interrupt();\n+                }\n+            });\n+\n+            // With queue size > pool size, slicing should be disabled\n+            assertEquals(\n+                1,\n+                DefaultSearchContext.determineMaximumNumberOfSlices(\n+                    threadPoolExecutor,\n+                    parallelReq,\n+                    SearchService.ResultsType.DFS,\n+                    true,\n+                    fieldCardinality\n+                )\n+            );\n+\n+            // Release all tasks\n+            blockLatch.countDown();\n+        } finally {\n+            threadPoolExecutor.shutdown();\n+            threadPoolExecutor.awaitTermination(10, java.util.concurrent.TimeUnit.SECONDS);\n+        }\n+    }\n+\n     public void testIsParallelCollectionSupportedForResults() {\n         SearchSourceBuilder searchSourceBuilderOrNull = randomBoolean() ? null : new SearchSourceBuilder();\n         ToLongFunction<String> fieldCardinality = name -> -1;",
  "logs_path": "auggie/sonnet4.5/a9463435/elastic_elasticsearch_pr114911/logs.jsonl",
  "errors": [],
  "edit_run_id": "a9463435",
  "test_label": "v0"
}