{
  "repo_url": "https://github.com/elastic/elasticsearch.git",
  "pr_number": 114911,
  "base_commit": "f6a1e36d6be56a5d480765ad2d5f72f4adcaef5b",
  "runner": "factory",
  "model": "claude-sonnet-4-5-20250929",
  "timeout_s": 7200,
  "status": "success",
  "elapsed_ms": 259476,
  "patch_unified": "diff --git a/server/src/main/java/org/elasticsearch/search/DefaultSearchContext.java b/server/src/main/java/org/elasticsearch/search/DefaultSearchContext.java\nindex 1521b17a..8ac35f7c 100644\n--- a/server/src/main/java/org/elasticsearch/search/DefaultSearchContext.java\n+++ b/server/src/main/java/org/elasticsearch/search/DefaultSearchContext.java\n@@ -291,7 +291,7 @@ final class DefaultSearchContext extends SearchContext {\n         ToLongFunction<String> fieldCardinality\n     ) {\n         return executor instanceof ThreadPoolExecutor tpe\n-            && tpe.getQueue().isEmpty()\n+            && tpe.getQueue().size() <= tpe.getMaximumPoolSize()\n             && isParallelCollectionSupportedForResults(resultsType, request.source(), fieldCardinality, enableQueryPhaseParallelCollection)\n                 ? tpe.getMaximumPoolSize()\n                 : 1;\ndiff --git a/server/src/test/java/org/elasticsearch/search/DefaultSearchContextTests.java b/server/src/test/java/org/elasticsearch/search/DefaultSearchContextTests.java\nindex 0e4945e8..a863b7e0 100644\n--- a/server/src/test/java/org/elasticsearch/search/DefaultSearchContextTests.java\n+++ b/server/src/test/java/org/elasticsearch/search/DefaultSearchContextTests.java\n@@ -79,6 +79,7 @@ import org.elasticsearch.xcontent.XContentBuilder;\n \n import java.io.IOException;\n import java.util.UUID;\n+import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.Executors;\n import java.util.function.Function;\n@@ -640,6 +641,113 @@ public class DefaultSearchContextTests extends MapperServiceTestCase {\n         );\n     }\n \n+    public void testDetermineMaximumNumberOfSlicesWithQueueSize() throws InterruptedException {\n+        IndexShard indexShard = mock(IndexShard.class);\n+        when(indexShard.shardId()).thenReturn(new ShardId(\"index\", \"uuid\", 0));\n+        ShardSearchRequest parallelReq = new ShardSearchRequest(\n+            OriginalIndices.NONE,\n+            new SearchRequest().allowPartialSearchResults(randomBoolean()),\n+            indexShard.shardId(),\n+            0,\n+            1,\n+            AliasFilter.EMPTY,\n+            1f,\n+            System.currentTimeMillis(),\n+            null\n+        );\n+        int executorPoolSize = randomIntBetween(2, 10);\n+        int queueSize = executorPoolSize + randomIntBetween(1, 10);\n+        // Create an executor with queue capacity\n+        ExecutorService threadPoolExecutor = EsExecutors.newFixed(\n+            \"test\",\n+            executorPoolSize,\n+            queueSize,\n+            Thread::new,\n+            new ThreadContext(Settings.EMPTY),\n+            EsExecutors.TaskTrackingConfig.DO_NOT_TRACK\n+        );\n+        ToLongFunction<String> fieldCardinality = name -> -1;\n+\n+        // Queue is empty, should allow parallelization\n+        assertEquals(\n+            executorPoolSize,\n+            DefaultSearchContext.determineMaximumNumberOfSlices(\n+                threadPoolExecutor,\n+                parallelReq,\n+                SearchService.ResultsType.DFS,\n+                true,\n+                fieldCardinality\n+            )\n+        );\n+\n+        // Use a latch to block all threads so tasks queue up\n+        final CountDownLatch blockingLatch = new CountDownLatch(1);\n+        final CountDownLatch readyLatch = new CountDownLatch(executorPoolSize);\n+        \n+        // Fill the thread pool with blocked tasks\n+        for (int i = 0; i < executorPoolSize; i++) {\n+            threadPoolExecutor.submit(() -> {\n+                try {\n+                    readyLatch.countDown();\n+                    blockingLatch.await();\n+                } catch (InterruptedException e) {\n+                    Thread.currentThread().interrupt();\n+                }\n+            });\n+        }\n+        \n+        // Wait for all threads to be occupied\n+        readyLatch.await();\n+\n+        // Now add tasks to the queue up to the threshold (equal to pool size)\n+        for (int i = 0; i < executorPoolSize; i++) {\n+            threadPoolExecutor.submit(() -> {\n+                try {\n+                    blockingLatch.await();\n+                } catch (InterruptedException e) {\n+                    Thread.currentThread().interrupt();\n+                }\n+            });\n+        }\n+\n+        // Queue size is at the threshold (equal to pool size), should still allow parallelization\n+        assertEquals(\n+            executorPoolSize,\n+            DefaultSearchContext.determineMaximumNumberOfSlices(\n+                threadPoolExecutor,\n+                parallelReq,\n+                SearchService.ResultsType.DFS,\n+                true,\n+                fieldCardinality\n+            )\n+        );\n+\n+        // Add one more task to exceed the threshold\n+        threadPoolExecutor.submit(() -> {\n+            try {\n+                blockingLatch.await();\n+            } catch (InterruptedException e) {\n+                Thread.currentThread().interrupt();\n+            }\n+        });\n+\n+        // Queue size exceeds the threshold, should disable parallelization\n+        assertEquals(\n+            1,\n+            DefaultSearchContext.determineMaximumNumberOfSlices(\n+                threadPoolExecutor,\n+                parallelReq,\n+                SearchService.ResultsType.DFS,\n+                true,\n+                fieldCardinality\n+            )\n+        );\n+\n+        // Release all threads and clean up\n+        blockingLatch.countDown();\n+        threadPoolExecutor.shutdown();\n+    }\n+\n     public void testIsParallelCollectionSupportedForResults() {\n         SearchSourceBuilder searchSourceBuilderOrNull = randomBoolean() ? null : new SearchSourceBuilder();\n         ToLongFunction<String> fieldCardinality = name -> -1;",
  "logs_path": "factory/claude-sonnet-4-5-20250929/074538b9/elastic_elasticsearch_pr114911/logs.jsonl",
  "errors": [],
  "edit_run_id": "074538b9",
  "test_label": "v0"
}