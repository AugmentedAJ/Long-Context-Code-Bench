## V1 Elasticsearch 100-PR Benchmark (canonical)

This documents the canonical v1 dataset (100 synthesized prompts, rollouts 1-3 only) and the corresponding completed Claude Code edit run.

### Prompts (canonical)
- Path: `data/samples/v1/`
- Count: **100** PR samples (synthesized prompts, rollouts 1-3)
- Public artifacts include only these 100 synthesized prompts; no reference to the larger prompt dataset is needed.

### Edits (canonical)
- Runner/model: `claude-code` / `claude-sonnet-4-5`
- Run ID: `8d6f99fc`
- Path: `output/edits/claude-code/claude-sonnet-4-5/8d6f99fc/`
- Status: 100/100 success
- Diff presence: 91 with non-empty diffs, 9 with empty diffs
  - Empty-diff PRs: 134393, 134420, 134790, 3963, 4129, 4234, 4253, 4494, 4495

### Command used to produce the canonical edits
```
uv run python -m long_context_bench.cli edit data/samples/v1 \
  --runner claude-code \
  --model claude-sonnet-4-5 \
  --dataset-version v1 \
  --test-label v1-rollouts-1-3-sonnet4.5 \
  --timeout 1800 \
  --concurrency 4 \
  --cache-dir .repo_cache \
  --force \
  --stream-output
```

### Cleanup performed
- Removed duplicate top-level v1 samples; kept only the 100 canonical samples under `data/samples/v1/`.
- Removed older/partial Claude Code runs (`2465eb00`, `c7a3f90a`, `dd30913d`, `e9a2f06b`), keeping only the canonical run `8d6f99fc` (other runs, e.g., `0fb73108`, remain untouched).

### Backup
- Archive: `v1_backup_20251121_131654.zip` (7.2 MB)
- Contents: 100 prompts (`data/samples/v1/`), canonical edits (`8d6f99fc`), source PR list (`data/elasticsearch_prs_100_prompt_dataset.json`), README for the backup.

### Reproduce / verify
1) Ensure git working tree is clean and tokens are set (e.g., `ANTHROPIC_API_KEY`; `AUGMENT_API_TOKEN` if using Auggie).
2) Prompts are at `data/samples/v1/` (100 files).
3) To re-run edits (optional): run the command above; outputs will land under `output/edits/claude-code/claude-sonnet-4-5/<new_run_id>/`.
4) Judge stage (once edits are ready): point to the canonical edits dir and use the chosen judge model (e.g., Claude Code Sonnet 4.5) against the ground-truth PR patches.

### Notes
- Public distribution should include only the 100 synthesized prompts and the canonical edit run; no reference to the larger prompt dataset is required.
- 9 PRs have empty diffs (likely documentation/no-op cases); judging should account for that.